<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: Spark 2.4.4 架构原理</title>
    <link rel="canonical" href="http://alexwangx.github.io/apache-spark-internals/2.4.4/apache-spark-internals/2.4.4/spark-scheduler-DAGScheduler.html">
    <meta name="generator" content="Antora 2.0.0">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86782445-1"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','UA-86782445-1')</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="http://alexwangx.github.io/apache-spark-internals/2.4.4">Spark 2.4.4 架构原理</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="#">Home</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Products</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Product A</a>
            <a class="navbar-item" href="#">Product B</a>
            <a class="navbar-item" href="#">Product C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Services</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Service A</a>
            <a class="navbar-item" href="#">Service B</a>
            <a class="navbar-item" href="#">Service C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Resources</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Resource A</a>
            <a class="navbar-item" href="#">Resource B</a>
            <a class="navbar-item" href="#">Resource C</a>
          </div>
        </div>
        <div class="navbar-item">
          <span class="control">
            <a class="button is-primary" href="#">Download</a>
          </span>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="apache-spark-internals" data-version="2.4.4">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Apache Spark</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-overview.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Block Storage System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockDataManager.html">BlockDataManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockId.html">BlockId</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ManagedBuffer.html">ManagedBuffer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockManager.html">BlockManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MemoryStore.html">MemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockEvictionHandler.html">BlockEvictionHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-StorageMemoryPool.html">StorageMemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MemoryPool.html">MemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DiskStore.html">DiskStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcHandler.html">RpcHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcResponseCallback.html">RpcResponseCallback</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportRequestHandler.html">TransportRequestHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportContext.html">TransportContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportServer.html">TransportServer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportClientFactory.html">TransportClientFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MessageHandler.html">MessageHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockManagerMaster.html">BlockManagerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-blockmanager-BlockManagerMasterEndpoint.html">BlockManagerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DiskBlockManager.html">DiskBlockManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockInfoManager.html">BlockInfoManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-BlockInfo.html">BlockInfo</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-BlockManagerSlaveEndpoint.html">BlockManagerSlaveEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-DiskBlockObjectWriter.html">DiskBlockObjectWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockManager-BlockManagerSource.html">BlockManagerSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockManager-ShuffleMetricsSource.html">ShuffleMetricsSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-StorageStatus.html">StorageStatus</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Transferring Data Blocks (between Nodes in Spark Application)</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-ShuffleClient.html">ShuffleClient</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockTransferService.html">BlockTransferService</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-ShuffleClient-ExternalShuffleClient.html">ExternalShuffleClient</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-NettyBlockTransferService.html">NettyBlockTransferService</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-NettyBlockRpcServer.html">NettyBlockRpcServer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockFetchingListener.html">BlockFetchingListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-RetryingBlockFetcher.html">RetryingBlockFetcher</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RetryingBlockFetcher-BlockFetchStarter.html">BlockFetchStarter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shuffle System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleManager.html">ShuffleManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleBlockResolver.html">ShuffleBlockResolver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-SortShuffleManager.html">SortShuffleManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-IndexShuffleBlockResolver.html">IndexShuffleBlockResolver</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleHandle.html">ShuffleHandle</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BaseShuffleHandle.html">BaseShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BypassMergeSortShuffleHandle.html">BypassMergeSortShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-SerializedShuffleHandle.html">SerializedShuffleHandle</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleWriter.html">ShuffleWriter</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BypassMergeSortShuffleWriter.html">BypassMergeSortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-SortShuffleWriter.html">SortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-UnsafeShuffleWriter.html">UnsafeShuffleWriter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleReader.html">ShuffleReader</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BlockStoreShuffleReader.html">BlockStoreShuffleReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleExternalSorter.html">ShuffleExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleInMemorySorter.html">ShuffleInMemorySorter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-architecture.html">Spark Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-driver.html">Driver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-Executor.html">Executor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-Executor-TaskRunner.html">TaskRunner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-executor-ExecutorSource.html">ExecutorSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-master.html">Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-workers.html">Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkConf.html">SparkConf</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-properties.html">Spark Properties and spark-defaults.conf Properties File</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-deploy-mode.html">Deploy Mode</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkContext.html">SparkContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-HeartbeatReceiver.html">HeartbeatReceiver RPC Endpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkContext-creating-instance-internals.html">Inside Creating SparkContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-ConsoleProgressBar.html">ConsoleProgressBar</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-SparkStatusTracker.html">SparkStatusTracker</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-local-properties.html">Local Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-execution-model.html">Execution Model</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-configuration-properties.html">Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-anatomy-spark-application.html">Anatomy of Spark Application</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd.html">RDD</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-RDD.html">RDD API</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-operations.html">Operators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-transformations.html">Transformations</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-rdd-PairRDDFunctions.html">PairRDDFunctions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-actions.html">Actions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-lineage.html">RDD Lineage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-caching.html">Caching and Persistence</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-StorageLevel.html">StorageLevel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-checkpointing.html">Checkpointing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-CheckpointRDD.html">CheckpointRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-partitions.html">Partitions and Partitioning</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-Partition.html">Partition</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-Partitioner.html">Partitioner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-HashPartitioner.html">HashPartitioner</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-shuffle.html">Shuffling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-Dependency.html">RDD Dependencies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-NarrowDependency.html">NarrowDependency</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ShuffleDependency.html">ShuffleDependency</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-Aggregator.html">Map/Reduce-side Aggregator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Specialized RDDs</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ParallelCollectionRDD.html">ParallelCollectionRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-MapPartitionsRDD.html">MapPartitionsRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-OrderedRDDFunctions.html">OrderedRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-CoGroupedRDD.html">CoGroupedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-SubtractedRDD.html">SubtractedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-HadoopRDD.html">HadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-NewHadoopRDD.html">NewHadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ShuffledRDD.html">ShuffledRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-TaskLocation.html">TaskLocation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-SparkHadoopWriter.html">SparkHadoopWriter</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-FileCommitProtocol.html">FileCommitProtocol</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapReduceCommitProtocol.html">HadoopMapReduceCommitProtocol</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapRedCommitProtocol.html">HadoopMapRedCommitProtocol</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-HadoopWriteConfigUtil.html">HadoopWriteConfigUtil</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapReduceWriteConfigUtil.html">HadoopMapReduceWriteConfigUtil</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapRedWriteConfigUtil.html">HadoopMapRedWriteConfigUtil</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-core-AppStatusStore.html">AppStatusStore</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-core-AppStatusPlugin.html">AppStatusPlugin</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-core-KVStore.html">KVStore</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-KVStoreView.html">KVStoreView</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-ElementTrackingStore.html">ElementTrackingStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-InMemoryStore.html">InMemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-LevelDB.html">LevelDB</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-InterruptibleIterator.html">InterruptibleIterator</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-barrier-execution-mode.html">Barrier Execution Mode</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-RDDBarrier.html">RDDBarrier</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shared Variables</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-broadcast.html">Broadcast variables</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-accumulators.html">Accumulators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-AccumulatorContext.html">AccumulatorContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Tools</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shell.html">Spark Shell (spark-shell)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-submit.html">Spark Submit (spark-submit)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitArguments.html">SparkSubmitArguments</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitOptionParser.html">SparkSubmitOptionParser</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitCommandBuilder.html">SparkSubmitCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-class.html">spark-class shell script</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-AbstractCommandBuilder.html">AbstractCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SparkLauncher.html">SparkLauncher</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Core Services</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Low-Level Spark Task Scheduler</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-ActiveJob.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-SchedulableBuilder.html">SchedulableBuilder</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-FIFOSchedulableBuilder.html">FIFOSchedulableBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-FairSchedulableBuilder.html">FairSchedulableBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-TaskScheduler.html">TaskScheduler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-TaskSchedulerImpl.html">TaskSchedulerImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Task.html">Task</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ShuffleMapTask.html">ShuffleMapTask</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ResultTask.html">ResultTask</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSet.html">TaskSet</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSetManager.html">TaskSetManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Schedulable.html">Schedulable Entities</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-Pool.html">Schedulable Pool</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-SchedulingMode.html">Scheduling Mode</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskInfo.html">TaskInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TaskRunner-FetchFailedException.html">FetchFailedException</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-MapStatus.html">MapStatus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskDescription.html">TaskDescription</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-taskschedulerimpl-speculative-execution.html">Speculative Execution of Tasks</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskResultGetter.html">TaskResultGetter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-TaskContext.html">TaskContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-BarrierTaskContext.html">BarrierTaskContext</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TaskContextImpl.html">TaskContextImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskResult.html">TaskResults</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSetBlacklist.html">TaskSetBlacklist</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">High-Level Spark Stage Scheduler</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="3">
    <a class="nav-link" href="spark-scheduler-DAGScheduler.html">DAGScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Stage.html">Stage</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ShuffleMapStage.html">ShuffleMapStage</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ResultStage.html">ResultStage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-StageInfo.html">StageInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-DAGSchedulerEventProcessLoop.html">DAGScheduler Event Bus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-JobListener.html">JobListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-JobWaiter.html">JobWaiter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-memory-unified-memory-management.html">Unified Memory Management</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-memory-TaskMemoryManager.html">TaskMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-memory-MemoryConsumer.html">MemoryConsumer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-MemoryManager.html">MemoryManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-UnifiedMemoryManager.html">UnifiedMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-StaticMemoryManager.html">StaticMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-MemoryManager-properties.html">MemoryManager Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SerializerManager.html">SerializerManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SparkEnv.html">SparkEnv</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SchedulerBackend.html">SchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-CoarseGrainedSchedulerBackend.html">CoarseGrainedSchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-CoarseGrainedSchedulerBackend-DriverEndpoint.html">DriverEndpoint</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-ExecutorBackend.html">ExecutorBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CoarseGrainedExecutorBackend.html">CoarseGrainedExecutorBackend</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalShuffleService.html">ExternalShuffleService</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-OneForOneStreamManager.html">OneForOneStreamManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ShuffleBlockFetcherIterator.html">ShuffleBlockFetcherIterator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalSorter.html">ExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-mapoutputtracker.html">MapOutputTracker</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-MapOutputTrackerMaster.html">MapOutputTrackerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-service-MapOutputTrackerMasterEndpoint.html">MapOutputTrackerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-MapOutputTrackerWorker.html">MapOutputTrackerWorker</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-serialization.html">Serialization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-Serializer.html">Serializer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SerializerInstance.html">SerializerInstance</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SerializationStream.html">SerializationStream</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DeserializationStream.html">DeserializationStream</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalClusterManager.html">ExternalClusterManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-broadcastmanager.html">BroadcastManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BroadcastFactory.html">BroadcastFactory</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TorrentBroadcastFactory.html">TorrentBroadcastFactory</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TorrentBroadcast.html">TorrentBroadcast</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CompressionCodec.html">CompressionCodec</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-contextcleaner.html">ContextCleaner</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CleanerListener.html">CleanerListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-dynamic-allocation.html">Dynamic Allocation (of Executors)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-ExecutorAllocationManager.html">ExecutorAllocationManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-ExecutorAllocationClient.html">ExecutorAllocationClient</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-ExecutorAllocationManagerSource.html">ExecutorAllocationManagerSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-http-file-server.html">HTTP File Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-data-locality.html">Data Locality</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-cachemanager.html">Cache Manager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-service-outputcommitcoordinator.html">OutputCommitCoordinator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rpc.html">RPC Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-RpcEnv.html">RpcEnv</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-RpcEndpoint.html">RpcEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcEndpointRef.html">RpcEndpointRef</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcEnvFactory.html">RpcEnvFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-netty.html">Netty-based RpcEnv</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-TransportConf.html">TransportConf</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-Utils.html">Utils Helper Object</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Security</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-webui-security.html">Securing Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-deployment-environments.html">Deployment Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-cluster.html">Spark on cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-history-server.html">Spark History Server</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-HistoryServer.html">HistoryServer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-SQLHistoryListener.html">SQLHistoryListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-FsHistoryProvider.html">FsHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationHistoryProvider.html">ApplicationHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-HistoryServerArguments.html">HistoryServerArguments</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationCacheOperations.html">ApplicationCacheOperations</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationCache.html">ApplicationCache</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring, Tuning, Debugging and Testing</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-logging.html">Logging</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tuning.html">Performance Tuning</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-SparkListener.html">SparkListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-AppStatusListener.html">AppStatusListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-EventLoggingListener.html">EventLoggingListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-ExecutorAllocationListener.html">ExecutorAllocationListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-SpillListener.html">SpillListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-StatsReportListener.html">StatsReportListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-scheduler-LiveListenerBus.html">LiveListenerBus</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkListenerBus.html">SparkListenerBus</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListenerBus-AsyncEventQueue.html">AsyncEventQueue</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListenerBus-ReplayListenerBus.html">ReplayListenerBus</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-JsonProtocol.html">JsonProtocol</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-debugging.html">Debugging Spark</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Varia</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-building-from-sources.html">Building Apache Spark from Sources</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="varia/spark-hadoop.html">Spark and Hadoop</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkHadoopUtil.html">SparkHadoopUtil</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-inmemory-filesystems.html">Spark and software in-memory file systems</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-others.html">Spark and The Others</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-deeplearning.html">Distributed Deep Learning on Spark</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-packages.html">Spark Packages</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-tips-and-tricks.html">Spark Tips and Tricks</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-access-private-members-spark-shell.html">Access private members in Scala in Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-sparkexception-task-not-serializable.html">SparkException: Task not serializable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-running-spark-windows.html">Running Spark Applications on Windows</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Further Learning</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-courses.html">Courses</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-books.html">Books</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-sql.html">Spark SQL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-structured-streaming.html">Spark Structured Streaming</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/index.html">Web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-jobs.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-stages.html">Stages</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-storage.html">Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-environment.html">Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-executors.html">Executors</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-JobsTab.html">JobsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-AllJobsPage.html">AllJobsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-JobPage.html">JobPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-StagesTab.html">StagesTab&#8201;&#8212;&#8201;Stages for All Jobs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-AllStagesPage.html">AllStagesPage&#8201;&#8212;&#8201;Stages for All Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-StagePage.html">StagePage&#8201;&#8212;&#8201;Stage Details</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-PoolPage.html">PoolPage&#8201;&#8212;&#8201;Pool Details</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-StorageTab.html">StorageTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-StoragePage.html">StoragePage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-RDDPage.html">RDDPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-EnvironmentTab.html">EnvironmentTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-EnvironmentPage.html">EnvironmentPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-ExecutorsTab.html">ExecutorsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-ExecutorsPage.html">ExecutorsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-ExecutorThreadDumpPage.html">ExecutorThreadDumpPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-SparkUI.html">SparkUI&#8201;&#8212;&#8201;Web UI of Spark Application</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-SparkUITab.html">SparkUITab</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-BlockStatusListener.html">BlockStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-EnvironmentListener.html">EnvironmentListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-executors-ExecutorsListener.html">ExecutorsListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-JobProgressListener.html">JobProgressListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-StorageStatusListener.html">StorageStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-StorageListener.html">StorageListener&#8201;&#8212;&#8201;Spark Listener for Tracking Persistence Status of RDD Blocks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-RDDOperationGraphListener.html">RDDOperationGraphListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-WebUI.html">WebUI&#8201;&#8212;&#8201;Framework For Web UIs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-WebUIPage.html">WebUIPage&#8201;&#8212;&#8201;Contract of Pages in Web UI</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-WebUITab.html">WebUITab&#8201;&#8212;&#8201;Contract of Tabs in Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-RDDStorageInfo.html">RDDStorageInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-core-RDDInfo.html">RDDInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-core-LiveEntity.html">LiveEntity</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-core-LiveRDD.html">LiveRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-UIUtils.html">UIUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-JettyUtils.html">JettyUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-properties.html">web UI Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/index.html">Spark Metrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-MetricsSystem.html">MetricsSystem</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-MetricsConfig.html">MetricsConfig</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-metrics-Source.html">Source</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-scheduler-DAGSchedulerSource.html">DAGSchedulerSourcer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-metrics-Sink.html">Sink</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-metrics-MetricsServlet.html">MetricsServlet JSON Metrics Sink</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-properties.html">Metrics Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-executor-TaskMetrics.html">TaskMetrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-executor-ShuffleWriteMetrics.html">ShuffleWriteMetrics</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/index.html">Spark MLlib</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines.html">ML Pipelines (spark.ml)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-Pipeline.html">Pipeline</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-PipelineStage.html">PipelineStage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-transformers.html">Transformers</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-Transformer.html">Transformer</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-transformers-Tokenizer.html">Tokenizer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-estimators.html">Estimators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Estimator.html">Estimator</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-StringIndexer.html">StringIndexer</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-KMeans.html">KMeans</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-TrainValidationSplit.html">TrainValidationSplit</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Predictor.html">Predictor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-RandomForestRegressor.html">RandomForestRegressor</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Regressor.html">Regressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-LinearRegression.html">LinearRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Classifier.html">Classifier</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-RandomForestClassifier.html">RandomForestClassifier</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-DecisionTreeClassifier.html">DecisionTreeClassifier</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-models.html">Models</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-Model.html">Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Evaluator.html">Evaluator&#8201;&#8212;&#8201;ML Pipeline Component for Model Scoring</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-BinaryClassificationEvaluator.html">BinaryClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Binary Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ClusteringEvaluator.html">ClusteringEvaluator&#8201;&#8212;&#8201;Evaluator of Clustering Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-MulticlassClassificationEvaluator.html">MulticlassClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Multiclass Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-RegressionEvaluator.html">RegressionEvaluator&#8201;&#8212;&#8201;Evaluator of Regression Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidator.html">CrossValidator&#8201;&#8212;&#8201;Model Tuning / Finding The Best Model</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidatorModel.html">CrossValidatorModel</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ParamGridBuilder.html">ParamGridBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidator-example.html">CrossValidator with Pipeline Example</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Params.html">Params and ParamMaps</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ValidatorParams.html">ValidatorParams</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-HasParallelism.html">HasParallelism</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-persistence.html">ML Persistence&#8201;&#8212;&#8201;Saving and Loading Models and Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLWritable.html">MLWritable</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLReader.html">MLReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-example-classification.html">Example&#8201;&#8212;&#8201;Text Classification</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-example-regression.html">Example&#8201;&#8212;&#8201;Linear Regression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-logistic-regression.html">Logistic Regression</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-LogisticRegression.html">LogisticRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-latent-dirichlet-allocation.html">Latent Dirichlet Allocation (LDA)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-vector.html">Vector</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-labeledpoint.html">LabeledPoint</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-streaming.html">Streaming MLlib</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-GeneralizedLinearRegression.html">GeneralizedLinearRegression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-alternating-least-squares.html">Alternating Least Squares (ALS) Matrix Factorization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALS.html">ALS&#8201;&#8212;&#8201;Estimator for ALSModel</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALSModel.html">ALSModel&#8201;&#8212;&#8201;Model for Predictions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALSModelReader.html">ALSModelReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-Instrumentation.html">Instrumentation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLUtils.html">MLUtils</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-local/index.html">Spark local</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LocalSchedulerBackend.html">LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LocalEndpoint.html">LocalEndpoint&#8201;&#8212;&#8201;RPC Endpoint for LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LauncherBackend.html">LauncherBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/index.html">Spark on YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnShuffleService.html">YarnShuffleService&#8201;&#8212;&#8201;ExternalShuffleService on YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ExecutorRunnable.html">ExecutorRunnable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-client.html">Client</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnrmclient.html">YarnRMClient</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-applicationmaster.html">ApplicationMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-AMEndpoint.html">AMEndpoint&#8201;&#8212;&#8201;ApplicationMaster RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnClusterManager.html">YarnClusterManager&#8201;&#8212;&#8201;ExternalClusterManager for YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-taskschedulers.html">TaskSchedulers for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnscheduler.html">YarnScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnclusterscheduler.html">YarnClusterScheduler</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-schedulerbackends.html">SchedulerBackends for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnschedulerbackend.html">YarnSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-client-yarnclientschedulerbackend.html">YarnClientSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-yarnclusterschedulerbackend.html">YarnClusterSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-YarnSchedulerEndpoint.html">YarnSchedulerEndpoint RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnAllocator.html">YarnAllocator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-introduction.html">Introduction to Hadoop YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-setup.html">Setting up YARN Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-kerberos.html">Kerberos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ConfigurableCredentialManager.html">ConfigurableCredentialManager</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ClientDistributedCacheManager.html">ClientDistributedCacheManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnSparkHadoopUtil.html">YarnSparkHadoopUtil</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-settings.html">Settings</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-standalone/index.html">Spark Standalone</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-Master.html">Standalone Master&#8201;&#8212;&#8201;Cluster Manager of Spark Standalone</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-worker.html">Standalone Worker</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-standalone/spark-standalone-webui.html">web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-standalone/spark-standalone-webui-ApplicationPage.html">ApplicationPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-LocalSparkCluster.html">LocalSparkCluster&#8201;&#8212;&#8201;Single-JVM Spark Standalone Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-submission-gateways.html">Submission Gateways</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-master-scripts.html">Management Scripts for Standalone Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-worker-scripts.html">Management Scripts for Standalone Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-status.html">Checking Status</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-example-2-workers-on-1-node-cluster.html">Example 2-workers-on-1-node Standalone Cluster (one executor per worker)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-StandaloneSchedulerBackend.html">StandaloneSchedulerBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/index.html">Status REST API</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-ApiRootResource.html">ApiRootResource&#8201;&#8212;&#8201;/api/v1 URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-ApplicationListResource.html">ApplicationListResource&#8201;&#8212;&#8201;applications URI Handler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-OneApplicationResource.html">OneApplicationResource&#8201;&#8212;&#8201;applications/appId URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="rest-api/spark-api-StagesResource.html">StagesResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-OneApplicationAttemptResource.html">OneApplicationAttemptResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-AbstractApplicationResource.html">AbstractApplicationResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-BaseAppResource.html">BaseAppResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-ApiRequestContext.html">ApiRequestContext</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-UIRoot.html">UIRoot&#8201;&#8212;&#8201;Contract for Root Contrainers of Application UI Information</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-UIRootFromServletContext.html">UIRootFromServletContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-mesos/index.html">Spark on Mesos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-mesos-MesosCoarseGrainedSchedulerBackend.html">MesosCoarseGrainedSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-mesos-introduction.html">About Mesos</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-executor-backends-MesosExecutorBackend.html">MesosExecutorBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Exercises</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-pairrddfunctions-oneliners.html">One-liners using PairRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-take-multiple-jobs.html">Learning Jobs and Partitions Using take Action</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-standalone-master-ha.html">Spark Standalone - Using ZooKeeper for High-Availability of Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-hello-world-using-spark-shell.html">Spark&#8217;s Hello World using Spark shell and Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-examples-wordcount-spark-shell.html">WordCount using Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-first-app.html">Your first complete Spark application (using Scala and sbt)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-notable-use-cases.html">Spark (notable) use cases</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-sql-hive-orc-example.html">Using Spark SQL to update data in Hive using ORC files</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-scheduler-listener.html">Developing Custom SparkListener to monitor DAGScheduler in Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-rpc-environment.html">Developing RPC Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-rdd.html">Developing Custom RDD</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-dataframe-jdbc-postgresql.html">Working with Datasets from JDBC Data Sources (and PostgreSQL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-failing-stage.html">Causing Stage to Fail</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Apache Spark</span>
    <span class="version">2.4.4</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Apache Spark</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="index.html">2.4.4</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main role="main">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Apache Spark</a></li>
    <li>Core Services</li>
    <li>High-Level Spark Stage Scheduler</li>
    <li><a href="spark-scheduler-DAGScheduler.html">DAGScheduler</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///Users/alex/Alex/_Code/GitBook/mastering-apache-spark-book-cn/modules/ROOT/pages/spark-scheduler-DAGScheduler.adoc">Edit this Page</a></div>
</div>
<article class="doc">
<div class="sect1">
<h2 id="_dagschedulerstage_oriented_scheduler"><a class="anchor" href="#_dagschedulerstage_oriented_scheduler"></a><a id="DAGScheduler"></a> DAGScheduler&#8201;&#8212;&#8201;Stage-Oriented Scheduler</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The introduction that follows was highly influenced by the scaladoc of <a href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala">org.apache.spark.scheduler.DAGScheduler</a>. As DAGScheduler is a private class it does not appear in the official API documentation. You are strongly encouraged to read <a href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala">the sources</a> and only then read this and the related pages afterwards.</p>
</div>
<div class="paragraph">
<p><em>"Reading the sources"</em>, I say?! Yes, I <em>am</em> kidding!</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_introduction"><a class="anchor" href="#_introduction"></a>Introduction</h3>
<div class="paragraph">
<p><strong>DAGScheduler</strong> is the scheduling layer of Apache Spark that implements <strong>stage-oriented scheduling</strong>. It transforms a <strong>logical execution plan</strong> (i.e. <a href="spark-rdd-lineage.adoc">RDD lineage</a> of dependencies built using <a href="spark-rdd-transformations.adoc">RDD transformations</a>) to a <strong>physical execution plan</strong> (using <a href="spark-scheduler-Stage.adoc">stages</a>).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/dagscheduler-rdd-lineage-stage-dag.png" alt="dagscheduler rdd lineage stage dag">
</div>
<div class="title">Figure 1. <code>DAGScheduler</code> Transforming RDD Lineage Into Stage DAG</div>
</div>
<div class="paragraph">
<p>After an <a href="spark-rdd-actions.adoc">action</a> has been called, <a href="spark-SparkContext.adoc">SparkContext</a> hands over a logical plan to <code>DAGScheduler</code> that it in turn translates to a set of stages that are submitted as <a href="spark-scheduler-TaskSet.adoc">TaskSets</a> for execution (see <a href="spark-execution-model.adoc">Execution Model</a>).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/dagscheduler-rdd-partitions-job-resultstage.png" alt="dagscheduler rdd partitions job resultstage">
</div>
<div class="title">Figure 2. Executing action leads to new ResultStage and ActiveJob in DAGScheduler</div>
</div>
<div class="paragraph">
<p>The fundamental concepts of <code>DAGScheduler</code> are <strong>jobs</strong> and <strong>stages</strong> (refer to <a href="spark-scheduler-ActiveJob.adoc">Jobs</a> and <a href="spark-scheduler-Stage.adoc">Stages</a> respectively) that it tracks through <a href="#internal-registries">internal registries and counters</a>.</p>
</div>
<div class="paragraph">
<p>DAGScheduler works solely on the driver and is created as part of <a href="spark-SparkContext.adoc#creating-instance">SparkContext&#8217;s initialization</a> (right after <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a> and <a href="spark-SchedulerBackend.adoc">SchedulerBackend</a> are ready).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/dagscheduler-new-instance.png" alt="dagscheduler new instance">
</div>
<div class="title">Figure 3. DAGScheduler as created by SparkContext with other services</div>
</div>
<div class="paragraph">
<p>DAGScheduler does three things in Spark (thorough explanations follow):</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Computes an <strong>execution DAG</strong>, i.e. DAG of stages, for a job.</p>
</li>
<li>
<p>Determines the <a href="#preferred-locations">preferred locations</a> to run each task on.</p>
</li>
<li>
<p>Handles failures due to <strong>shuffle output files</strong> being lost.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><code>DAGScheduler</code> computes <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">a directed acyclic graph (DAG)</a> of stages for each job, keeps track of which RDDs and stage outputs are materialized, and finds a minimal schedule to run jobs. It then submits stages to <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a>.</p>
</div>
<div class="paragraph">
<p>In addition to coming up with the execution DAG, DAGScheduler also determines the preferred locations to run each task on, based on the current cache status, and passes the information to <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a>.</p>
</div>
<div class="paragraph">
<p><code>DAGScheduler</code> tracks which <a href="spark-rdd-caching.adoc">RDDs are cached (or persisted)</a> to avoid "recomputing" them, i.e. redoing the map side of a shuffle. <code>DAGScheduler</code> remembers what <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a>s have already produced output files (that are stored in <a href="spark-BlockManager.adoc">BlockManager</a>s).</p>
</div>
<div class="paragraph">
<p>DAGScheduler is only interested in cache location coordinates, i.e. host and executor id, per partition of a RDD.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME: A diagram, please
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Furthermore, it handles failures due to shuffle output files being lost, in which case old stages may need to be resubmitted. Failures within a stage that are not caused by shuffle file loss are handled by the TaskScheduler itself, which will retry each task a small number of times before cancelling the whole stage.</p>
</div>
<div class="paragraph">
<p>DAGScheduler uses an <strong>event queue architecture</strong> in which a thread can post <code>DAGSchedulerEvent</code> events, e.g. a new job or stage being submitted, that DAGScheduler reads and executes sequentially. See the section <a href="#event-loop">Internal Event Loop - dag-scheduler-event-loop</a>.</p>
</div>
<div class="paragraph">
<p>DAGScheduler runs stages in topological order.</p>
</div>
<table id="internal-properties" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. DAGScheduler&#8217;s Internal Properties</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Initial Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="metricsSource"></a> metricsSource</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="spark-scheduler-DAGSchedulerSource.adoc">DAGSchedulerSource</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FIXME</p></td>
</tr>
</tbody>
</table>
<table id="internal-registries" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. DAGScheduler&#8217;s Internal Registries and Counters</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 66.6667%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="activeJobs"></a> <code>activeJobs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ActiveJob</code> instances</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="cacheLocs"></a> <code>cacheLocs</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Block locations per RDD and partition.</p>
<p class="tableblock">Uses <a href="spark-TaskLocation.adoc">TaskLocation</a> that includes a host name and an executor id on that host (as <code>ExecutorCacheTaskLocation</code>).</p>
<p class="tableblock">The keys are RDDs (their ids) and the values are arrays indexed by partition numbers.</p>
<p class="tableblock">Each entry is a set of block locations where a RDD partition is cached, i.e. the <a href="spark-BlockManager.adoc">BlockManager</a>s of the blocks.</p>
<p class="tableblock">Initialized empty when <a href="#creating-instance"><code>DAGScheduler</code> is created</a>.</p>
<p class="tableblock">Used when <code>DAGScheduler</code> is requested for the <a href="#getCacheLocs">locations of the cache blocks of a RDD</a> or <a href="#clearCacheLocs">clear them</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="failedEpoch"></a> <code>failedEpoch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lookup table of lost executors and the epoch of the event.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="failedStages"></a> <code>failedStages</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Stages that failed due to fetch failures (when a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-FetchFailed">task fails with <code>FetchFailed</code> exception</a>).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="jobIdToActiveJob"></a> <code>jobIdToActiveJob</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lookup table of <code>ActiveJob</code>s per job id.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="jobIdToStageIds"></a> <code>jobIdToStageIds</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lookup table of all stages per <code>ActiveJob</code> id</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="nextJobId"></a> <code>nextJobId</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The next job id counting from <code>0</code>.</p>
<p class="tableblock">Used when <code>DAGScheduler</code> <a href="#submitJob">submits a job</a> and <a href="#submitMapStage">a map stage</a>, and <a href="#runApproximateJob">runs an approximate job</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="nextStageId"></a> <code>nextStageId</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The next stage id counting from <code>0</code>.</p>
<p class="tableblock">Used when <code>DAGScheduler</code> creates a <a href="#createShuffleMapStage">shuffle map stage</a> and a <a href="#createResultStage">result stage</a>. It is the key in <a href="#stageIdToStage">stageIdToStage</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="runningStages"></a> <code>runningStages</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The set of stages that are currently "running".</p>
<p class="tableblock">A stage is added when <a href="#submitMissingTasks">submitMissingTasks</a> gets executed (without first checking if the stage has not already been added).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="shuffleIdToMapStage"></a> <code>shuffleIdToMapStage</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lookup table of <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a>s per <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="stageIdToStage"></a> <code>stageIdToStage</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lookup table for stages per their ids.</p>
<p class="tableblock">Used when <code>DAGScheduler</code> <a href="#createShuffleMapStage">creates a shuffle map stage</a>, <a href="#createResultStage">creates a result stage</a>, <a href="#cleanupStateForJobAndIndependentStages">cleans up job state and independent stages</a>, is informed that <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleBeginEvent">a task is started</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskSetFailed">a taskset has failed</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleJobSubmitted">a job is submitted (to compute a <code>ResultStage</code>)</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleMapStageSubmitted">a map stage was submitted</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion">a task has completed</a> or <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleStageCancellation">a stage was cancelled</a>, <a href="#updateAccumulators">updates accumulators</a>, <a href="#abortStage">aborts a stage</a> and <a href="#failJobAndIndependentStages">fails a job and independent stages</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="waitingStages"></a> <code>waitingStages</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The stages with parents to be computed</p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Enable <code>INFO</code>, <code>DEBUG</code> or <code>TRACE</code> logging levels for <code>org.apache.spark.scheduler.DAGSchedule</code> logger to see what happens inside <code>DAGScheduler</code>.</p>
</div>
<div class="paragraph">
<p>Add the following line to <code>conf/log4j.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>log4j.logger.org.apache.spark.scheduler.DAGScheduler=TRACE</code></pre>
</div>
</div>
<div class="paragraph">
<p>Refer to <a href="spark-logging.adoc">Logging</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>DAGScheduler uses <a href="spark-SparkContext.adoc">SparkContext</a>, <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a>, <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a>, <a href="spark-service-mapoutputtracker.adoc">MapOutputTracker</a> and <a href="spark-BlockManager.adoc">BlockManager</a> for its services. However, at the very minimum, <code>DAGScheduler</code> takes a <code>SparkContext</code> only (and requests <code>SparkContext</code> for the other services).</p>
</div>
<div class="paragraph">
<p>DAGScheduler reports metrics about its execution (refer to the section <a href="#metrics">Metrics</a>).</p>
</div>
<div class="paragraph">
<p>When DAGScheduler schedules a job as a result of <a href="spark-rdd.adoc#actions">executing an action on a RDD</a> or <a href="spark-SparkContext.adoc#runJob">calling SparkContext.runJob() method directly</a>, it spawns parallel tasks to compute (partial) results per partition.</p>
</div>
</div>
<div class="sect2">
<h3 id="_running_approximate_jobrunapproximatejob_method"><a class="anchor" href="#_running_approximate_jobrunapproximatejob_method"></a><a id="runApproximateJob"></a> Running Approximate Job&#8201;&#8212;&#8201;<code>runApproximateJob</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_createresultstage_internal_method"><a class="anchor" href="#_createresultstage_internal_method"></a><a id="createResultStage"></a> <code>createResultStage</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">createResultStage(
  rdd: RDD[_],
  func: (TaskContext, Iterator[_]) =&gt; _,
  partitions: Array[Int],
  jobId: Int,
  callSite: CallSite): ResultStage</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_updatejobidstageidmaps_method"><a class="anchor" href="#_updatejobidstageidmaps_method"></a><a id="updateJobIdStageIdMaps"></a> <code>updateJobIdStageIdMaps</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_creating_dagscheduler_instance"><a class="anchor" href="#_creating_dagscheduler_instance"></a><a id="creating-instance"></a><a id="initialization"></a> Creating DAGScheduler Instance</h3>
<div class="paragraph">
<p><code>DAGScheduler</code> takes the following when created:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="sc"></a> <a href="spark-SparkContext.adoc">SparkContext</a></p>
</li>
<li>
<p><a id="taskScheduler"></a> <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a></p>
</li>
<li>
<p><a id="listenerBus"></a> <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a></p>
</li>
<li>
<p><a id="mapOutputTracker"></a> <a href="spark-service-MapOutputTrackerMaster.adoc">MapOutputTrackerMaster</a></p>
</li>
<li>
<p><a id="blockManagerMaster"></a> <a href="spark-BlockManagerMaster.adoc">BlockManagerMaster</a></p>
</li>
<li>
<p><a id="env"></a> <a href="spark-SparkEnv.adoc">SparkEnv</a></p>
</li>
<li>
<p><a id="clock"></a> <code>Clock</code> (defaults to <code>SystemClock</code>)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><code>DAGScheduler</code> initializes the <a href="#internal-registries">internal registries and counters</a>.</p>
</div>
<div class="paragraph">
<p><code>DAGScheduler</code> <a href="spark-scheduler-TaskScheduler.adoc#setDAGScheduler">sets itself in the given <code>TaskScheduler</code></a> and in the end starts <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>DAGScheduler</code> can reference all the services through a single <a href="spark-SparkContext.adoc">SparkContext</a> with or without specifying explicit <a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_livelistenerbus_event_bus_for_sparklistenereventslistenerbus_property"><a class="anchor" href="#_livelistenerbus_event_bus_for_sparklistenereventslistenerbus_property"></a><a id="listenerBus"></a> LiveListenerBus Event Bus for SparkListenerEvents&#8201;&#8212;&#8201;<code>listenerBus</code> Property</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">listenerBus: LiveListenerBus</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>listenerBus</code> is a <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> to post scheduling events and is passed in when <a href="#creating-instance"><code>DAGScheduler</code> is created</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_executorheartbeatreceived_method"><a class="anchor" href="#_executorheartbeatreceived_method"></a><a id="executorHeartbeatReceived"></a> <code>executorHeartbeatReceived</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">executorHeartbeatReceived(
  execId: String,
  accumUpdates: Array[(Long, Int, Int, Seq[AccumulableInfo])],
  blockManagerId: BlockManagerId): Boolean</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>executorHeartbeatReceived</code> posts a <a href="spark-scheduler-SparkListener.adoc#SparkListenerExecutorMetricsUpdate">SparkListenerExecutorMetricsUpdate</a> (to <a href="#listenerBus">listenerBus</a>) and informs <a href="spark-BlockManagerMaster.adoc">BlockManagerMaster</a> that <code>blockManagerId</code> block manager is alive (by posting <a href="spark-BlockManagerMaster.adoc#BlockManagerHeartbeat">BlockManagerHeartbeat</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>executorHeartbeatReceived</code> is called when <code>TaskSchedulerImpl</code> <a href="spark-scheduler-TaskSchedulerImpl.adoc#executorHeartbeatReceived">handles <code>executorHeartbeatReceived</code></a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cleaning_up_after_activejob_and_independent_stagescleanupstateforjobandindependentstages_method"><a class="anchor" href="#_cleaning_up_after_activejob_and_independent_stagescleanupstateforjobandindependentstages_method"></a><a id="cleanupStateForJobAndIndependentStages"></a> Cleaning Up After ActiveJob and Independent Stages&#8201;&#8212;&#8201;<code>cleanupStateForJobAndIndependentStages</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cleanupStateForJobAndIndependentStages(job: ActiveJob): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cleanupStateForJobAndIndependentStages</code> cleans up the state for <code>job</code> and any stages that are <em>not</em> part of any other job.</p>
</div>
<div class="paragraph">
<p><code>cleanupStateForJobAndIndependentStages</code> looks the <code>job</code> up in the internal <a href="#jobIdToStageIds">jobIdToStageIds</a> registry.</p>
</div>
<div class="paragraph">
<p>If no stages are found, the following ERROR is printed out to the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR No stages registered for job [jobId]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Oterwise, <code>cleanupStateForJobAndIndependentStages</code> uses <a href="#stageIdToStage">stageIdToStage</a> registry to find the stages (the real objects not ids!).</p>
</div>
<div class="paragraph">
<p>For each stage, <code>cleanupStateForJobAndIndependentStages</code> reads the jobs the stage belongs to.</p>
</div>
<div class="paragraph">
<p>If the <code>job</code> does not belong to the jobs of the stage, the following ERROR is printed out to the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR Job [jobId] not registered for stage [stageId] even though that stage was registered for the job</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the <code>job</code> was the only job for the stage, the stage (and the stage id) gets cleaned up from the registries, i.e. <a href="#runningStages">runningStages</a>, <a href="#shuffleIdToMapStage">shuffleIdToMapStage</a>, <a href="#waitingStages">waitingStages</a>, <a href="#failedStages">failedStages</a> and <a href="#stageIdToStage">stageIdToStage</a>.</p>
</div>
<div class="paragraph">
<p>While removing from <a href="#runningStages">runningStages</a>, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG Removing running stage [stageId]</code></pre>
</div>
</div>
<div class="paragraph">
<p>While removing from <a href="#waitingStages">waitingStages</a>, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG Removing stage [stageId] from waiting set.</code></pre>
</div>
</div>
<div class="paragraph">
<p>While removing from <a href="#failedStages">failedStages</a>, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG Removing stage [stageId] from failed set.</code></pre>
</div>
</div>
<div class="paragraph">
<p>After all cleaning (using <a href="#stageIdToStage">stageIdToStage</a> as the source registry), if the stage belonged to the one and only <code>job</code>, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG After removal of stage [stageId], remaining stages = [stageIdToStage.size]</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>job</code> is removed from <a href="#jobIdToStageIds">jobIdToStageIds</a>, <a href="#jobIdToActiveJob">jobIdToActiveJob</a>, <a href="#activeJobs">activeJobs</a> registries.</p>
</div>
<div class="paragraph">
<p>The final stage of the <code>job</code> is removed, i.e. <a href="spark-scheduler-ResultStage.adoc#removeActiveJob">ResultStage</a> or <a href="spark-scheduler-ShuffleMapStage.adoc#removeActiveJob">ShuffleMapStage</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cleanupStateForJobAndIndependentStages</code> is used in <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-Success-ResultTask"><code>handleTaskCompletion</code> when a <code>ResultTask</code> has completed successfully</a>, <a href="#failJobAndIndependentStages">failJobAndIndependentStages</a> and <a href="#markMapStageJobAsFinished">markMapStageJobAsFinished</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_marking_shufflemapstage_job_finishedmarkmapstagejobasfinished_method"><a class="anchor" href="#_marking_shufflemapstage_job_finishedmarkmapstagejobasfinished_method"></a><a id="markMapStageJobAsFinished"></a> Marking ShuffleMapStage Job Finished&#8201;&#8212;&#8201;<code>markMapStageJobAsFinished</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">markMapStageJobAsFinished(job: ActiveJob, stats: MapOutputStatistics): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>markMapStageJobAsFinished</code> marks the active <code>job</code> finished and notifies Spark listeners.</p>
</div>
<div class="paragraph">
<p>Internally, <code>markMapStageJobAsFinished</code> marks the zeroth partition finished and increases the number of tasks finished in <code>job</code>.</p>
</div>
<div class="paragraph">
<p>The <a href="spark-scheduler-JobListener.adoc#taskSucceeded"><code>job</code> listener is notified about the 0th task succeeded</a>.</p>
</div>
<div class="paragraph">
<p>The <a href="#cleanupStateForJobAndIndependentStages">state of the <code>job</code> and independent stages are cleaned up</a>.</p>
</div>
<div class="paragraph">
<p>Ultimately, <a href="spark-scheduler-SparkListener.adoc#SparkListenerJobEnd">SparkListenerJobEnd</a> is posted to <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> (as <a href="#listenerBus">listenerBus</a>) for the <code>job</code>, the current time (in millis) and <code>JobSucceeded</code> job result.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>markMapStageJobAsFinished</code> is used in <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleMapStageSubmitted">handleMapStageSubmitted</a> and <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc##handleTaskCompletion">handleTaskCompletion</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_jobsubmitjob_method"><a class="anchor" href="#_submitting_jobsubmitjob_method"></a><a id="submitJob"></a> Submitting Job&#8201;&#8212;&#8201;<code>submitJob</code> method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitJob[T, U](
  rdd: RDD[T],
  func: (TaskContext, Iterator[T]) =&gt; U,
  partitions: Seq[Int],
  callSite: CallSite,
  resultHandler: (Int, U) =&gt; Unit,
  properties: Properties): JobWaiter[U]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitJob</code> creates a <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> and posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#JobSubmitted"><code>JobSubmitted</code> event</a>.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/dagscheduler-submitjob.png" alt="dagscheduler submitjob">
</div>
<div class="title">Figure 4. DAGScheduler.submitJob</div>
</div>
<div class="paragraph">
<p>Internally, <code>submitJob</code> does the following:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Checks whether <code>partitions</code> reference available partitions of the input <code>rdd</code>.</p>
</li>
<li>
<p>Increments <a href="#nextJobId">nextJobId</a> internal job counter.</p>
</li>
<li>
<p>Returns a 0-task <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> when the number of <code>partitions</code> is zero.</p>
</li>
<li>
<p>Posts a <code>JobSubmitted</code> event and returns a <code>JobWaiter</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>You may see a <code>IllegalArgumentException</code> thrown when the input <code>partitions</code> references partitions not in the input <code>rdd</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Attempting to access a non-existent partition: [p]. Total number of partitions: [maxPartitions]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitJob</code> is called when <a href="spark-SparkContext.adoc#submitJob"><code>SparkContext</code> submits a job</a> and <a href="#runJob"><code>DAGScheduler</code> runs a job</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitJob</code> assumes that the partitions of a RDD are indexed from 0 onwards in sequential order.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_shuffledependency_for_executionsubmitmapstage_method"><a class="anchor" href="#_submitting_shuffledependency_for_executionsubmitmapstage_method"></a><a id="submitMapStage"></a> Submitting ShuffleDependency for Execution&#8201;&#8212;&#8201;<code>submitMapStage</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitMapStage[K, V, C](
  dependency: ShuffleDependency[K, V, C],
  callback: MapOutputStatistics =&gt; Unit,
  callSite: CallSite,
  properties: Properties): JobWaiter[MapOutputStatistics]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitMapStage</code> creates a <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> (that it eventually returns) and posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#MapStageSubmitted">MapStageSubmitted</a> event to <a href="#eventProcessLoop">DAGScheduler Event Bus</a>).</p>
</div>
<div class="paragraph">
<p>Internally, <code>submitMapStage</code> increments <a href="#nextJobId"><code>nextJobId</code> internal counter</a> to get the job id.</p>
</div>
<div class="paragraph">
<p><code>submitMapStage</code> then creates a <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> (with the job id and with one artificial task that will however get completed only when the entire stage finishes).</p>
</div>
<div class="paragraph">
<p><code>submitMapStage</code> announces the map stage submission application-wide (by posting a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#MapStageSubmitted">MapStageSubmitted</a> to <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <code>MapStageSubmitted</code> holds the newly-created job id and <code>JobWaiter</code> with the input <code>dependency</code>, <code>callSite</code> and <code>properties</code> parameters.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>submitMapStage</code> returns the <code>JobWaiter</code>.</p>
</div>
<div class="paragraph">
<p>If the number of partition to compute is <code>0</code>, <code>submitMapStage</code> throws a <code>SparkException</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Can't run submitMapStage on RDD with 0 partitions</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitMapStage</code> is used when <a href="spark-SparkContext.adoc#submitMapStage"><code>SparkContext</code> submits a map stage for execution</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_stage_cancellation_from_sparkcontext_by_posting_stagecancelled_to_dagscheduler_event_buscancelstage_method"><a class="anchor" href="#_relaying_stage_cancellation_from_sparkcontext_by_posting_stagecancelled_to_dagscheduler_event_buscancelstage_method"></a><a id="cancelStage"></a> Relaying Stage Cancellation From SparkContext (by Posting StageCancelled to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>cancelStage</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelStage(stageId: Int)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelJobGroup</code> merely posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#StageCancelled">StageCancelled</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelStage</code> is used exclusively when <code>SparkContext</code> <a href="spark-SparkContext.adoc#cancelStage">cancels a stage</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_job_group_cancellation_from_sparkcontext_by_posting_jobgroupcancelled_to_dagscheduler_event_buscanceljobgroup_method"><a class="anchor" href="#_relaying_job_group_cancellation_from_sparkcontext_by_posting_jobgroupcancelled_to_dagscheduler_event_buscanceljobgroup_method"></a><a id="cancelJobGroup"></a> Relaying Job Group Cancellation From SparkContext (by Posting JobGroupCancelled to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>cancelJobGroup</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelJobGroup(groupId: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelJobGroup</code> prints the following INFO message to the logs followed by posting a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#JobGroupCancelled">JobGroupCancelled</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Asked to cancel job group [groupId]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelJobGroup</code> is used exclusively when <code>SparkContext</code> <a href="spark-SparkContext.adoc#cancelJobGroup">cancels a job group</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_all_jobs_cancellation_from_sparkcontext_by_posting_alljobscancelled_to_dagscheduler_event_buscancelalljobs_method"><a class="anchor" href="#_relaying_all_jobs_cancellation_from_sparkcontext_by_posting_alljobscancelled_to_dagscheduler_event_buscancelalljobs_method"></a><a id="cancelAllJobs"></a> Relaying All Jobs Cancellation From SparkContext (by Posting AllJobsCancelled to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>cancelAllJobs</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelAllJobs(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelAllJobs</code> merely posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#AllJobsCancelled">AllJobsCancelled</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelAllJobs</code> is used exclusively when <code>SparkContext</code> <a href="spark-SparkContext.adoc#cancelAllJobs">cancels all running or scheduled Spark jobs</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_task_started_from_tasksetmanager_by_posting_beginevent_to_dagscheduler_event_bustaskstarted_method"><a class="anchor" href="#_relaying_task_started_from_tasksetmanager_by_posting_beginevent_to_dagscheduler_event_bustaskstarted_method"></a><a id="taskStarted"></a> Relaying Task Started From TaskSetManager (by Posting BeginEvent to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>taskStarted</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">taskStarted(task: Task[_], taskInfo: TaskInfo)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>taskStarted</code> merely posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#BeginEvent">BeginEvent</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>taskStarted</code> is used exclusively when a <code>TaskSetManager</code> <a href="spark-scheduler-TaskSetManager.adoc#resourceOffer">starts a task</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_task_fetchinggetting_result_from_tasksetmanager_by_posting_gettingresultevent_to_dagscheduler_event_bustaskgettingresult_method"><a class="anchor" href="#_relaying_task_fetchinggetting_result_from_tasksetmanager_by_posting_gettingresultevent_to_dagscheduler_event_bustaskgettingresult_method"></a><a id="taskGettingResult"></a> Relaying Task Fetching/Getting Result From TaskSetManager (by Posting GettingResultEvent to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>taskGettingResult</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">taskGettingResult(taskInfo: TaskInfo)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>taskGettingResult</code> merely posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#GettingResultEvent">GettingResultEvent</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>taskGettingResult</code> is used exclusively when a <code>TaskSetManager</code> <a href="spark-scheduler-TaskSetManager.adoc#handleTaskGettingResult">gets notified about a task fetching result</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_task_end_from_tasksetmanager_by_posting_completionevent_to_dagscheduler_event_bustaskended_method"><a class="anchor" href="#_relaying_task_end_from_tasksetmanager_by_posting_completionevent_to_dagscheduler_event_bustaskended_method"></a><a id="taskEnded"></a> Relaying Task End From TaskSetManager (by Posting CompletionEvent to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>taskEnded</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">taskEnded(
  task: Task[_],
  reason: TaskEndReason,
  result: Any,
  accumUpdates: Map[Long, Any],
  taskInfo: TaskInfo,
  taskMetrics: TaskMetrics): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>taskEnded</code> simply posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#CompletionEvent">CompletionEvent</a> event to the <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read <a href="spark-executor-TaskMetrics.adoc">TaskMetrics</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>taskEnded</code> is used exclusively when <code>TaskSetManager</code> is requested to <a href="spark-scheduler-TaskSetManager.html#handleSuccessfulTask" class="page">handleSuccessfulTask</a>, <a href="spark-scheduler-TaskSetManager.html#handleFailedTask" class="page">handleFailedTask</a>, and <a href="spark-scheduler-TaskSetManager.html#executorLost" class="page">executorLost</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_taskset_failed_from_tasksetmanager_by_posting_tasksetfailed_to_dagscheduler_event_bustasksetfailed_method"><a class="anchor" href="#_relaying_taskset_failed_from_tasksetmanager_by_posting_tasksetfailed_to_dagscheduler_event_bustasksetfailed_method"></a><a id="taskSetFailed"></a> Relaying TaskSet Failed From TaskSetManager (by Posting TaskSetFailed to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>taskSetFailed</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">taskSetFailed(
  taskSet: TaskSet,
  reason: String,
  exception: Option[Throwable]): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>taskSetFailed</code> simply posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#TaskSetFailed">TaskSetFailed</a> to <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The input arguments of <code>taskSetFailed</code> are exactly the arguments of <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#TaskSetFailed">TaskSetFailed</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>taskSetFailed</code> is used exclusively when a <code>TaskSetManager</code> <a href="spark-scheduler-TaskSetManager.adoc#abort">is aborted</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_executor_lost_from_taskschedulerimpl_by_posting_executorlost_to_dagscheduler_event_busexecutorlost_method"><a class="anchor" href="#_relaying_executor_lost_from_taskschedulerimpl_by_posting_executorlost_to_dagscheduler_event_busexecutorlost_method"></a><a id="executorLost"></a> Relaying Executor Lost From TaskSchedulerImpl (by Posting ExecutorLost to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>executorLost</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">executorLost(execId: String, reason: ExecutorLossReason): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>executorLost</code> simply posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#ExecutorLost">ExecutorLost</a> event to <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>executorLost</code> is used when <code>TaskSchedulerImpl</code> <a href="spark-scheduler-TaskSchedulerImpl.adoc#statusUpdate">gets task status update</a> (and a task gets lost which is used to indicate that the executor got broken and hence should be considered lost) or <a href="spark-scheduler-TaskSchedulerImpl.adoc#executorLost">executorLost</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_executor_added_from_taskschedulerimpl_by_posting_executoradded_to_dagscheduler_event_busexecutoradded_method"><a class="anchor" href="#_relaying_executor_added_from_taskschedulerimpl_by_posting_executoradded_to_dagscheduler_event_busexecutoradded_method"></a><a id="executorAdded"></a> Relaying Executor Added From TaskSchedulerImpl (by Posting ExecutorAdded to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>executorAdded</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">executorAdded(execId: String, host: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>executorAdded</code> simply posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#ExecutorAdded">ExecutorAdded</a> event to <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>executorAdded</code> is used exclusively when <code>TaskSchedulerImpl</code> <a href="spark-scheduler-TaskSchedulerImpl.adoc#resourceOffers">is offered resources on executors</a> (and a new executor is found in the resource offers).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_relaying_job_cancellation_from_sparkcontext_or_jobwaiter_by_posting_jobcancelled_to_dagscheduler_event_buscanceljob_method"><a class="anchor" href="#_relaying_job_cancellation_from_sparkcontext_or_jobwaiter_by_posting_jobcancelled_to_dagscheduler_event_buscanceljob_method"></a><a id="cancelJob"></a> Relaying Job Cancellation From SparkContext or JobWaiter (by Posting JobCancelled to DAGScheduler Event Bus)&#8201;&#8212;&#8201;<code>cancelJob</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelJob(jobId: Int): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelJob</code> prints the following INFO message and posts a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#JobCancelled">JobCancelled</a> to <a href="#eventProcessLoop">DAGScheduler Event Bus</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO DAGScheduler: Asked to cancel job [id]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelJob</code> is used when <a href="spark-SparkContext.adoc#cancelJob">SparkContext</a> or <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> cancel a Spark job.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_or_creating_missing_direct_parent_shufflemapstages_for_shuffledependencies_of_input_rddgetorcreateparentstages_internal_method"><a class="anchor" href="#_finding_or_creating_missing_direct_parent_shufflemapstages_for_shuffledependencies_of_input_rddgetorcreateparentstages_internal_method"></a><a id="getOrCreateParentStages"></a> Finding Or Creating Missing Direct Parent ShuffleMapStages (For ShuffleDependencies of Input RDD)&#8201;&#8212;&#8201;<code>getOrCreateParentStages</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getOrCreateParentStages(rdd: RDD[_], firstJobId: Int): List[Stage]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getOrCreateParentStages</code> <a href="#getShuffleDependencies">finds all direct parent <code>ShuffleDependencies</code></a> of the input <code>rdd</code> and then <a href="#getOrCreateShuffleMapStage">finds <code>ShuffleMapStage</code> stages</a> for each <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getOrCreateParentStages</code> is used when <code>DAGScheduler</code> <a href="#createShuffleMapStage">createShuffleMapStage</a> and <a href="#createResultStage">createResultStage</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_marking_stage_finishedmarkstageasfinished_internal_method"><a class="anchor" href="#_marking_stage_finishedmarkstageasfinished_internal_method"></a><a id="markStageAsFinished"></a> Marking Stage Finished&#8201;&#8212;&#8201;<code>markStageAsFinished</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">markStageAsFinished(stage: Stage, errorMessage: Option[String] = None): Unit</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_running_jobrunjob_method"><a class="anchor" href="#_running_jobrunjob_method"></a><a id="runJob"></a> Running Job&#8201;&#8212;&#8201;<code>runJob</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">runJob[T, U](
  rdd: RDD[T],
  func: (TaskContext, Iterator[T]) =&gt; U,
  partitions: Seq[Int],
  callSite: CallSite,
  resultHandler: (Int, U) =&gt; Unit,
  properties: Properties): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runJob</code> submits an action job to the <code>DAGScheduler</code> and waits for a result.</p>
</div>
<div class="paragraph">
<p>Internally, <code>runJob</code> executes <a href="#submitJob">submitJob</a> and then waits until a result comes using <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a>.</p>
</div>
<div class="paragraph">
<p>When the job succeeds, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Job [jobId] finished: [callSite], took [time] s</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the job fails, you should see the following INFO message in the logs and the exception (that led to the failure) is thrown.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Job [jobId] failed: [callSite], took [time] s</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runJob</code> is used when <a href="spark-SparkContext.adoc#runJob"><code>SparkContext</code> runs a job</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_or_creating_new_shufflemapstages_for_shuffledependencygetorcreateshufflemapstage_internal_method"><a class="anchor" href="#_finding_or_creating_new_shufflemapstages_for_shuffledependencygetorcreateshufflemapstage_internal_method"></a><a id="getOrCreateShuffleMapStage"></a> Finding or Creating New ShuffleMapStages for ShuffleDependency&#8201;&#8212;&#8201;<code>getOrCreateShuffleMapStage</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getOrCreateShuffleMapStage(
  shuffleDep: ShuffleDependency[_, _, _],
  firstJobId: Int): ShuffleMapStage</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getOrCreateShuffleMapStage</code> finds or creates the <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a> for the input <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>getOrCreateShuffleMapStage</code> finds the <code>ShuffleDependency</code> in <a href="#shuffleIdToMapStage"><code>shuffleIdToMapStage</code> internal registry</a> and returns one when found.</p>
</div>
<div class="paragraph">
<p>If no <code>ShuffleDependency</code> was available, <code>getOrCreateShuffleMapStage</code> <a href="#getMissingAncestorShuffleDependencies">finds all the missing shuffle dependencies</a> and <a href="#createShuffleMapStage">creates corresponding <code>ShuffleMapStage</code> stages</a> (including one for the input <code>shuffleDep</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
All the new <code>ShuffleMapStage</code> stages are associated with the input <code>firstJobId</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getOrCreateShuffleMapStage</code> is used when <code>DAGScheduler</code> <a href="#getOrCreateParentStages">finds or creates missing direct parent ShuffleMapStages</a> (for ShuffleDependencies of given RDD), <a href="#getMissingParentStages">getMissingParentStages</a> (for <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependencies</a>), <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleMapStageSubmitted">is notified that <code>ShuffleDependency</code> was submitted</a>, and <a href="#stageDependsOn">checks if a stage depends on another</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_creating_shufflemapstage_for_shuffledependency_copying_shuffle_map_output_locations_from_previous_jobscreateshufflemapstage_method"><a class="anchor" href="#_creating_shufflemapstage_for_shuffledependency_copying_shuffle_map_output_locations_from_previous_jobscreateshufflemapstage_method"></a><a id="createShuffleMapStage"></a> Creating ShuffleMapStage for ShuffleDependency (Copying Shuffle Map Output Locations From Previous Jobs)&#8201;&#8212;&#8201;<code>createShuffleMapStage</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">createShuffleMapStage(
  shuffleDep: ShuffleDependency[_, _, _],
  jobId: Int): ShuffleMapStage</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>createShuffleMapStage</code> creates a <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a> for the input <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> and <code>jobId</code> (of a <a href="spark-scheduler-ActiveJob.adoc">ActiveJob</a>) possibly copying shuffle map output locations from previous jobs to avoid recomputing records.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When a <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a> is created, the <code>id</code> is generated (using <a href="#nextStageId"><code>nextStageId</code> internal counter</a>), <code>rdd</code> is from <code>ShuffleDependency</code>, <code>numTasks</code> is the number of partitions in the RDD, all <code>parents</code> are looked up (and possibly created), the <code>jobId</code> is given, <code>callSite</code> is the <code>creationSite</code> of the RDD, and <code>shuffleDep</code> is the input <code>ShuffleDependency</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>createShuffleMapStage</code> first <a href="#getOrCreateParentStages">finds or creates missing parent <code>ShuffleMapStage</code> stages of the associated RDD</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> is associated with exactly one <code>RDD[Product2[K, V]]</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>createShuffleMapStage</code> <a href="spark-scheduler-ShuffleMapStage.adoc#creating-instance">creates a <code>ShuffleMapStage</code></a> (with the stage id from <a href="#nextStageId"><code>nextStageId</code> internal counter</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The RDD of the new <code>ShuffleMapStage</code> is from the input <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>createShuffleMapStage</code> registers the <code>ShuffleMapStage</code> in <a href="#stageIdToStage">stageIdToStage</a> and <a href="#shuffleIdToMapStage">shuffleIdToMapStage</a> internal registries.</p>
</div>
<div class="paragraph">
<p><code>createShuffleMapStage</code> calls <a href="#updateJobIdStageIdMaps">updateJobIdStageIdMaps</a>.</p>
</div>
<div class="paragraph">
<p>If <a href="spark-service-MapOutputTrackerMaster.adoc#containsShuffle"><code>MapOutputTrackerMaster</code> tracks the input <code>ShuffleDependency</code></a> (because other jobs have already computed it), <code>createShuffleMapStage</code> <a href="spark-service-MapOutputTrackerMaster.adoc#getSerializedMapOutputStatuses">requests the serialized <code>ShuffleMapStage</code> outputs</a>, <a href="spark-service-MapOutputTracker.adoc#deserializeMapStatuses">deserializes them</a> and <a href="spark-scheduler-ShuffleMapStage.adoc#addOutputLoc">registers with the new <code>ShuffleMapStage</code></a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-service-MapOutputTrackerMaster.adoc">MapOutputTrackerMaster</a> was defined when <a href="#creating-instance"><code>DAGScheduler</code> was created</a>.
</td>
</tr>
</table>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/DAGScheduler-MapOutputTrackerMaster-containsShuffle.png" alt="DAGScheduler MapOutputTrackerMaster containsShuffle">
</div>
<div class="title">Figure 5. <code>DAGScheduler</code> Asks <code>MapOutputTrackerMaster</code> Whether Shuffle Map Output Is Already Tracked</div>
</div>
<div class="paragraph">
<p>If however <code>MapOutputTrackerMaster</code> does not track the input <code>ShuffleDependency</code>, you should see the following INFO message in the logs and <code>createShuffleMapStage</code> <a href="spark-service-MapOutputTrackerMaster.adoc#registerShuffle">registers the <code>ShuffleDependency</code> with <code>MapOutputTrackerMaster</code></a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Registering RDD [id] ([creationSite])</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>createShuffleMapStage</code> returns the new <code>ShuffleMapStage</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>createShuffleMapStage</code> is executed only when <code>DAGScheduler</code> <a href="#getOrCreateShuffleMapStage">finds or creates parent <code>ShuffleMapStage</code> stages for a <code>ShuffleDependency</code></a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_clearing_cache_of_rdd_block_locationsclearcachelocs_internal_method"><a class="anchor" href="#_clearing_cache_of_rdd_block_locationsclearcachelocs_internal_method"></a><a id="clearCacheLocs"></a> Clearing Cache of RDD Block Locations&#8201;&#8212;&#8201;<code>clearCacheLocs</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">clearCacheLocs(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>clearCacheLocs</code> clears the <a href="#cacheLocs">internal registry of the partition locations per RDD</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>DAGScheduler</code> clears the cache while <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#resubmitFailedStages">resubmitting failed stages</a>, and as a result of <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#JobSubmitted">JobSubmitted</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#MapStageSubmitted">MapStageSubmitted</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#CompletionEvent">CompletionEvent</a>, <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#ExecutorLost">ExecutorLost</a> events.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_missing_shuffledependencies_for_rddgetmissingancestorshuffledependencies_internal_method"><a class="anchor" href="#_finding_missing_shuffledependencies_for_rddgetmissingancestorshuffledependencies_internal_method"></a><a id="getMissingAncestorShuffleDependencies"></a> Finding Missing ShuffleDependencies For RDD&#8201;&#8212;&#8201;<code>getMissingAncestorShuffleDependencies</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getMissingAncestorShuffleDependencies(rdd: RDD[_]): Stack[ShuffleDependency[_, _, _]]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getMissingAncestorShuffleDependencies</code> finds all missing <a href="spark-rdd-ShuffleDependency.adoc">shuffle dependencies</a> for the given <a href="spark-rdd.adoc">RDD</a> traversing its <a href="spark-rdd-lineage.adoc">dependency chain</a> (aka <em>RDD lineage</em>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <strong>missing shuffle dependency</strong> of a RDD is a dependency not registered in <a href="#shuffleIdToMapStage"><code>shuffleIdToMapStage</code> internal registry</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>getMissingAncestorShuffleDependencies</code> <a href="#getShuffleDependencies">finds direct parent shuffle dependencies</a> of the input RDD and collects the ones that are not registered in <a href="#shuffleIdToMapStage"><code>shuffleIdToMapStage</code> internal registry</a>. It repeats the process for the RDDs of the parent shuffle dependencies.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getMissingAncestorShuffleDependencies</code> is used when <code>DAGScheduler</code> <a href="#getOrCreateShuffleMapStage">finds all <code>ShuffleMapStage</code> stages for a <code>ShuffleDependency</code></a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_direct_parent_shuffle_dependencies_of_rddgetshuffledependencies_internal_method"><a class="anchor" href="#_finding_direct_parent_shuffle_dependencies_of_rddgetshuffledependencies_internal_method"></a><a id="getShuffleDependencies"></a> Finding Direct Parent Shuffle Dependencies of RDD&#8201;&#8212;&#8201;<code>getShuffleDependencies</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getShuffleDependencies(rdd: RDD[_]): HashSet[ShuffleDependency[_, _, _]]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getShuffleDependencies</code> finds direct parent <a href="spark-rdd-ShuffleDependency.adoc">shuffle dependencies</a> for the given <a href="spark-rdd.adoc">RDD</a>.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-DAGScheduler-getShuffleDependencies.png" alt="spark DAGScheduler getShuffleDependencies">
</div>
<div class="title">Figure 6. getShuffleDependencies Finds Direct Parent ShuffleDependencies (shuffle1 and shuffle2)</div>
</div>
<div class="paragraph">
<p>Internally, <code>getShuffleDependencies</code> takes the direct <a href="spark-rdd.adoc#dependencies">shuffle dependencies of the input RDD</a> and direct shuffle dependencies of all the parent non-<code>ShuffleDependencies</code> in the <a href="spark-rdd-lineage.adoc">dependency chain</a> (aka <em>RDD lineage</em>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getShuffleDependencies</code> is used when <code>DAGScheduler</code> <a href="#getOrCreateParentStages">finds or creates missing direct parent ShuffleMapStages</a> (for ShuffleDependencies of given RDD) and <a href="#getMissingAncestorShuffleDependencies">finds all missing shuffle dependencies for a given RDD</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_failing_job_and_independent_single_job_stagesfailjobandindependentstages_internal_method"><a class="anchor" href="#_failing_job_and_independent_single_job_stagesfailjobandindependentstages_internal_method"></a><a id="failJobAndIndependentStages"></a> Failing Job and Independent Single-Job Stages&#8201;&#8212;&#8201;<code>failJobAndIndependentStages</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">failJobAndIndependentStages(
  job: ActiveJob,
  failureReason: String,
  exception: Option[Throwable] = None): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p>The internal <code>failJobAndIndependentStages</code> method fails the input <code>job</code> and all the stages that are only used by the job.</p>
</div>
<div class="paragraph">
<p>Internally, <code>failJobAndIndependentStages</code> uses <a href="#jobIdToStageIds"><code>jobIdToStageIds</code> internal registry</a> to look up the stages registered for the job.</p>
</div>
<div class="paragraph">
<p>If no stages could be found, you should see the following ERROR message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR No stages registered for job [id]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Otherwise, for every stage, <code>failJobAndIndependentStages</code> finds the job ids the stage belongs to.</p>
</div>
<div class="paragraph">
<p>If no stages could be found or the job is not referenced by the stages, you should see the following ERROR message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR Job [id] not registered for stage [id] even though that stage was registered for the job</code></pre>
</div>
</div>
<div class="paragraph">
<p>Only when there is exactly one job registered for the stage and the stage is in RUNNING state (in <code>runningStages</code> internal registry), <a href="spark-scheduler-TaskScheduler.adoc#contract"><code>TaskScheduler</code> is requested to cancel the stage&#8217;s tasks</a> and <a href="#markStageAsFinished">marks the stage finished</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>failJobAndIndependentStages</code> is called from <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleJobCancellation">handleJobCancellation</a> and <code>abortStage</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>failJobAndIndependentStages</code> uses <a href="#jobIdToStageIds">jobIdToStageIds</a>, <a href="#stageIdToStage">stageIdToStage</a>, and <a href="#runningStages">runningStages</a> internal registries.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_aborting_stageabortstage_internal_method"><a class="anchor" href="#_aborting_stageabortstage_internal_method"></a><a id="abortStage"></a> Aborting Stage&#8201;&#8212;&#8201;<code>abortStage</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">abortStage(
  failedStage: Stage,
  reason: String,
  exception: Option[Throwable]): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>abortStage</code> is an internal method that finds all the active jobs that depend on the <code>failedStage</code> stage and fails them.</p>
</div>
<div class="paragraph">
<p>Internally, <code>abortStage</code> looks the <code>failedStage</code> stage up in the internal <a href="#stageIdToStage">stageIdToStage</a> registry and exits if there the stage was not registered earlier.</p>
</div>
<div class="paragraph">
<p>If it was, <code>abortStage</code> finds all the active jobs (in the internal <a href="#activeJobs">activeJobs</a> registry) with the <a href="#stageDependsOn">final stage depending on the <code>failedStage</code> stage</a>.</p>
</div>
<div class="paragraph">
<p>At this time, the <code>completionTime</code> property (of the failed stage&#8217;s <a href="spark-scheduler-StageInfo.adoc">StageInfo</a>) is assigned to the current time (millis).</p>
</div>
<div class="paragraph">
<p>All the active jobs that depend on the failed stage (as calculated above) and the stages that do not belong to other jobs (aka <em>independent stages</em>) are <a href="#failJobAndIndependentStages">failed</a> (with the failure reason being "Job aborted due to stage failure: [reason]" and the input <code>exception</code>).</p>
</div>
<div class="paragraph">
<p>If there are no jobs depending on the failed stage, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Ignoring failure of [failedStage] because all jobs depending on it are done</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>abortStage</code> is used to <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskSetFailed">handle <code>TaskSetFailed</code> event</a>, when <a href="#submitStage">submitting a stage with no active job</a>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_checking_out_stage_dependency_on_given_stagestagedependson_method"><a class="anchor" href="#_checking_out_stage_dependency_on_given_stagestagedependson_method"></a><a id="stageDependsOn"></a> Checking Out Stage Dependency on Given Stage&#8201;&#8212;&#8201;<code>stageDependsOn</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">stageDependsOn(stage: Stage, target: Stage): Boolean</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>stageDependsOn</code> compares two stages and returns whether the <code>stage</code> depends on <code>target</code> stage (i.e. <code>true</code>) or not (i.e. <code>false</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A stage <code>A</code> depends on stage <code>B</code> if <code>B</code> is among the ancestors of <code>A</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>stageDependsOn</code> walks through the graph of RDDs of the input <code>stage</code>. For every RDD in the RDD&#8217;s dependencies (using <code>RDD.dependencies</code>) <code>stageDependsOn</code> adds the RDD of a <a href="spark-rdd-NarrowDependency.adoc">NarrowDependency</a> to a stack of RDDs to visit while for a <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> it <a href="#getOrCreateShuffleMapStage">finds <code>ShuffleMapStage</code> stages for a <code>ShuffleDependency</code></a> for the dependency and the <code>stage</code>'s first job id that it later adds to a stack of RDDs to visit if the map stage is ready, i.e. all the partitions have shuffle outputs.</p>
</div>
<div class="paragraph">
<p>After all the RDDs of the input <code>stage</code> are visited, <code>stageDependsOn</code> checks if the <code>target</code>'s RDD is among the RDDs of the <code>stage</code>, i.e. whether the <code>stage</code> depends on <code>target</code> stage.</p>
</div>
</div>
<div class="sect2">
<h3 id="_dag_scheduler_event_loopdagscheduler_event_bus"><a class="anchor" href="#_dag_scheduler_event_loopdagscheduler_event_bus"></a><a id="event-loop"></a><a id="eventProcessLoop"></a> dag-scheduler-event-loop&#8201;&#8212;&#8201;DAGScheduler Event Bus</h3>
<div class="paragraph">
<p><code>eventProcessLoop</code> is <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc">DAGScheduler&#8217;s event bus</a> to which Spark (by <a href="#submitJob">submitJob</a>) posts jobs to schedule their execution. Later on, <a href="spark-scheduler-TaskSetManager.adoc">TaskSetManager</a> talks back to <code>DAGScheduler</code> to inform about the status of the tasks using the same "communication channel".</p>
</div>
<div class="paragraph">
<p>It allows Spark to release the current thread when posting happens and let the event loop handle events on a separate thread - asynchronously.</p>
</div>
<div class="paragraph">
<p>&#8230;&#8203;IMAGE&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME statistics? <code>MapOutputStatistics</code>?
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_waiting_child_stages_for_executionsubmitwaitingchildstages_internal_method"><a class="anchor" href="#_submitting_waiting_child_stages_for_executionsubmitwaitingchildstages_internal_method"></a><a id="submitWaitingChildStages"></a> Submitting Waiting Child Stages for Execution&#8201;&#8212;&#8201;<code>submitWaitingChildStages</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitWaitingChildStages(parent: Stage): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitWaitingChildStages</code> submits for execution all waiting stages for which the input <code>parent</code> <a href="spark-scheduler-Stage.adoc">Stage</a> is the direct parent.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<strong>Waiting stages</strong> are the stages registered in <a href="#waitingStages"><code>waitingStages</code> internal registry</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When executed, you should see the following <code>TRACE</code> messages in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>TRACE DAGScheduler: Checking if any dependencies of [parent] are now runnable
TRACE DAGScheduler: running: [runningStages]
TRACE DAGScheduler: waiting: [waitingStages]
TRACE DAGScheduler: failed: [failedStages]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitWaitingChildStages</code> finds child stages of the input <code>parent</code> stage, removes them from <code>waitingStages</code> internal registry, and <a href="#submitStage">submits</a> one by one sorted by their job ids.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitWaitingChildStages</code> is executed when <code>DAGScheduler</code> <a href="#submitMissingTasks">submits missing tasks for stage</a> and <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-Success-ShuffleMapTask">handles successful <code>ShuffleMapTask</code> completion</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_stage_or_its_missing_parents_for_executionsubmitstage_internal_method"><a class="anchor" href="#_submitting_stage_or_its_missing_parents_for_executionsubmitstage_internal_method"></a><a id="submitStage"></a> Submitting Stage or Its Missing Parents for Execution&#8201;&#8212;&#8201;<code>submitStage</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitStage(stage: Stage): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitStage</code> is an internal method that <code>DAGScheduler</code> uses to submit the input <code>stage</code> or its missing parents (if there any stages not computed yet before the input <code>stage</code> could).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitStage</code> is also used to <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#resubmitFailedStages">resubmit failed stages</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>submitStage</code> recursively submits any missing parents of the <code>stage</code>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>submitStage</code> first finds the earliest-created job id that needs the <code>stage</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A stage itself tracks the jobs (their ids) it belongs to (using the internal <code>jobIds</code> registry).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The following steps depend on whether there is a job or not.</p>
</div>
<div class="paragraph">
<p>If there are no jobs that require the <code>stage</code>, <code>submitStage</code> <a href="#abortStage">aborts it</a> with the reason:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>No active job for stage [id]</code></pre>
</div>
</div>
<div class="paragraph">
<p>If however there is a job for the <code>stage</code>, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: submitStage([stage])</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitStage</code> checks the status of the <code>stage</code> and continues when it was not recorded in <a href="#waitingStages">waiting</a>, <a href="#runningStages">running</a> or <a href="#failedStages">failed</a> internal registries. It simply exits otherwise.</p>
</div>
<div class="paragraph">
<p>With the <code>stage</code> ready for submission, <code>submitStage</code> calculates the <a href="#getMissingParentStages">list of missing parent stages of the <code>stage</code></a> (sorted by their job ids). You should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: missing: [missing]</code></pre>
</div>
</div>
<div class="paragraph">
<p>When the <code>stage</code> has no parent stages missing, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO DAGScheduler: Submitting [stage] ([stage.rdd]), which has no missing parents</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitStage</code> <a href="#submitMissingTasks">submits the <code>stage</code></a> (with the earliest-created job id) and finishes.</p>
</div>
<div class="paragraph">
<p>If however there are missing parent stages for the <code>stage</code>, <code>submitStage</code> <a href="#submitStage">submits all the parent stages</a>, and the <code>stage</code> is recorded in the internal <a href="#waitingStages">waitingStages</a> registry.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>submitStage</code> is used when <code>DAGScheduler</code> is requested for the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#resubmitFailedStages">resubmitFailedStages</a></p>
</li>
<li>
<p><a href="#submitWaitingChildStages">submitWaitingChildStages</a></p>
</li>
<li>
<p><a href="#handleJobSubmitted">handleJobSubmitted</a>, <a href="#handleMapStageSubmitted">handleMapStageSubmitted</a>, and <a href="#handleTaskCompletion">handleTaskCompletion</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_handlejobsubmitted_method"><a class="anchor" href="#_handlejobsubmitted_method"></a><a id="handleJobSubmitted"></a> <code>handleJobSubmitted</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">handleJobSubmitted(
  jobId: Int,
  finalRDD: RDD[_],
  func: (TaskContext, Iterator[_]) =&gt; _,
  partitions: Array[Int],
  callSite: CallSite,
  listener: JobListener,
  properties: Properties): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>handleJobSubmitted</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>handleJobSubmitted</code> is used when&#8230;&#8203;FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_handlemapstagesubmitted_method"><a class="anchor" href="#_handlemapstagesubmitted_method"></a><a id="handleMapStageSubmitted"></a> <code>handleMapStageSubmitted</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">handleMapStageSubmitted(
  jobId: Int,
  dependency: ShuffleDependency[_, _, _],
  callSite: CallSite,
  listener: JobListener,
  properties: Properties): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>handleMapStageSubmitted</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>handleMapStageSubmitted</code> is used when&#8230;&#8203;FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_handling_task_completion_completioneventhandletaskcompletion_method"><a class="anchor" href="#_handling_task_completion_completioneventhandletaskcompletion_method"></a><a id="handleTaskCompletion"></a> Handling Task Completion (CompletionEvent)&#8201;&#8212;&#8201;<code>handleTaskCompletion</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">handleTaskCompletion(event: CompletionEvent): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>handleTaskCompletion</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>handleTaskCompletion</code> is used exclusively when <code>DAGSchedulerEventProcessLoop</code> is requested to <a href="spark-scheduler-DAGSchedulerEventProcessLoop.html#CompletionEvent" class="page">handle a CompletionEvent</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_fault_recovery_stage_attempts"><a class="anchor" href="#_fault_recovery_stage_attempts"></a><a id="stage-attempts"></a> Fault recovery - stage attempts</h3>
<div class="paragraph">
<p>A single stage can be re-executed in multiple <strong>attempts</strong> due to fault recovery. The number of attempts is configured (FIXME).</p>
</div>
<div class="paragraph">
<p>If <code>TaskScheduler</code> reports that a task failed because a map output file from a previous stage was lost, the <code>DAGScheduler</code> resubmits the lost stage. This is detected through a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-FetchFailed"><code>CompletionEvent</code> with <code>FetchFailed</code></a>, or an <a href="#ExecutorLost">ExecutorLost</a> event. <code>DAGScheduler</code> will wait a small amount of time to see whether other nodes or tasks fail, then resubmit <code>TaskSets</code> for any lost stage(s) that compute the missing tasks.</p>
</div>
<div class="paragraph">
<p>Please note that tasks from the old attempts of a stage could still be running.</p>
</div>
<div class="paragraph">
<p>A stage object tracks multiple <a href="spark-scheduler-StageInfo.adoc">StageInfo</a> objects to pass to Spark listeners or the web UI.</p>
</div>
<div class="paragraph">
<p>The latest <code>StageInfo</code> for the most recent attempt for a stage is accessible through <code>latestInfo</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_preferred_locations"><a class="anchor" href="#_preferred_locations"></a><a id="preferred-locations"></a> Preferred Locations</h3>
<div class="paragraph">
<p><code>DAGScheduler</code> computes where to run each task in a stage based on the <a href="spark-rdd.adoc#getPreferredLocations">preferred locations of its underlying RDDs</a>, or <a href="#getCacheLocs">the location of cached or shuffle data</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_adaptive_query_planning_adaptive_scheduling"><a class="anchor" href="#_adaptive_query_planning_adaptive_scheduling"></a><a id="adaptive-query-planning"></a> Adaptive Query Planning / Adaptive Scheduling</h3>
<div class="paragraph">
<p>See <a href="https://issues.apache.org/jira/browse/SPARK-9850">SPARK-9850 Adaptive execution in Spark</a> for the design document. The work is currently in progress.</p>
</div>
<div class="paragraph">
<p><a href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/DAGScheduler.scala#L661">DAGScheduler.submitMapStage</a> method is used for adaptive query planning, to run map stages and look at statistics about their outputs before submitting downstream stages.</p>
</div>
</div>
<div class="sect2">
<h3 id="_scheduledexecutorservice_daemon_services"><a class="anchor" href="#_scheduledexecutorservice_daemon_services"></a>ScheduledExecutorService daemon services</h3>
<div class="paragraph">
<p>DAGScheduler uses the following ScheduledThreadPoolExecutors (with the policy of removing cancelled tasks from a work queue at time of cancellation):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>dag-scheduler-message</code> - a daemon thread pool using <code>j.u.c.ScheduledThreadPoolExecutor</code> with core pool size <code>1</code>. It is used to post a <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#ResubmitFailedStages">ResubmitFailedStages</a> event when <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-FetchFailed"><code>FetchFailed</code> is reported</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>They are created using <code>ThreadUtils.newDaemonSingleThreadScheduledExecutor</code> method that uses Guava DSL to instantiate a ThreadFactory.</p>
</div>
</div>
<div class="sect2">
<h3 id="_finding_missing_parent_shufflemapstages_for_stagegetmissingparentstages_internal_method"><a class="anchor" href="#_finding_missing_parent_shufflemapstages_for_stagegetmissingparentstages_internal_method"></a><a id="getMissingParentStages"></a> Finding Missing Parent ShuffleMapStages For Stage&#8201;&#8212;&#8201;<code>getMissingParentStages</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getMissingParentStages(stage: Stage): List[Stage]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getMissingParentStages</code> finds missing parent <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a>s in the dependency graph of the input <code>stage</code> (using the <a href="https://en.wikipedia.org/wiki/Breadth-first_search">breadth-first search algorithm</a>).</p>
</div>
<div class="paragraph">
<p>Internally, <code>getMissingParentStages</code> starts with the <code>stage</code>'s RDD and walks up the tree of all parent RDDs to find <a href="#getCacheLocs">uncached partitions</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <code>Stage</code> tracks the associated RDD using <a href="spark-scheduler-Stage.adoc#rdd"><code>rdd</code> property</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
An <strong>uncached partition</strong> of a RDD is a partition that has <code>Nil</code> in the <a href="#cacheLocs">internal registry of partition locations per RDD</a> (which results in no RDD blocks in any of the active <a href="spark-BlockManager.adoc">BlockManager</a>s on executors).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>getMissingParentStages</code> traverses the <a href="spark-rdd.adoc#dependencies">parent dependencies of the RDD</a> and acts according to their type, i.e. <a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> or <a href="spark-rdd-NarrowDependency.adoc">NarrowDependency</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> and <a href="spark-rdd-NarrowDependency.adoc">NarrowDependency</a> are the main top-level <a href="spark-rdd-Dependency.adoc">Dependencies</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For each <code>NarrowDependency</code>, <code>getMissingParentStages</code> simply marks the corresponding RDD to visit and moves on to a next dependency of a RDD or works on another unvisited parent RDD.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-rdd-NarrowDependency.adoc">NarrowDependency</a> is a RDD dependency that allows for pipelined execution.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>getMissingParentStages</code> focuses on <code>ShuffleDependency</code> dependencies.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-rdd-ShuffleDependency.adoc">ShuffleDependency</a> is a RDD dependency that represents a dependency on the output of a <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a>, i.e. <strong>shuffle map stage</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For each <code>ShuffleDependency</code>, <code>getMissingParentStages</code> <a href="#getOrCreateShuffleMapStage">finds <code>ShuffleMapStage</code> stages</a>. If the <code>ShuffleMapStage</code> is not <em>available</em>, it is added to the set of missing (map) stages.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <code>ShuffleMapStage</code> is <strong>available</strong> when all its partitions are computed, i.e. results are available (as blocks).
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME&#8230;&#8203;IMAGE with ShuffleDependencies queried
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getMissingParentStages</code> is used when <code>DAGScheduler</code> <a href="#submitStage">submits missing parent <code>ShuffleMapStage</code>s (of a stage)</a> and handles <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleJobSubmitted">JobSubmitted</a> and <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleMapStageSubmitted">MapStageSubmitted</a> events.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_missing_tasks_of_stage_in_a_spark_jobsubmitmissingtasks_internal_method"><a class="anchor" href="#_submitting_missing_tasks_of_stage_in_a_spark_jobsubmitmissingtasks_internal_method"></a><a id="submitMissingTasks"></a> Submitting Missing Tasks of Stage (in a Spark Job)&#8201;&#8212;&#8201;<code>submitMissingTasks</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitMissingTasks(stage: Stage, jobId: Int): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When executed, you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: submitMissingTasks([stage])</code></pre>
</div>
</div>
<div class="paragraph">
<p>The input <code>stage</code>'s <a href="spark-scheduler-Stage.adoc#pendingPartitions"><code>pendingPartitions</code> internal field</a> is cleared (it is later filled out with the partitions to run tasks for).</p>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> requests the <code>stage</code> for <a href="spark-scheduler-Stage.adoc#findMissingPartitions">missing partitions</a>, i.e. the indices of the partitions to compute.</p>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> marks the <code>stage</code> as running (i.e. adds it to <a href="#runningStages">runningStages</a> internal registry).</p>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> <a href="spark-service-outputcommitcoordinator.adoc#stageStart">notifies <code>OutputCommitCoordinator</code> that the stage is started</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The input <code>maxPartitionId</code> argument handed over to <a href="spark-service-outputcommitcoordinator.adoc#stageStart">OutputCommitCoordinator</a> depends on the type of the stage, i.e. <code>ShuffleMapStage</code> or <code>ResultStage</code>. <code>ShuffleMapStage</code> tracks the number of partitions itself (as <code>numPartitions</code> property) while <code>ResultStage</code> uses the internal <code>RDD</code> to find out the number.
</td>
</tr>
</table>
</div>
<div id="submitMissingTasks-taskIdToLocations" class="paragraph">
<p>For the missing partitions, <code>submitMissingTasks</code> computes their <strong>task locality preferences</strong>, i.e. pairs of missing partition ids and <a href="#getPreferredLocs">their task locality information</a>.
HERE
NOTE: The locality information of a RDD is called <strong>preferred locations</strong>.</p>
</div>
<div class="paragraph">
<p>In case of <em>non-fatal</em> exceptions at this time (while getting the locality information), <code>submitMissingTasks</code> <a href="spark-scheduler-Stage.adoc#makeNewStageAttempt">creates a new stage attempt</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A stage attempt is an internal property of a stage.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Despite the failure to submit any tasks, <code>submitMissingTasks</code> does announce that at least there was an attempt on <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> by posting a <a href="spark-scheduler-SparkListener.adoc#SparkListenerStageSubmitted">SparkListenerStageSubmitted</a> message.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spark application&#8217;s <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> is given when <a href="#creating-instance"><code>DAGScheduler</code> is created</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> then <a href="#abortStage">aborts the stage</a> (with the reason being "Task creation failed" followed by the exception).</p>
</div>
<div class="paragraph">
<p>The <code>stage</code> is removed from the internal <a href="#runningStages"><code>runningStages</code> collection of stages</a> and <code>submitMissingTasks</code> exits.</p>
</div>
<div class="paragraph">
<p>When no exception was thrown (while computing the locality information for tasks), <code>submitMissingTasks</code> <a href="spark-scheduler-Stage.adoc#makeNewStageAttempt">creates a new stage attempt</a> and announces it on <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> by posting a <a href="spark-scheduler-SparkListener.adoc#SparkListenerStageSubmitted">SparkListenerStageSubmitted</a> message.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Yes, that <em>is</em> correct. Whether there was a task submission failure or not, <code>submitMissingTasks</code> creates a new stage attempt and posts a <code>SparkListenerStageSubmitted</code>. That makes sense, <em>doesn&#8217;t it?</em>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>At that time, <code>submitMissingTasks</code> serializes the RDD (of the stage for which tasks are submitted for) and, depending on the type of the stage, the <a href="spark-scheduler-ShuffleMapStage.adoc#shuffleDep"><code>ShuffleDependency</code> (for <code>ShuffleMapStage</code>)</a> or the <a href="spark-scheduler-ResultStage.adoc#func">function (for <code>ResultStage</code>)</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitMissingTasks</code> uses a closure <code>Serializer</code> that <a href="#creating-instance"><code>DAGScheduler</code> creates for the entire lifetime when it is created</a>. The closure serializer is available through <a href="spark-SparkEnv.adoc#closureSerializer">SparkEnv</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The serialized so-called <em>task binary bytes</em> are <a href="spark-SparkContext.adoc#broadcast">"wrapped" as a broadcast variable</a> (to make it available for executors to execute later on).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
That exact moment should make clear how important <a href="spark-broadcast.adoc">broadcast variables</a> are for Spark itself that you, a Spark developer, can use, too, to distribute data across the nodes in a Spark application in a very efficient way.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Any <code>NotSerializableException</code> exceptions lead to <a href="#abortStage">aborting the stage</a> (with the reason being "Task not serializable: [exception]") and removing the stage from the <a href="#runningStages">internal <code>runningStages</code> collection of stages</a>. <code>submitMissingTasks</code> exits.</p>
</div>
<div class="paragraph">
<p>Any <em>non-fatal</em> exceptions lead to <a href="#abortStage">aborting the stage</a> (with the reason being "Task serialization failed" followed by the exception) and removing the stage from the <a href="#runningStages">internal <code>runningStages</code> collection of stages</a>. <code>submitMissingTasks</code> exits.</p>
</div>
<div class="paragraph">
<p>With no exceptions along the way, <code>submitMissingTasks</code> computes a collection of <a href="spark-scheduler-Task.adoc">tasks</a> to execute for the missing partitions (of the <code>stage</code>).</p>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> creates a <a href="spark-scheduler-ShuffleMapTask.adoc">ShuffleMapTask</a> or <a href="spark-scheduler-ResultTask.adoc">ResultTask</a> for every missing partition of the <code>stage</code> being <a href="spark-scheduler-ShuffleMapStage.adoc">ShuffleMapStage</a> or <a href="spark-scheduler-ResultStage.adoc">ResultStage</a>, respectively. <code>submitMissingTasks</code> uses the preferred locations (computed earlier) per partition.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Image with creating tasks for partitions in the stage.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Any <em>non-fatal</em> exceptions lead to <a href="#abortStage">aborting the stage</a> (with the reason being "Task creation failed" followed by the exception) and removing the stage from the <a href="#runningStages">internal <code>runningStages</code> collection of stages</a>. <code>submitMissingTasks</code> exits.</p>
</div>
<div class="paragraph">
<p>If there are tasks to submit for execution (i.e. there are missing partitions in the stage), you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO DAGScheduler: Submitting [size] missing tasks from [stage] ([rdd])</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> records the partitions (of the tasks) in the <code>stage</code>'s <a href="spark-scheduler-Stage.adoc#pendingPartitions"><code>pendingPartitions</code> property</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>pendingPartitions</code> property of the <code>stage</code> was cleared when <code>submitMissingTasks</code> started.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: New pending partitions: [pendingPartitions]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> <a href="spark-scheduler-TaskScheduler.adoc#submitTasks">submits the tasks to <code>TaskScheduler</code> for execution</a> (with the id of the <code>stage</code>, attempt id, the input <code>jobId</code>, and the properties of the <code>ActiveJob</code> with <code>jobId</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <code>TaskScheduler</code> was given when <a href="#creating-instance"><code>DAGScheduler</code> was created</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME What are the <code>ActiveJob</code> properties for? Where are they used?
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>submitMissingTasks</code> records the <a href="spark-scheduler-Stage.adoc#latestInfo">submission time in the stage&#8217;s <code>StageInfo</code></a> and exits.</p>
</div>
<div class="paragraph">
<p>If however there are no tasks to submit for execution, <code>submitMissingTasks</code> <a href="#markStageAsFinished">marks the stage as finished</a> (with no <code>errorMessage</code>).</p>
</div>
<div class="paragraph">
<p>You should see a DEBUG message that varies per the type of the input <code>stage</code> which are:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: Stage [stage] is actually done; (available: [isAvailable],available outputs: [numAvailableOutputs],partitions: [numPartitions])</code></pre>
</div>
</div>
<div class="paragraph">
<p>or</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG DAGScheduler: Stage [stage] is actually done; (partitions: [numPartitions])</code></pre>
</div>
</div>
<div class="paragraph">
<p>for <code>ShuffleMapStage</code> and <code>ResultStage</code>, respectively.</p>
</div>
<div class="paragraph">
<p>In the end, with no tasks to submit for execution, <code>submitMissingTasks</code> <a href="#submitWaitingChildStages">submits waiting child stages for execution</a> and exits.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitMissingTasks</code> is used exclusively when <code>DAGScheduler</code> is requested to <a href="#submitStage">submit a stage or its missing parents for execution</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_computing_preferred_locations_for_missing_partitionsgetpreferredlocs_method"><a class="anchor" href="#_computing_preferred_locations_for_missing_partitionsgetpreferredlocs_method"></a><a id="getPreferredLocs"></a> Computing Preferred Locations for Missing Partitions&#8201;&#8212;&#8201;<code>getPreferredLocs</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getPreferredLocs(rdd: RDD[_], partition: Int): Seq[TaskLocation]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getPreferredLocs</code> is simply an alias for the internal (recursive) <a href="#getPreferredLocsInternal">getPreferredLocsInternal</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getPreferredLocs</code> is used when <a href="spark-SparkContext.adoc#getPreferredLocs"><code>SparkContext</code> gets the locality information for a RDD partition</a> and <code>DAGScheduler</code> <a href="#submitMissingTasks">submits missing tasks for a stage</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_blockmanagers_executors_for_cached_rdd_partitions_aka_block_location_discoverygetcachelocs_internal_method"><a class="anchor" href="#_finding_blockmanagers_executors_for_cached_rdd_partitions_aka_block_location_discoverygetcachelocs_internal_method"></a><a id="getCacheLocs"></a> Finding BlockManagers (Executors) for Cached RDD Partitions (aka Block Location Discovery)&#8201;&#8212;&#8201;<code>getCacheLocs</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getCacheLocs(rdd: RDD[_]): IndexedSeq[Seq[TaskLocation]]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getCacheLocs</code> gives <a href="spark-TaskLocation.adoc">TaskLocations</a> (block locations) for the partitions of the input <code>rdd</code>. <code>getCacheLocs</code> caches lookup results in <a href="#cacheLocs">cacheLocs</a> internal registry.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The size of the collection from <code>getCacheLocs</code> is exactly the number of partitions in <code>rdd</code> RDD.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The size of every <a href="spark-TaskLocation.adoc">TaskLocation</a> collection (i.e. every entry in the result of <code>getCacheLocs</code>) is exactly the number of blocks managed using <a href="spark-BlockManager.adoc">BlockManagers</a> on executors.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>getCacheLocs</code> finds <code>rdd</code> in the <a href="#cacheLocs">cacheLocs</a> internal registry (of partition locations per RDD).</p>
</div>
<div class="paragraph">
<p>If <code>rdd</code> is not in <a href="#cacheLocs">cacheLocs</a> internal registry, <code>getCacheLocs</code> branches per its <a href="spark-rdd-StorageLevel.adoc">storage level</a>.</p>
</div>
<div class="paragraph">
<p>For <code>NONE</code> storage level (i.e. no caching), the result is an empty locations (i.e. no location preference).</p>
</div>
<div class="paragraph">
<p>For other non-<code>NONE</code> storage levels, <code>getCacheLocs</code> <a href="spark-BlockManagerMaster.adoc#getLocations-block-array">requests <code>BlockManagerMaster</code> for block locations</a> that are then mapped to <a href="spark-TaskLocation.adoc">TaskLocations</a> with the hostname of the owning <code>BlockManager</code> for a block (of a partition) and the executor id.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getCacheLocs</code> uses <a href="#blockManagerMaster">BlockManagerMaster</a> that was defined when <a href="#creating-instance"><code>DAGScheduler</code> was created</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>getCacheLocs</code> records the computed block locations per partition (as <a href="spark-TaskLocation.adoc">TaskLocation</a>) in <a href="#cacheLocs">cacheLocs</a> internal registry.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getCacheLocs</code> requests locations from <code>BlockManagerMaster</code> using <a href="spark-BlockDataManager.adoc#RDDBlockId">RDDBlockId</a> with the RDD id and the partition indices (which implies that the order of the partitions matters to request proper blocks).
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>DAGScheduler</code> uses <a href="spark-TaskLocation.adoc">TaskLocations</a> (with host and executor) while <a href="spark-BlockManagerMaster.adoc">BlockManagerMaster</a> uses <a href="spark-BlockManager.adoc#BlockManagerId">BlockManagerId</a> (to track similar information, i.e. block locations).
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getCacheLocs</code> is used when <code>DAGScheduler</code> finds <a href="#getMissingParentStages">missing parent MapStages</a> and <a href="#getPreferredLocsInternal">getPreferredLocsInternal</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_placement_preferences_for_rdd_partition_recursivelygetpreferredlocsinternal_internal_method"><a class="anchor" href="#_finding_placement_preferences_for_rdd_partition_recursivelygetpreferredlocsinternal_internal_method"></a><a id="getPreferredLocsInternal"></a> Finding Placement Preferences for RDD Partition (recursively)&#8201;&#8212;&#8201;<code>getPreferredLocsInternal</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getPreferredLocsInternal(
  rdd: RDD[_],
  partition: Int,
  visited: HashSet[(RDD[_], Int)]): Seq[TaskLocation]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getPreferredLocsInternal</code> first <a href="#getCacheLocs">finds the <code>TaskLocations</code> for the <code>partition</code> of the <code>rdd</code></a> (using <a href="#cacheLocs">cacheLocs</a> internal cache) and returns them.</p>
</div>
<div class="paragraph">
<p>Otherwise, if not found, <code>getPreferredLocsInternal</code> <a href="spark-rdd.adoc#preferredLocations">requests <code>rdd</code> for the preferred locations of <code>partition</code></a> and returns them.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Preferred locations of the partitions of a RDD are also called <strong>placement preferences</strong> or <strong>locality preferences</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Otherwise, if not found, <code>getPreferredLocsInternal</code> finds the first parent <a href="spark-rdd-NarrowDependency.adoc">NarrowDependency</a> and (recursively) <a href="#getPreferredLocsInternal">finds <code>TaskLocations</code></a>.</p>
</div>
<div class="paragraph">
<p>If all the attempts fail to yield any non-empty result, <code>getPreferredLocsInternal</code> returns an empty collection of <a href="spark-TaskLocation.adoc">TaskLocations</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getPreferredLocsInternal</code> is used exclusively when <code>DAGScheduler</code> <a href="#getPreferredLocs">computes preferred locations for missing partitions</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_stopping_dagschedulerstop_method"><a class="anchor" href="#_stopping_dagschedulerstop_method"></a><a id="stop"></a> Stopping DAGScheduler&#8201;&#8212;&#8201;<code>stop</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">stop(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>stop</code> stops the internal <code>dag-scheduler-message</code> thread pool, <a href="#event-loop">dag-scheduler-event-loop</a>, and <a href="spark-scheduler-TaskScheduler.adoc#stop">TaskScheduler</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_updating_accumulators_with_partial_values_from_completed_tasksupdateaccumulators_internal_method"><a class="anchor" href="#_updating_accumulators_with_partial_values_from_completed_tasksupdateaccumulators_internal_method"></a><a id="updateAccumulators"></a> Updating Accumulators with Partial Values from Completed Tasks&#8201;&#8212;&#8201;<code>updateAccumulators</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">updateAccumulators(event: CompletionEvent): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p>The private <code>updateAccumulators</code> method merges the partial values of accumulators from a completed task into their "source" accumulators on the driver.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It is called by <a href="#handleTaskCompletion">handleTaskCompletion</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For each <a href="spark-accumulators.adoc#AccumulableInfo">AccumulableInfo</a> in the <code>CompletionEvent</code>, a partial value from a task is obtained (from <code>AccumulableInfo.update</code>) and added to the driver&#8217;s accumulator (using <code>Accumulable.++=</code> method).</p>
</div>
<div class="paragraph">
<p>For named accumulators with the update value being a non-zero value, i.e. not <code>Accumulable.zero</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>stage.latestInfo.accumulables</code> for the <code>AccumulableInfo.id</code> is set</p>
</li>
<li>
<p><code>CompletionEvent.taskInfo.accumulables</code> has a new <a href="spark-accumulators.adoc#AccumulableInfo">AccumulableInfo</a> added.</p>
</li>
</ul>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Where are <code>Stage.latestInfo.accumulables</code> and <code>CompletionEvent.taskInfo.accumulables</code> used?
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>updateAccumulators</code> is used exclusively when <code>DAGScheduler</code> is requested to <a href="#handleTaskCompletion">handle a task completion</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_checkbarrierstagewithnumslots_internal_method"><a class="anchor" href="#_checkbarrierstagewithnumslots_internal_method"></a><a id="checkBarrierStageWithNumSlots"></a> <code>checkBarrierStageWithNumSlots</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">checkBarrierStageWithNumSlots(rdd: RDD[_]): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>checkBarrierStageWithNumSlots</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>checkBarrierStageWithNumSlots</code> is used when <code>DAGScheduler</code> is requested to <a href="#createShuffleMapStage">createShuffleMapStage</a> and <a href="#createResultStage">createResultStage</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_settings"><a class="anchor" href="#_settings"></a><a id="settings"></a> Settings</h3>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Spark Properties</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Spark Property</th>
<th class="tableblock halign-left valign-top">Default Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="spark_test_noStageRetry"></a> <code>spark.test.noStageRetry</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">When enabled (i.e. <code>true</code>), <a href="spark-scheduler-DAGSchedulerEventProcessLoop.adoc#handleTaskCompletion-FetchFailed">task failures with <code>FetchFailed</code> exceptions</a> will not cause stage retries, in order to surface the problem. Used for testing.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_workerremoved_method"><a class="anchor" href="#_workerremoved_method"></a><a id="workerRemoved"></a> <code>workerRemoved</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">workerRemoved(
  workerId: String,
  host: String,
  message: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>workerRemoved</code> simply requests the <a href="#eventProcessLoop">DAGSchedulerEventProcessLoop</a> to post a <code>WorkerRemoved</code> event.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>workerRemoved</code> is used when&#8230;&#8203;FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_posttaskend_internal_method"><a class="anchor" href="#_posttaskend_internal_method"></a><a id="postTaskEnd"></a> <code>postTaskEnd</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">postTaskEnd(event: CompletionEvent): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>postTaskEnd</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>postTaskEnd</code> is used exclusively when <code>DAGScheduler</code> is requested to <a href="#handleTaskCompletion">handle a task completion</a>.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</article>
</main>
</div>
<footer class="footer">
  <p>This page was built using the Antora default UI.</p>
  <p>The source code for this UI is licensed under the terms of the MPL-2.0 license.</p>
</footer>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
