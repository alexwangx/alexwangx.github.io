<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: Spark 2.4.4 架构原理</title>
    <link rel="canonical" href="http://alexwangx.github.io/apache-spark-internals/2.4.4/apache-spark-internals/2.4.4/spark-SparkContext.html">
    <meta name="generator" content="Antora 2.0.0">
    <link rel="stylesheet" href="../../_/css/site.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86782445-1"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','UA-86782445-1')</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="http://alexwangx.github.io/apache-spark-internals/2.4.4">Spark 2.4.4 架构原理</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="#">Home</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Products</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Product A</a>
            <a class="navbar-item" href="#">Product B</a>
            <a class="navbar-item" href="#">Product C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Services</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Service A</a>
            <a class="navbar-item" href="#">Service B</a>
            <a class="navbar-item" href="#">Service C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Resources</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Resource A</a>
            <a class="navbar-item" href="#">Resource B</a>
            <a class="navbar-item" href="#">Resource C</a>
          </div>
        </div>
        <div class="navbar-item">
          <span class="control">
            <a class="button is-primary" href="#">Download</a>
          </span>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="apache-spark-internals" data-version="2.4.4">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Apache Spark</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-overview.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Block Storage System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockDataManager.html">BlockDataManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockId.html">BlockId</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ManagedBuffer.html">ManagedBuffer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockManager.html">BlockManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MemoryStore.html">MemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockEvictionHandler.html">BlockEvictionHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-StorageMemoryPool.html">StorageMemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MemoryPool.html">MemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DiskStore.html">DiskStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcHandler.html">RpcHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcResponseCallback.html">RpcResponseCallback</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportRequestHandler.html">TransportRequestHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportContext.html">TransportContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportServer.html">TransportServer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TransportClientFactory.html">TransportClientFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-MessageHandler.html">MessageHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockManagerMaster.html">BlockManagerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-blockmanager-BlockManagerMasterEndpoint.html">BlockManagerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DiskBlockManager.html">DiskBlockManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BlockInfoManager.html">BlockInfoManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-BlockInfo.html">BlockInfo</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-BlockManagerSlaveEndpoint.html">BlockManagerSlaveEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-DiskBlockObjectWriter.html">DiskBlockObjectWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockManager-BlockManagerSource.html">BlockManagerSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockManager-ShuffleMetricsSource.html">ShuffleMetricsSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-blockmanager-StorageStatus.html">StorageStatus</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Transferring Data Blocks (between Nodes in Spark Application)</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-ShuffleClient.html">ShuffleClient</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-BlockTransferService.html">BlockTransferService</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-ShuffleClient-ExternalShuffleClient.html">ExternalShuffleClient</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-NettyBlockTransferService.html">NettyBlockTransferService</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-NettyBlockRpcServer.html">NettyBlockRpcServer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-BlockFetchingListener.html">BlockFetchingListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-RetryingBlockFetcher.html">RetryingBlockFetcher</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RetryingBlockFetcher-BlockFetchStarter.html">BlockFetchStarter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shuffle System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleManager.html">ShuffleManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleBlockResolver.html">ShuffleBlockResolver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-SortShuffleManager.html">SortShuffleManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-IndexShuffleBlockResolver.html">IndexShuffleBlockResolver</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleHandle.html">ShuffleHandle</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BaseShuffleHandle.html">BaseShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BypassMergeSortShuffleHandle.html">BypassMergeSortShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-SerializedShuffleHandle.html">SerializedShuffleHandle</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleWriter.html">ShuffleWriter</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BypassMergeSortShuffleWriter.html">BypassMergeSortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-SortShuffleWriter.html">SortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-UnsafeShuffleWriter.html">UnsafeShuffleWriter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-shuffle-ShuffleReader.html">ShuffleReader</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-shuffle-BlockStoreShuffleReader.html">BlockStoreShuffleReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleExternalSorter.html">ShuffleExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shuffle-ShuffleInMemorySorter.html">ShuffleInMemorySorter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-architecture.html">Spark Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-driver.html">Driver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-Executor.html">Executor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-Executor-TaskRunner.html">TaskRunner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-executor-ExecutorSource.html">ExecutorSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-master.html">Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-workers.html">Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkConf.html">SparkConf</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-properties.html">Spark Properties and spark-defaults.conf Properties File</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-deploy-mode.html">Deploy Mode</a>
  </li>
</ul>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkContext.html">SparkContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-HeartbeatReceiver.html">HeartbeatReceiver RPC Endpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkContext-creating-instance-internals.html">Inside Creating SparkContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-ConsoleProgressBar.html">ConsoleProgressBar</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-SparkStatusTracker.html">SparkStatusTracker</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-sparkcontext-local-properties.html">Local Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-execution-model.html">Execution Model</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-configuration-properties.html">Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-anatomy-spark-application.html">Anatomy of Spark Application</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd.html">RDD</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-RDD.html">RDD API</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-operations.html">Operators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-transformations.html">Transformations</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-rdd-PairRDDFunctions.html">PairRDDFunctions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-actions.html">Actions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-lineage.html">RDD Lineage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-caching.html">Caching and Persistence</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-StorageLevel.html">StorageLevel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-checkpointing.html">Checkpointing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-CheckpointRDD.html">CheckpointRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-partitions.html">Partitions and Partitioning</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-Partition.html">Partition</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-Partitioner.html">Partitioner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-HashPartitioner.html">HashPartitioner</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-rdd-shuffle.html">Shuffling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rdd-Dependency.html">RDD Dependencies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-NarrowDependency.html">NarrowDependency</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ShuffleDependency.html">ShuffleDependency</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-Aggregator.html">Map/Reduce-side Aggregator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Specialized RDDs</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ParallelCollectionRDD.html">ParallelCollectionRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-MapPartitionsRDD.html">MapPartitionsRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-OrderedRDDFunctions.html">OrderedRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-CoGroupedRDD.html">CoGroupedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-SubtractedRDD.html">SubtractedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-HadoopRDD.html">HadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-NewHadoopRDD.html">NewHadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rdd-ShuffledRDD.html">ShuffledRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-TaskLocation.html">TaskLocation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-SparkHadoopWriter.html">SparkHadoopWriter</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-FileCommitProtocol.html">FileCommitProtocol</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapReduceCommitProtocol.html">HadoopMapReduceCommitProtocol</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapRedCommitProtocol.html">HadoopMapRedCommitProtocol</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-internal-io-HadoopWriteConfigUtil.html">HadoopWriteConfigUtil</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapReduceWriteConfigUtil.html">HadoopMapReduceWriteConfigUtil</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-internal-io-HadoopMapRedWriteConfigUtil.html">HadoopMapRedWriteConfigUtil</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-core-AppStatusStore.html">AppStatusStore</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-core-AppStatusPlugin.html">AppStatusPlugin</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-core-KVStore.html">KVStore</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-KVStoreView.html">KVStoreView</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-ElementTrackingStore.html">ElementTrackingStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-InMemoryStore.html">InMemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-core-LevelDB.html">LevelDB</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-InterruptibleIterator.html">InterruptibleIterator</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-barrier-execution-mode.html">Barrier Execution Mode</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-RDDBarrier.html">RDDBarrier</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shared Variables</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-broadcast.html">Broadcast variables</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-accumulators.html">Accumulators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-AccumulatorContext.html">AccumulatorContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Tools</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-shell.html">Spark Shell (spark-shell)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-submit.html">Spark Submit (spark-submit)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitArguments.html">SparkSubmitArguments</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitOptionParser.html">SparkSubmitOptionParser</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-submit-SparkSubmitCommandBuilder.html">SparkSubmitCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-class.html">spark-class shell script</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-AbstractCommandBuilder.html">AbstractCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SparkLauncher.html">SparkLauncher</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Core Services</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Low-Level Spark Task Scheduler</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-ActiveJob.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-SchedulableBuilder.html">SchedulableBuilder</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-FIFOSchedulableBuilder.html">FIFOSchedulableBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-FairSchedulableBuilder.html">FairSchedulableBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-TaskScheduler.html">TaskScheduler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-TaskSchedulerImpl.html">TaskSchedulerImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Task.html">Task</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ShuffleMapTask.html">ShuffleMapTask</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ResultTask.html">ResultTask</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSet.html">TaskSet</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSetManager.html">TaskSetManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Schedulable.html">Schedulable Entities</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-Pool.html">Schedulable Pool</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-SchedulingMode.html">Scheduling Mode</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskInfo.html">TaskInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-TaskRunner-FetchFailedException.html">FetchFailedException</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-MapStatus.html">MapStatus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskDescription.html">TaskDescription</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-taskschedulerimpl-speculative-execution.html">Speculative Execution of Tasks</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskResultGetter.html">TaskResultGetter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-TaskContext.html">TaskContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-BarrierTaskContext.html">BarrierTaskContext</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TaskContextImpl.html">TaskContextImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskResult.html">TaskResults</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-TaskSetBlacklist.html">TaskSetBlacklist</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">High-Level Spark Stage Scheduler</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-DAGScheduler.html">DAGScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-Stage.html">Stage</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ShuffleMapStage.html">ShuffleMapStage</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-ResultStage.html">ResultStage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-StageInfo.html">StageInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-scheduler-DAGSchedulerEventProcessLoop.html">DAGScheduler Event Bus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-JobListener.html">JobListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-scheduler-JobWaiter.html">JobWaiter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-memory-unified-memory-management.html">Unified Memory Management</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-memory-TaskMemoryManager.html">TaskMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-memory-MemoryConsumer.html">MemoryConsumer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-MemoryManager.html">MemoryManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-UnifiedMemoryManager.html">UnifiedMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-StaticMemoryManager.html">StaticMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-MemoryManager-properties.html">MemoryManager Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SerializerManager.html">SerializerManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-SparkEnv.html">SparkEnv</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SchedulerBackend.html">SchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-CoarseGrainedSchedulerBackend.html">CoarseGrainedSchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-CoarseGrainedSchedulerBackend-DriverEndpoint.html">DriverEndpoint</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-ExecutorBackend.html">ExecutorBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CoarseGrainedExecutorBackend.html">CoarseGrainedExecutorBackend</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalShuffleService.html">ExternalShuffleService</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-OneForOneStreamManager.html">OneForOneStreamManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ShuffleBlockFetcherIterator.html">ShuffleBlockFetcherIterator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalSorter.html">ExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-mapoutputtracker.html">MapOutputTracker</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-MapOutputTrackerMaster.html">MapOutputTrackerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-service-MapOutputTrackerMasterEndpoint.html">MapOutputTrackerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-MapOutputTrackerWorker.html">MapOutputTrackerWorker</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-serialization.html">Serialization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-Serializer.html">Serializer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SerializerInstance.html">SerializerInstance</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SerializationStream.html">SerializationStream</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-DeserializationStream.html">DeserializationStream</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-ExternalClusterManager.html">ExternalClusterManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-broadcastmanager.html">BroadcastManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-BroadcastFactory.html">BroadcastFactory</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TorrentBroadcastFactory.html">TorrentBroadcastFactory</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-TorrentBroadcast.html">TorrentBroadcast</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CompressionCodec.html">CompressionCodec</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-service-contextcleaner.html">ContextCleaner</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-CleanerListener.html">CleanerListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-dynamic-allocation.html">Dynamic Allocation (of Executors)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-ExecutorAllocationManager.html">ExecutorAllocationManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-ExecutorAllocationClient.html">ExecutorAllocationClient</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-service-ExecutorAllocationManagerSource.html">ExecutorAllocationManagerSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-http-file-server.html">HTTP File Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-data-locality.html">Data Locality</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-cachemanager.html">Cache Manager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-service-outputcommitcoordinator.html">OutputCommitCoordinator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-rpc.html">RPC Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-RpcEnv.html">RpcEnv</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-RpcEndpoint.html">RpcEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcEndpointRef.html">RpcEndpointRef</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-RpcEnvFactory.html">RpcEnvFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-rpc-netty.html">Netty-based RpcEnv</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-TransportConf.html">TransportConf</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-Utils.html">Utils Helper Object</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Security</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-webui-security.html">Securing Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-deployment-environments.html">Deployment Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-cluster.html">Spark on cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-history-server.html">Spark History Server</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-HistoryServer.html">HistoryServer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-SQLHistoryListener.html">SQLHistoryListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-FsHistoryProvider.html">FsHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationHistoryProvider.html">ApplicationHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-HistoryServerArguments.html">HistoryServerArguments</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationCacheOperations.html">ApplicationCacheOperations</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-history-server-ApplicationCache.html">ApplicationCache</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring, Tuning, Debugging and Testing</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-logging.html">Logging</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tuning.html">Performance Tuning</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-scheduler-SparkListener.html">SparkListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-AppStatusListener.html">AppStatusListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-EventLoggingListener.html">EventLoggingListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-ExecutorAllocationListener.html">ExecutorAllocationListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-SpillListener.html">SpillListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListener-StatsReportListener.html">StatsReportListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-scheduler-LiveListenerBus.html">LiveListenerBus</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-SparkListenerBus.html">SparkListenerBus</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListenerBus-AsyncEventQueue.html">AsyncEventQueue</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkListenerBus-ReplayListenerBus.html">ReplayListenerBus</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-JsonProtocol.html">JsonProtocol</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-debugging.html">Debugging Spark</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Varia</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-building-from-sources.html">Building Apache Spark from Sources</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="varia/spark-hadoop.html">Spark and Hadoop</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-SparkHadoopUtil.html">SparkHadoopUtil</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-inmemory-filesystems.html">Spark and software in-memory file systems</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-others.html">Spark and The Others</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-deeplearning.html">Distributed Deep Learning on Spark</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="varia/spark-packages.html">Spark Packages</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-tips-and-tricks.html">Spark Tips and Tricks</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-access-private-members-spark-shell.html">Access private members in Scala in Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-sparkexception-task-not-serializable.html">SparkException: Task not serializable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-tips-and-tricks-running-spark-windows.html">Running Spark Applications on Windows</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Further Learning</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-courses.html">Courses</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-books.html">Books</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-sql.html">Spark SQL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="spark-structured-streaming.html">Spark Structured Streaming</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/index.html">Web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-jobs.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-stages.html">Stages</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-storage.html">Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-environment.html">Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-executors.html">Executors</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-JobsTab.html">JobsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-AllJobsPage.html">AllJobsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-JobPage.html">JobPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-StagesTab.html">StagesTab&#8201;&#8212;&#8201;Stages for All Jobs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-AllStagesPage.html">AllStagesPage&#8201;&#8212;&#8201;Stages for All Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-StagePage.html">StagePage&#8201;&#8212;&#8201;Stage Details</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-PoolPage.html">PoolPage&#8201;&#8212;&#8201;Pool Details</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-StorageTab.html">StorageTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-StoragePage.html">StoragePage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-RDDPage.html">RDDPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-EnvironmentTab.html">EnvironmentTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-EnvironmentPage.html">EnvironmentPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-ExecutorsTab.html">ExecutorsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-ExecutorsPage.html">ExecutorsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-ExecutorThreadDumpPage.html">ExecutorThreadDumpPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-SparkUI.html">SparkUI&#8201;&#8212;&#8201;Web UI of Spark Application</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-SparkUITab.html">SparkUITab</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-BlockStatusListener.html">BlockStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-EnvironmentListener.html">EnvironmentListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-executors-ExecutorsListener.html">ExecutorsListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-JobProgressListener.html">JobProgressListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-StorageStatusListener.html">StorageStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-StorageListener.html">StorageListener&#8201;&#8212;&#8201;Spark Listener for Tracking Persistence Status of RDD Blocks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-RDDOperationGraphListener.html">RDDOperationGraphListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-webui-WebUI.html">WebUI&#8201;&#8212;&#8201;Framework For Web UIs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-WebUIPage.html">WebUIPage&#8201;&#8212;&#8201;Contract of Pages in Web UI</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-webui-WebUITab.html">WebUITab&#8201;&#8212;&#8201;Contract of Tabs in Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-RDDStorageInfo.html">RDDStorageInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-core-RDDInfo.html">RDDInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="webui/spark-core-LiveEntity.html">LiveEntity</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="webui/spark-core-LiveRDD.html">LiveRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-UIUtils.html">UIUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-JettyUtils.html">JettyUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="webui/spark-webui-properties.html">web UI Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/index.html">Spark Metrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-MetricsSystem.html">MetricsSystem</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-MetricsConfig.html">MetricsConfig</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-metrics-Source.html">Source</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-scheduler-DAGSchedulerSource.html">DAGSchedulerSourcer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-metrics-Sink.html">Sink</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-metrics-MetricsServlet.html">MetricsServlet JSON Metrics Sink</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="metrics/spark-metrics-properties.html">Metrics Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="metrics/spark-executor-TaskMetrics.html">TaskMetrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="metrics/spark-executor-ShuffleWriteMetrics.html">ShuffleWriteMetrics</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/index.html">Spark MLlib</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines.html">ML Pipelines (spark.ml)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-Pipeline.html">Pipeline</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-PipelineStage.html">PipelineStage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-transformers.html">Transformers</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-Transformer.html">Transformer</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-transformers-Tokenizer.html">Tokenizer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-estimators.html">Estimators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Estimator.html">Estimator</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-StringIndexer.html">StringIndexer</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-KMeans.html">KMeans</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-TrainValidationSplit.html">TrainValidationSplit</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Predictor.html">Predictor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-RandomForestRegressor.html">RandomForestRegressor</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Regressor.html">Regressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-LinearRegression.html">LinearRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Classifier.html">Classifier</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-RandomForestClassifier.html">RandomForestClassifier</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="spark-mllib/spark-mllib-DecisionTreeClassifier.html">DecisionTreeClassifier</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-models.html">Models</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-Model.html">Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Evaluator.html">Evaluator&#8201;&#8212;&#8201;ML Pipeline Component for Model Scoring</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-BinaryClassificationEvaluator.html">BinaryClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Binary Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ClusteringEvaluator.html">ClusteringEvaluator&#8201;&#8212;&#8201;Evaluator of Clustering Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-MulticlassClassificationEvaluator.html">MulticlassClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Multiclass Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-RegressionEvaluator.html">RegressionEvaluator&#8201;&#8212;&#8201;Evaluator of Regression Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidator.html">CrossValidator&#8201;&#8212;&#8201;Model Tuning / Finding The Best Model</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidatorModel.html">CrossValidatorModel</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ParamGridBuilder.html">ParamGridBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-CrossValidator-example.html">CrossValidator with Pipeline Example</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-Params.html">Params and ParamMaps</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-ValidatorParams.html">ValidatorParams</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="spark-mllib/spark-mllib-HasParallelism.html">HasParallelism</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-persistence.html">ML Persistence&#8201;&#8212;&#8201;Saving and Loading Models and Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLWritable.html">MLWritable</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLReader.html">MLReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-example-classification.html">Example&#8201;&#8212;&#8201;Text Classification</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-pipelines-example-regression.html">Example&#8201;&#8212;&#8201;Linear Regression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-logistic-regression.html">Logistic Regression</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-LogisticRegression.html">LogisticRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-latent-dirichlet-allocation.html">Latent Dirichlet Allocation (LDA)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-vector.html">Vector</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-labeledpoint.html">LabeledPoint</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-streaming.html">Streaming MLlib</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-GeneralizedLinearRegression.html">GeneralizedLinearRegression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-mllib/spark-mllib-alternating-least-squares.html">Alternating Least Squares (ALS) Matrix Factorization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALS.html">ALS&#8201;&#8212;&#8201;Estimator for ALSModel</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALSModel.html">ALSModel&#8201;&#8212;&#8201;Model for Predictions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-mllib/spark-mllib-ALSModelReader.html">ALSModelReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-Instrumentation.html">Instrumentation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-mllib/spark-mllib-MLUtils.html">MLUtils</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-local/index.html">Spark local</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LocalSchedulerBackend.html">LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LocalEndpoint.html">LocalEndpoint&#8201;&#8212;&#8201;RPC Endpoint for LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-local/spark-LauncherBackend.html">LauncherBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/index.html">Spark on YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnShuffleService.html">YarnShuffleService&#8201;&#8212;&#8201;ExternalShuffleService on YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ExecutorRunnable.html">ExecutorRunnable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-client.html">Client</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnrmclient.html">YarnRMClient</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-applicationmaster.html">ApplicationMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-AMEndpoint.html">AMEndpoint&#8201;&#8212;&#8201;ApplicationMaster RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnClusterManager.html">YarnClusterManager&#8201;&#8212;&#8201;ExternalClusterManager for YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-taskschedulers.html">TaskSchedulers for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnscheduler.html">YarnScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnclusterscheduler.html">YarnClusterScheduler</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-schedulerbackends.html">SchedulerBackends for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-yarnschedulerbackend.html">YarnSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-client-yarnclientschedulerbackend.html">YarnClientSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-yarnclusterschedulerbackend.html">YarnClusterSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-YarnSchedulerEndpoint.html">YarnSchedulerEndpoint RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnAllocator.html">YarnAllocator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-introduction.html">Introduction to Hadoop YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-cluster-setup.html">Setting up YARN Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-yarn/spark-yarn-kerberos.html">Kerberos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ConfigurableCredentialManager.html">ConfigurableCredentialManager</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-ClientDistributedCacheManager.html">ClientDistributedCacheManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-YarnSparkHadoopUtil.html">YarnSparkHadoopUtil</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-yarn/spark-yarn-settings.html">Settings</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-standalone/index.html">Spark Standalone</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-Master.html">Standalone Master&#8201;&#8212;&#8201;Cluster Manager of Spark Standalone</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-worker.html">Standalone Worker</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-standalone/spark-standalone-webui.html">web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-standalone/spark-standalone-webui-ApplicationPage.html">ApplicationPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-LocalSparkCluster.html">LocalSparkCluster&#8201;&#8212;&#8201;Single-JVM Spark Standalone Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-submission-gateways.html">Submission Gateways</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-master-scripts.html">Management Scripts for Standalone Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-worker-scripts.html">Management Scripts for Standalone Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-status.html">Checking Status</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-example-2-workers-on-1-node-cluster.html">Example 2-workers-on-1-node Standalone Cluster (one executor per worker)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-standalone/spark-standalone-StandaloneSchedulerBackend.html">StandaloneSchedulerBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/index.html">Status REST API</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-ApiRootResource.html">ApiRootResource&#8201;&#8212;&#8201;/api/v1 URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-ApplicationListResource.html">ApplicationListResource&#8201;&#8212;&#8201;applications URI Handler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-OneApplicationResource.html">OneApplicationResource&#8201;&#8212;&#8201;applications/appId URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="rest-api/spark-api-StagesResource.html">StagesResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-OneApplicationAttemptResource.html">OneApplicationAttemptResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-AbstractApplicationResource.html">AbstractApplicationResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-BaseAppResource.html">BaseAppResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rest-api/spark-api-ApiRequestContext.html">ApiRequestContext</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rest-api/spark-api-UIRoot.html">UIRoot&#8201;&#8212;&#8201;Contract for Root Contrainers of Application UI Information</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="rest-api/spark-api-UIRootFromServletContext.html">UIRootFromServletContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-on-mesos/index.html">Spark on Mesos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-mesos-MesosCoarseGrainedSchedulerBackend.html">MesosCoarseGrainedSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-mesos-introduction.html">About Mesos</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-on-mesos/spark-executor-backends-MesosExecutorBackend.html">MesosExecutorBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Exercises</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-pairrddfunctions-oneliners.html">One-liners using PairRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-take-multiple-jobs.html">Learning Jobs and Partitions Using take Action</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-standalone-master-ha.html">Spark Standalone - Using ZooKeeper for High-Availability of Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-hello-world-using-spark-shell.html">Spark&#8217;s Hello World using Spark shell and Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-examples-wordcount-spark-shell.html">WordCount using Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-first-app.html">Your first complete Spark application (using Scala and sbt)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-notable-use-cases.html">Spark (notable) use cases</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-sql-hive-orc-example.html">Using Spark SQL to update data in Hive using ORC files</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-scheduler-listener.html">Developing Custom SparkListener to monitor DAGScheduler in Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-rpc-environment.html">Developing RPC Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-custom-rdd.html">Developing Custom RDD</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-dataframe-jdbc-postgresql.html">Working with Datasets from JDBC Data Sources (and PostgreSQL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="exercises/spark-exercise-failing-stage.html">Causing Stage to Fail</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Apache Spark</span>
    <span class="version">2.4.4</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Apache Spark</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="index.html">2.4.4</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main role="main">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Apache Spark</a></li>
    <li><a href="spark-architecture.html">Spark Architecture</a></li>
    <li><a href="spark-SparkContext.html">SparkContext</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///Users/alex/Alex/_Code/GitBook/mastering-apache-spark-book-cn/modules/ROOT/pages/spark-SparkContext.adoc">Edit this Page</a></div>
</div>
<article class="doc">
<div class="sect1">
<h2 id="_sparkcontextentry_point_to_spark_core"><a class="anchor" href="#_sparkcontextentry_point_to_spark_core"></a><a id="SparkContext"></a> SparkContext&#8201;&#8212;&#8201;Entry Point to Spark Core</h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>SparkContext</code> (aka <strong>Spark context</strong>) is the entry point to the services of Apache Spark (execution engine) and so the heart of a Spark application. In fact, you can consider an application a Spark application only when it uses a <code>SparkContext</code> (directly or indirectly).</p>
</div>
<table id="methods" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. SparkContext&#8217;s Developer API (Public Methods)</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#addJar-internals">addJar</a></p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div id="addJar" class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">addJar(path: String): Unit</code></pre>
</div>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p><em>More to be added soon</em></p>
</div></div></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Spark context <a href="spark-SparkContext-creating-instance-internals.adoc">sets up internal services</a> and establishes a connection to a <a href="spark-deployment-environments.adoc">Spark execution environment</a>.</p>
</div>
<div class="paragraph">
<p>Once a <a href="#creating-instance"><code>SparkContext</code> is created</a> you can use it to <a href="#creating-rdds">create RDDs</a>, <a href="#creating-accumulators">accumulators</a> and <a href="#broadcast">broadcast variables</a>, access Spark services and <a href="#runJob">run jobs</a> (until <code>SparkContext</code> is <a href="#stop">stopped</a>).</p>
</div>
<div class="paragraph">
<p>A Spark context is essentially a client of Spark&#8217;s execution environment and acts as the <em>master of your Spark application</em> (don&#8217;t get confused with the other meaning of <a href="spark-master.adoc">Master</a> in Spark, though).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/diagrams/sparkcontext-services.png" alt="sparkcontext services">
</div>
<div class="title">Figure 1. Spark context acts as the master of your Spark application</div>
</div>
<div class="paragraph">
<p><code>SparkContext</code> offers the following functions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Getting current status of a Spark application</p>
<div class="ulist">
<ul>
<li>
<p><a href="#env">SparkEnv</a></p>
</li>
<li>
<p><a href="#getConf">SparkConf</a></p>
</li>
<li>
<p><a href="#master">deployment environment (as master URL)</a></p>
</li>
<li>
<p><a href="#appName">application name</a></p>
</li>
<li>
<p><a href="#applicationAttemptId">unique identifier of execution attempt</a></p>
</li>
<li>
<p><a href="#deployMode">deploy mode</a></p>
</li>
<li>
<p><a href="#defaultParallelism">default level of parallelism</a> that specifies the number of <a href="spark-rdd-partitions.adoc">partitions</a> in RDDs when they are created without specifying the number explicitly by a user.</p>
</li>
<li>
<p><a href="#sparkUser">Spark user</a></p>
</li>
<li>
<p><a href="#startTime">the time (in milliseconds) when <code>SparkContext</code> was created</a></p>
</li>
<li>
<p><a href="#uiWebUrl">URL of web UI</a></p>
</li>
<li>
<p><a href="#version">Spark version</a></p>
</li>
<li>
<p><a href="#getExecutorStorageStatus">Storage status</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Setting Configuration</p>
<div class="ulist">
<ul>
<li>
<p><a href="#master-url">master URL</a></p>
</li>
<li>
<p><a href="spark-sparkcontext-local-properties.adoc">Local Properties&#8201;&#8212;&#8201;Creating Logical Job Groups</a></p>
</li>
<li>
<p><a href="#setJobGroup">Setting Local Properties to Group Spark Jobs</a></p>
</li>
<li>
<p><a href="#setting-default-log-level">Default Logging Level</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Creating Distributed Entities</p>
<div class="ulist">
<ul>
<li>
<p><a href="#creating-rdds">RDDs</a></p>
</li>
<li>
<p><a href="#creating-accumulators">Accumulators</a></p>
</li>
<li>
<p><a href="#broadcast">Broadcast variables</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Accessing services, e.g. <a href="#statusStore">AppStatusStore</a>, <a href="#taskScheduler">TaskScheduler</a>, <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a>, <a href="spark-BlockManager.adoc">BlockManager</a>, <a href="spark-SchedulerBackend.adoc">SchedulerBackends</a>, <a href="spark-shuffle-ShuffleManager.adoc">ShuffleManager</a> and the <a href="#cleaner">optional ContextCleaner</a>.</p>
</li>
<li>
<p><a href="#runJob">Running jobs synchronously</a></p>
</li>
<li>
<p><a href="#submitJob">Submitting jobs asynchronously</a></p>
</li>
<li>
<p><a href="#cancelJob">Cancelling a job</a></p>
</li>
<li>
<p><a href="#cancelStage">Cancelling a stage</a></p>
</li>
<li>
<p><a href="#custom-schedulers">Assigning custom Scheduler Backend, TaskScheduler and DAGScheduler</a></p>
</li>
<li>
<p><a href="#closure-cleaning">Closure cleaning</a></p>
</li>
<li>
<p><a href="#getPersistentRDDs">Accessing persistent RDDs</a></p>
</li>
<li>
<p><a href="#unpersist">Unpersisting RDDs, i.e. marking RDDs as non-persistent</a></p>
</li>
<li>
<p><a href="#addSparkListener">Registering SparkListener</a></p>
</li>
<li>
<p><a href="#dynamic-allocation">Programmable Dynamic Allocation</a></p>
</li>
</ul>
</div>
<table id="internal-registries" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. SparkContext&#8217;s Internal Registries and Counters</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>persistentRdds</code></p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p><a id="persistentRdds"></a> Lookup table of persistent/cached RDDs per their ids.</p>
</div>
<div class="paragraph">
<p>Used when <code>SparkContext</code> is requested to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#persistRDD">persistRDD</a></p>
</li>
<li>
<p><a href="#getRDDStorageInfo">getRDDStorageInfo</a></p>
</li>
<li>
<p><a href="#getPersistentRDDs">getPersistentRDDs</a></p>
</li>
<li>
<p><a href="#unpersistRDD">unpersistRDD</a></p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>stopped</code></p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p><a id="stopped"></a> Flag that says whether&#8230;&#8203;FIXME (<code>true</code>) or not (<code>false</code>)</p>
</div></div></td>
</tr>
</tbody>
</table>
<table id="internal-properties" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. SparkContext&#8217;s Internal Properties</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Initial Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="_taskScheduler"></a> _taskScheduler</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(uninitialized)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="spark-scheduler-TaskScheduler.adoc">TaskScheduler</a></p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read the scaladoc of  <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.SparkContext">org.apache.spark.SparkContext</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Enable <code>INFO</code> logging level for <code>org.apache.spark.SparkContext</code> logger to see what happens inside.</p>
</div>
<div class="paragraph">
<p>Add the following line to <code>conf/log4j.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>log4j.logger.org.apache.spark.SparkContext=INFO</code></pre>
</div>
</div>
<div class="paragraph">
<p>Refer to <a href="spark-logging.adoc">Logging</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_addfile_method"><a class="anchor" href="#_addfile_method"></a><a id="addFile"></a> <code>addFile</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">addFile(path: String): Unit <i class="conum" data-value="1"></i><b>(1)</b>
addFile(path: String, recursive: Boolean): Unit</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td><code>recursive</code> flag is off</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>addFile</code> adds the <code>path</code> file to be downloaded&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>addFile</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>SparkContext</code> is <a href="spark-SparkContext-creating-instance-internals.adoc#files">initialized</a> (and <code>files</code> were defined)</p>
</li>
<li>
<p>Spark SQL&#8217;s <code>AddFileCommand</code> is executed</p>
</li>
<li>
<p>Spark SQL&#8217;s <code>SessionResourceLoader</code> is requested to load a file resource</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_removing_rdd_blocks_from_blockmanagermasterunpersistrdd_internal_method"><a class="anchor" href="#_removing_rdd_blocks_from_blockmanagermasterunpersistrdd_internal_method"></a><a id="unpersistRDD"></a> Removing RDD Blocks from BlockManagerMaster&#8201;&#8212;&#8201;<code>unpersistRDD</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">unpersistRDD(rddId: Int, blocking: Boolean = true): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>unpersistRDD</code> requests <code>BlockManagerMaster</code> to <a href="spark-BlockManagerMaster.adoc#removeRdd">remove the blocks for the RDD</a> (given <code>rddId</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>unpersistRDD</code> uses <code>SparkEnv</code> <a href="spark-SparkEnv.adoc#blockManager">to access the current <code>BlockManager</code></a> that is in turn used to <a href="spark-BlockManager.adoc#master">access the current <code>BlockManagerMaster</code></a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>unpersistRDD</code> removes <code>rddId</code> from <a href="#persistentRdds">persistentRdds</a> registry.</p>
</div>
<div class="paragraph">
<p>In the end, <code>unpersistRDD</code> posts a <a href="spark-scheduler-SparkListener.adoc#SparkListenerUnpersistRDD">SparkListenerUnpersistRDD</a> (with <code>rddId</code>) to <a href="#listenerBus">LiveListenerBus Event Bus</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>unpersistRDD</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ContextCleaner</code> does <a href="spark-service-contextcleaner.adoc#doCleanupRDD">doCleanupRDD</a></p>
</li>
<li>
<p><code>SparkContext</code> <a href="#unpersist">unpersists an RDD</a> (i.e. marks an RDD as non-persistent)</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_unique_identifier_of_spark_applicationapplicationid_method"><a class="anchor" href="#_unique_identifier_of_spark_applicationapplicationid_method"></a><a id="applicationId"></a> Unique Identifier of Spark Application&#8201;&#8212;&#8201;<code>applicationId</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_postapplicationstart_internal_method"><a class="anchor" href="#_postapplicationstart_internal_method"></a><a id="postApplicationStart"></a> <code>postApplicationStart</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">postApplicationStart(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>postApplicationStart</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>postApplicationStart</code> is used exclusively while <code>SparkContext</code> is being <a href="spark-SparkContext-creating-instance-internals.html#postApplicationStart" class="page">created</a>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_postapplicationend_method"><a class="anchor" href="#_postapplicationend_method"></a><a id="postApplicationEnd"></a> <code>postApplicationEnd</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_clearactivecontext_method"><a class="anchor" href="#_clearactivecontext_method"></a><a id="clearActiveContext"></a> <code>clearActiveContext</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_accessing_persistent_rddsgetpersistentrdds_method"><a class="anchor" href="#_accessing_persistent_rddsgetpersistentrdds_method"></a><a id="getPersistentRDDs"></a> Accessing persistent RDDs&#8201;&#8212;&#8201;<code>getPersistentRDDs</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getPersistentRDDs: Map[Int, RDD[_]]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getPersistentRDDs</code> returns the collection of RDDs that have marked themselves as persistent via <a href="spark-rdd-caching.adoc#cache">cache</a>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>getPersistentRDDs</code> returns <a href="#persistentRdds">persistentRdds</a> internal registry.</p>
</div>
</div>
<div class="sect2">
<h3 id="_cancelling_jobcanceljob_method"><a class="anchor" href="#_cancelling_jobcanceljob_method"></a><a id="cancelJob"></a> Cancelling Job&#8201;&#8212;&#8201;<code>cancelJob</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelJob(jobId: Int)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelJob</code> requests <code>DAGScheduler</code> <a href="spark-scheduler-DAGScheduler.adoc#cancelJob">to cancel a Spark job</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_cancelling_stagecancelstage_methods"><a class="anchor" href="#_cancelling_stagecancelstage_methods"></a><a id="cancelStage"></a> Cancelling Stage&#8201;&#8212;&#8201;<code>cancelStage</code> Methods</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelStage(stageId: Int): Unit
cancelStage(stageId: Int, reason: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelStage</code> simply requests <code>DAGScheduler</code> <a href="spark-scheduler-DAGScheduler.adoc#cancelJob">to cancel a Spark stage</a> (with an optional <code>reason</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelStage</code> is used when <code>StagesTab</code> <a href="spark-webui-StagesTab.adoc#handleKillRequest">handles a kill request</a> (from a user in web UI).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_programmable_dynamic_allocation"><a class="anchor" href="#_programmable_dynamic_allocation"></a><a id="dynamic-allocation"></a> Programmable Dynamic Allocation</h3>
<div class="paragraph">
<p><code>SparkContext</code> offers the following methods as the developer API for <a href="spark-dynamic-allocation.adoc">dynamic allocation of executors</a>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="#requestExecutors">requestExecutors</a></p>
</li>
<li>
<p><a href="#killExecutors">killExecutors</a></p>
</li>
<li>
<p><a href="#requestTotalExecutors">requestTotalExecutors</a></p>
</li>
<li>
<p>(private!) <a href="#getExecutorIds">getExecutorIds</a></p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_requesting_new_executorsrequestexecutors_method"><a class="anchor" href="#_requesting_new_executorsrequestexecutors_method"></a><a id="requestExecutors"></a> Requesting New Executors&#8201;&#8212;&#8201;<code>requestExecutors</code> Method</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">requestExecutors(numAdditionalExecutors: Int): Boolean</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>requestExecutors</code> requests <code>numAdditionalExecutors</code> executors from <a href="spark-CoarseGrainedSchedulerBackend.adoc">CoarseGrainedSchedulerBackend</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_requesting_to_kill_executorskillexecutors_method"><a class="anchor" href="#_requesting_to_kill_executorskillexecutors_method"></a><a id="killExecutors"></a> Requesting to Kill Executors&#8201;&#8212;&#8201;<code>killExecutors</code> Method</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">killExecutors(executorIds: Seq[String]): Boolean</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_requesting_total_executorsrequesttotalexecutors_method"><a class="anchor" href="#_requesting_total_executorsrequesttotalexecutors_method"></a><a id="requestTotalExecutors"></a> Requesting Total Executors&#8201;&#8212;&#8201;<code>requestTotalExecutors</code> Method</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">requestTotalExecutors(
  numExecutors: Int,
  localityAwareTasks: Int,
  hostToLocalTaskCount: Map[String, Int]): Boolean</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>requestTotalExecutors</code> is a <code>private[spark]</code> method that <a href="spark-CoarseGrainedSchedulerBackend.adoc#requestTotalExecutors">requests the exact number of executors from a coarse-grained scheduler backend</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It works for <a href="spark-CoarseGrainedSchedulerBackend.adoc">coarse-grained scheduler backends</a> only.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When called for other scheduler backends you should see the following WARN message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>WARN Requesting executors is only supported in coarse-grained mode</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_getting_executor_idsgetexecutorids_method"><a class="anchor" href="#_getting_executor_idsgetexecutorids_method"></a><a id="getExecutorIds"></a> Getting Executor Ids&#8201;&#8212;&#8201;<code>getExecutorIds</code> Method</h4>
<div class="paragraph">
<p><code>getExecutorIds</code> is a <code>private[spark]</code> method that is part of <a href="spark-service-ExecutorAllocationClient.adoc">ExecutorAllocationClient contract</a>. It simply <a href="spark-CoarseGrainedSchedulerBackend.adoc#getExecutorIds">passes the call on to the current coarse-grained scheduler backend, i.e. calls <code>getExecutorIds</code></a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It works for <a href="spark-CoarseGrainedSchedulerBackend.adoc">coarse-grained scheduler backends</a> only.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When called for other scheduler backends you should see the following WARN message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>WARN Requesting executors is only supported in coarse-grained mode</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Why does SparkContext implement the method for coarse-grained scheduler backends? Why doesn&#8217;t SparkContext throw an exception when the method is called? Nobody seems to be using it (!)
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_creating_sparkcontext_instance"><a class="anchor" href="#_creating_sparkcontext_instance"></a><a id="creating-instance"></a> Creating <code>SparkContext</code> Instance</h3>
<div class="paragraph">
<p>You can create a <code>SparkContext</code> instance with or without creating a <a href="spark-SparkConf.adoc">SparkConf</a> object first.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You may want to read <a href="spark-SparkContext-creating-instance-internals.adoc">Inside Creating SparkContext</a> to learn what happens behind the scenes when <code>SparkContext</code> is created.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_getting_existing_or_creating_new_sparkcontextgetorcreate_methods"><a class="anchor" href="#_getting_existing_or_creating_new_sparkcontextgetorcreate_methods"></a><a id="getOrCreate"></a> Getting Existing or Creating New SparkContext&#8201;&#8212;&#8201;<code>getOrCreate</code> Methods</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getOrCreate(): SparkContext
getOrCreate(conf: SparkConf): SparkContext</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getOrCreate</code> methods allow you to get the existing <code>SparkContext</code> or create a new one.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">import org.apache.spark.SparkContext
val sc = SparkContext.getOrCreate()

// Using an explicit SparkConf object
import org.apache.spark.SparkConf
val conf = new SparkConf()
  .setMaster("local[*]")
  .setAppName("SparkMe App")
val sc = SparkContext.getOrCreate(conf)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The no-param <code>getOrCreate</code> method requires that the two mandatory Spark settings - <a href="#master">master</a> and <a href="#appName">application name</a> - are specified using <a href="spark-submit.adoc">spark-submit</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_constructors"><a class="anchor" href="#_constructors"></a><a id="constructors"></a> Constructors</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">SparkContext()
SparkContext(conf: SparkConf)
SparkContext(master: String, appName: String, conf: SparkConf)
SparkContext(
  master: String,
  appName: String,
  sparkHome: String = null,
  jars: Seq[String] = Nil,
  environment: Map[String, String] = Map())</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can create a <code>SparkContext</code> instance using the four constructors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">import org.apache.spark.SparkConf
val conf = new SparkConf()
  .setMaster("local[*]")
  .setAppName("SparkMe App")

import org.apache.spark.SparkContext
val sc = new SparkContext(conf)</code></pre>
</div>
</div>
<div class="paragraph">
<p>When a Spark context starts up you should see the following INFO in the logs (amongst the other messages that come from the Spark services):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: Running Spark version 2.0.0-SNAPSHOT</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Only one SparkContext may be running in a single JVM (check out <a href="https://issues.apache.org/jira/browse/SPARK-2243">SPARK-2243 Support multiple SparkContexts in the same JVM</a>). Sharing access to a SparkContext in the JVM is the solution to share data within Spark (without relying on other means of data sharing using external data stores).
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_accessing_current_sparkenvenv_method"><a class="anchor" href="#_accessing_current_sparkenvenv_method"></a><a id="env"></a> Accessing Current SparkEnv&#8201;&#8212;&#8201;<code>env</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_getting_current_sparkconfgetconf_method"><a class="anchor" href="#_getting_current_sparkconfgetconf_method"></a><a id="getConf"></a> Getting Current SparkConf&#8201;&#8212;&#8201;<code>getConf</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getConf: SparkConf</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getConf</code> returns the current <a href="spark-SparkConf.adoc">SparkConf</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Changing the <code>SparkConf</code> object does not change the current configuration (as the method returns a copy).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_deployment_environmentmaster_method"><a class="anchor" href="#_deployment_environmentmaster_method"></a><a id="master"></a><a id="master-url"></a> Deployment Environment&#8201;&#8212;&#8201;<code>master</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">master: String</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>master</code> method returns the current value of <a href="spark-configuration-properties.adoc#spark.master">spark.master</a> which is the <a href="spark-deployment-environments.adoc">deployment environment</a> in use.</p>
</div>
</div>
<div class="sect2">
<h3 id="_application_nameappname_method"><a class="anchor" href="#_application_nameappname_method"></a><a id="appName"></a> Application Name&#8201;&#8212;&#8201;<code>appName</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">appName: String</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>appName</code> gives the value of the mandatory <a href="spark-SparkConf.adoc#spark.app.name">spark.app.name</a> setting.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>appName</code> is used when <a href="spark-standalone.adoc#SparkDeploySchedulerBackend"><code>SparkDeploySchedulerBackend</code> starts</a>, <a href="spark-webui-SparkUI.adoc#createLiveUI"><code>SparkUI</code> creates a web UI</a>, when <code>postApplicationStart</code> is executed, and for Mesos and checkpointing in Spark Streaming.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_unique_identifier_of_execution_attemptapplicationattemptid_method"><a class="anchor" href="#_unique_identifier_of_execution_attemptapplicationattemptid_method"></a><a id="applicationAttemptId"></a> Unique Identifier of Execution Attempt&#8201;&#8212;&#8201;<code>applicationAttemptId</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">applicationAttemptId: Option[String]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>applicationAttemptId</code> gives the  unique identifier of the execution attempt of a Spark application.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>applicationAttemptId</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="spark-scheduler-ShuffleMapTask.adoc#creating-instance">ShuffleMapTask</a> and <a href="spark-scheduler-ResultTask.adoc#creating-instance">ResultTask</a> are created</p>
</li>
<li>
<p><code>SparkContext</code> <a href="#postApplicationStart">announces that a Spark application has started</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_storage_status_of_all_blockmanagersgetexecutorstoragestatus_method"><a class="anchor" href="#_storage_status_of_all_blockmanagersgetexecutorstoragestatus_method"></a><a id="getExecutorStorageStatus"></a> Storage Status (of All BlockManagers)&#8201;&#8212;&#8201;<code>getExecutorStorageStatus</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getExecutorStorageStatus: Array[StorageStatus]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getExecutorStorageStatus</code> <a href="spark-BlockManagerMaster.adoc#getStorageStatus">requests <code>BlockManagerMaster</code> for storage status</a> (of all <a href="spark-BlockManager.adoc">BlockManagers</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getExecutorStorageStatus</code> is a developer API.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>getExecutorStorageStatus</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>SparkContext</code> <a href="#getRDDStorageInfo">is requested for storage status of cached RDDs</a></p>
</li>
<li>
<p><code>SparkStatusTracker</code> <a href="spark-sparkcontext-SparkStatusTracker.adoc#getExecutorInfos">is requested for information about all known executors</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_deploy_modedeploymode_method"><a class="anchor" href="#_deploy_modedeploymode_method"></a><a id="deployMode"></a> Deploy Mode&#8201;&#8212;&#8201;<code>deployMode</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">deployMode: String</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>deployMode</code> returns the current value of <a href="spark-deploy-mode.adoc">spark.submit.deployMode</a> setting or <code>client</code> if not set.</p>
</div>
</div>
<div class="sect2">
<h3 id="_scheduling_modegetschedulingmode_method"><a class="anchor" href="#_scheduling_modegetschedulingmode_method"></a><a id="getSchedulingMode"></a> Scheduling Mode&#8201;&#8212;&#8201;<code>getSchedulingMode</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getSchedulingMode: SchedulingMode.SchedulingMode</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getSchedulingMode</code> returns the current <a href="spark-scheduler-SchedulingMode.adoc">Scheduling Mode</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_schedulable_pool_by_namegetpoolforname_method"><a class="anchor" href="#_schedulable_pool_by_namegetpoolforname_method"></a><a id="getPoolForName"></a> Schedulable (Pool) by Name&#8201;&#8212;&#8201;<code>getPoolForName</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getPoolForName(pool: String): Option[Schedulable]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getPoolForName</code> returns a <a href="spark-scheduler-Schedulable.adoc">Schedulable</a> by the <code>pool</code> name, if one exists.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getPoolForName</code> is part of the Developer&#8217;s API and may change in the future.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, it requests the <a href="spark-scheduler-TaskScheduler.adoc#rootPool">TaskScheduler for the root pool</a> and <a href="spark-scheduler-Pool.adoc#schedulableNameToSchedulable">looks up the <code>Schedulable</code> by the <code>pool</code> name</a>.</p>
</div>
<div class="paragraph">
<p>It is exclusively used to <a href="spark-webui-PoolPage.adoc">show pool details in web UI (for a stage)</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_all_schedulable_poolsgetallpools_method"><a class="anchor" href="#_all_schedulable_poolsgetallpools_method"></a><a id="getAllPools"></a> All Schedulable Pools&#8201;&#8212;&#8201;<code>getAllPools</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getAllPools: Seq[Schedulable]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getAllPools</code> collects the <a href="spark-scheduler-Pool.adoc">Pools</a> in <a href="spark-scheduler-TaskScheduler.adoc#contract">TaskScheduler.rootPool</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>TaskScheduler.rootPool</code> is part of the <a href="spark-scheduler-TaskScheduler.adoc#contract">TaskScheduler Contract</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getAllPools</code> is part of the Developer&#8217;s API.
</td>
</tr>
</table>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Where is the method used?
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getAllPools</code> is used to calculate pool names for <a href="spark-webui-AllStagesPage.adoc#pool-names">Stages tab in web UI</a> with FAIR scheduling mode used.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_default_level_of_parallelism"><a class="anchor" href="#_default_level_of_parallelism"></a><a id="defaultParallelism"></a> Default Level of Parallelism</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">defaultParallelism: Int</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>defaultParallelism</code> requests <a href="#taskScheduler">TaskScheduler</a> for the <a href="spark-scheduler-TaskScheduler.adoc#defaultParallelism">default level of parallelism</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<strong>Default level of parallelism</strong> specifies the number of <a href="spark-rdd-partitions.adoc">partitions</a> in RDDs when created without specifying them explicitly by a user.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>defaultParallelism</code> is used in <a href="#parallelize">SparkContext.parallelize</a>, <code>SparkContext.range</code> and <a href="#makeRDD">SparkContext.makeRDD</a> (as well as Spark Streaming&#8217;s <code>DStream.countByValue</code> and <code>DStream.countByValueAndWindow</code> et al.).</p>
</div>
<div class="paragraph">
<p><code>defaultParallelism</code> is also used to instantiate <a href="spark-rdd-HashPartitioner.adoc">HashPartitioner</a> and for the minimum number of partitions in <a href="spark-rdd-HadoopRDD.adoc">HadoopRDDs</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_current_spark_scheduler_aka_taskschedulertaskscheduler_property"><a class="anchor" href="#_current_spark_scheduler_aka_taskschedulertaskscheduler_property"></a><a id="taskScheduler"></a> Current Spark Scheduler (aka TaskScheduler)&#8201;&#8212;&#8201;<code>taskScheduler</code> Property</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">taskScheduler: TaskScheduler
taskScheduler_=(ts: TaskScheduler): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>taskScheduler</code> manages (i.e. reads or writes) <a href="#_taskScheduler">_taskScheduler</a> internal property.</p>
</div>
</div>
<div class="sect2">
<h3 id="_getting_spark_versionversion_property"><a class="anchor" href="#_getting_spark_versionversion_property"></a><a id="version"></a> Getting Spark Version&#8201;&#8212;&#8201;<code>version</code> Property</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">version: String</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>version</code> returns the Spark version this <code>SparkContext</code> uses.</p>
</div>
</div>
<div class="sect2">
<h3 id="_makerdd_method"><a class="anchor" href="#_makerdd_method"></a><a id="makeRDD"></a> <code>makeRDD</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_jobs_asynchronouslysubmitjob_method"><a class="anchor" href="#_submitting_jobs_asynchronouslysubmitjob_method"></a><a id="submitJob"></a> Submitting Jobs Asynchronously&#8201;&#8212;&#8201;<code>submitJob</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitJob[T, U, R](
  rdd: RDD[T],
  processPartition: Iterator[T] =&gt; U,
  partitions: Seq[Int],
  resultHandler: (Int, U) =&gt; Unit,
  resultFunc: =&gt; R): SimpleFutureAction[R]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitJob</code> submits a job in an asynchronous, non-blocking way to <a href="spark-scheduler-DAGScheduler.adoc#submitJob">DAGScheduler</a>.</p>
</div>
<div class="paragraph">
<p>It cleans the <code>processPartition</code> input function argument and returns an instance of <a href="spark-rdd-actions.adoc#FutureAction">SimpleFutureAction</a> that holds the <a href="spark-scheduler-JobWaiter.adoc">JobWaiter</a> instance.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME What are <code>resultFunc</code>?
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>It is used in:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="spark-rdd-actions.adoc#AsyncRDDActions">AsyncRDDActions</a> methods</p>
</li>
<li>
<p><a href="spark-streaming/spark-streaming.adoc">Spark Streaming</a> for <a href="spark-streaming/spark-streaming-receivertracker.adoc#ReceiverTrackerEndpoint-startReceiver">ReceiverTrackerEndpoint.startReceiver</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_spark_configuration"><a class="anchor" href="#_spark_configuration"></a><a id="spark-configuration"></a> Spark Configuration</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_sparkcontext_and_rdds"><a class="anchor" href="#_sparkcontext_and_rdds"></a><a id="sparkcontext-and-rdd"></a> SparkContext and RDDs</h3>
<div class="paragraph">
<p>You use a Spark context to create RDDs (see <a href="#creating-rdds">Creating RDD</a>).</p>
</div>
<div class="paragraph">
<p>When an RDD is created, it belongs to and is completely owned by the Spark context it originated from. RDDs can&#8217;t by design be shared between SparkContexts.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/diagrams/sparkcontext-rdds.png" alt="sparkcontext rdds">
</div>
<div class="title">Figure 2. A Spark context creates a living space for RDDs.</div>
</div>
</div>
<div class="sect2">
<h3 id="_creating_rddparallelize_method"><a class="anchor" href="#_creating_rddparallelize_method"></a><a id="creating-rdds"></a><a id="parallelize"></a> Creating RDD&#8201;&#8212;&#8201;<code>parallelize</code> Method</h3>
<div class="paragraph">
<p><code>SparkContext</code> allows you to create many different RDDs from input sources like:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Scala&#8217;s collections, i.e. <code>sc.parallelize(0 to 100)</code></p>
</li>
<li>
<p>local or remote filesystems, i.e. <code>sc.textFile("README.md")</code></p>
</li>
<li>
<p>Any Hadoop <code>InputSource</code> using <code>sc.newAPIHadoopFile</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Read <a href="spark-rdd.adoc#creating-rdds">Creating RDDs</a> in <a href="spark-rdd.adoc">RDD - Resilient Distributed Dataset</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_unpersisting_rdd_marking_rdd_as_non_persistentunpersist_method"><a class="anchor" href="#_unpersisting_rdd_marking_rdd_as_non_persistentunpersist_method"></a><a id="unpersist"></a> Unpersisting RDD (Marking RDD as Non-Persistent)&#8201;&#8212;&#8201;<code>unpersist</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>unpersist</code> removes an RDD from the master&#8217;s <a href="spark-BlockManager.adoc">Block Manager</a> (calls <code>removeRdd(rddId: Int, blocking: Boolean)</code>) and the internal <a href="#persistentRdds">persistentRdds</a> mapping.</p>
</div>
<div class="paragraph">
<p>It finally posts <a href="spark-scheduler-SparkListener.adoc#SparkListenerUnpersistRDD">SparkListenerUnpersistRDD</a> message to <code>listenerBus</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_setting_checkpoint_directorysetcheckpointdir_method"><a class="anchor" href="#_setting_checkpoint_directorysetcheckpointdir_method"></a><a id="setCheckpointDir"></a> Setting Checkpoint Directory&#8201;&#8212;&#8201;<code>setCheckpointDir</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">setCheckpointDir(directory: String)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>setCheckpointDir</code> method is used to set up the checkpoint directory&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_registering_accumulatorregister_methods"><a class="anchor" href="#_registering_accumulatorregister_methods"></a><a id="register"></a> Registering Accumulator&#8201;&#8212;&#8201;<code>register</code> Methods</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">register(acc: AccumulatorV2[_, _]): Unit
register(acc: AccumulatorV2[_, _], name: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>register</code> registers the <code>acc</code> <a href="spark-accumulators.adoc">accumulator</a>. You can optionally give an accumulator a <code>name</code>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can create built-in accumulators for longs, doubles, and collection types using <a href="#creating-accumulators">specialized methods</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>register</code> <a href="spark-accumulators.adoc#register">registers <code>acc</code> accumulator</a> (with the current <code>SparkContext</code>).</p>
</div>
</div>
<div class="sect2">
<h3 id="_creating_built_in_accumulators"><a class="anchor" href="#_creating_built_in_accumulators"></a><a id="creating-accumulators"></a><a id="longAccumulator"></a><a id="doubleAccumulator"></a><a id="collectionAccumulator"></a> Creating Built-In Accumulators</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">longAccumulator: LongAccumulator
longAccumulator(name: String): LongAccumulator
doubleAccumulator: DoubleAccumulator
doubleAccumulator(name: String): DoubleAccumulator
collectionAccumulator[T]: CollectionAccumulator[T]
collectionAccumulator[T](name: String): CollectionAccumulator[T]</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use <code>longAccumulator</code>, <code>doubleAccumulator</code> or <code>collectionAccumulator</code> to create and register <a href="spark-accumulators.adoc">accumulators</a> for simple and collection values.</p>
</div>
<div class="paragraph">
<p><code>longAccumulator</code> returns <a href="spark-accumulators.adoc#LongAccumulator">LongAccumulator</a> with the zero value <code>0</code>.</p>
</div>
<div class="paragraph">
<p><code>doubleAccumulator</code> returns <a href="spark-accumulators.adoc#DoubleAccumulator">DoubleAccumulator</a> with the zero value <code>0.0</code>.</p>
</div>
<div class="paragraph">
<p><code>collectionAccumulator</code> returns <a href="spark-accumulators.adoc#CollectionAccumulator">CollectionAccumulator</a> with the zero value <code>java.util.List[T]</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">scala&gt; val acc = sc.longAccumulator
acc: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 0, name: None, value: 0)

scala&gt; val counter = sc.longAccumulator("counter")
counter: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1, name: Some(counter), value: 0)

scala&gt; counter.value
res0: Long = 0

scala&gt; sc.parallelize(0 to 9).foreach(n =&gt; counter.add(n))

scala&gt; counter.value
res3: Long = 45</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>name</code> input parameter allows you to give a name to an accumulator and have it displayed in <a href="spark-webui-StagePage.adoc#accumulators">Spark UI</a> (under Stages tab for a given stage).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-webui-accumulators.png" alt="spark webui accumulators">
</div>
<div class="title">Figure 3. Accumulators in the Spark UI</div>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
You can register custom accumulators using <a href="#register">register</a> methods.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_creating_broadcast_variablebroadcast_method"><a class="anchor" href="#_creating_broadcast_variablebroadcast_method"></a><a id="broadcast"></a> Creating Broadcast Variable&#8201;&#8212;&#8201;<code>broadcast</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">broadcast[T](value: T): Broadcast[T]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>broadcast</code> method creates a <a href="spark-broadcast.adoc">broadcast variable</a>. It is a shared memory with <code>value</code> (as broadcast blocks) on the driver and later on all Spark executors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>val sc: SparkContext = ???
scala&gt; val hello = sc.broadcast("hello")
hello: org.apache.spark.broadcast.Broadcast[String] = Broadcast(0)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Spark transfers the value to Spark executors <em>once</em>, and tasks can share it without incurring repetitive network transmissions when the broadcast variable is used multiple times.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/sparkcontext-broadcast-executors.png" alt="sparkcontext broadcast executors">
</div>
<div class="title">Figure 4. Broadcasting a value to executors</div>
</div>
<div class="paragraph">
<p>Internally, <code>broadcast</code> requests the <a href="spark-service-broadcastmanager.adoc#newBroadcast">current <code>BroadcastManager</code> to create a new broadcast variable</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The current <code>BroadcastManager</code> is available using <a href="spark-SparkEnv.adoc#broadcastManager"><code>SparkEnv.broadcastManager</code></a> attribute and is always <a href="spark-service-broadcastmanager.adoc">BroadcastManager</a> (with few internal configuration changes to reflect where it runs, i.e. inside the driver or executors).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: Created broadcast [id] from [callSite]</code></pre>
</div>
</div>
<div class="paragraph">
<p>If <code>ContextCleaner</code> is defined, the <a href="spark-service-contextcleaner.adoc#">new broadcast variable is registered for cleanup</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Spark does not support broadcasting RDDs.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>scala&gt; sc.broadcast(sc.range(0, 10))
java.lang.IllegalArgumentException: requirement failed: Can not directly broadcast RDDs; instead, call collect() and broadcast the result.
  at scala.Predef$.require(Predef.scala:224)
  at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1392)
  ... 48 elided</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once created, the broadcast variable (and other blocks) are displayed per executor and the driver in web UI (under <a href="spark-webui-executors.adoc">Executors tab</a>).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-broadcast-webui-executors-rdd-blocks.png" alt="spark broadcast webui executors rdd blocks">
</div>
<div class="title">Figure 5. Broadcast Variables In web UI&#8217;s Executors Tab</div>
</div>
</div>
<div class="sect2">
<h3 id="_distribute_jars_to_workers"><a class="anchor" href="#_distribute_jars_to_workers"></a><a id="jars"></a> Distribute JARs to workers</h3>
<div class="paragraph">
<p>The jar you specify with <code>SparkContext.addJar</code> will be copied to all the worker nodes.</p>
</div>
<div class="paragraph">
<p>The configuration setting <code>spark.jars</code> is a comma-separated list of jar paths to be included in all tasks executed from this SparkContext. A path can either be a local file, a file in HDFS (or other Hadoop-supported filesystems), an HTTP, HTTPS or FTP URI, or <code>local:/path</code> for a file on every worker node.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>scala&gt; sc.addJar("build.sbt")
15/11/11 21:54:54 INFO SparkContext: Added JAR build.sbt at http://192.168.1.4:49427/jars/build.sbt with timestamp 1447275294457</code></pre>
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Why is HttpFileServer used for addJar?
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_sparkcontext_as_application_wide_counter"><a class="anchor" href="#_sparkcontext_as_application_wide_counter"></a><code>SparkContext</code> as Application-Wide Counter</h3>
<div class="paragraph">
<p>SparkContext keeps track of:</p>
</div>
<div id="nextShuffleId" class="ulist">
<ul>
<li>
<p>shuffle ids using <code>nextShuffleId</code> internal counter for <a href="spark-scheduler-ShuffleMapStage.adoc">registering shuffle dependencies</a> to <a href="spark-shuffle-ShuffleManager.adoc">Shuffle Service</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_running_job_synchronouslyrunjob_methods"><a class="anchor" href="#_running_job_synchronouslyrunjob_methods"></a><a id="runJob"></a> Running Job Synchronously&#8201;&#8212;&#8201;<code>runJob</code> Methods</h3>
<div class="paragraph">
<p><a href="spark-rdd.adoc#actions">RDD actions</a> run <a href="spark-scheduler-ActiveJob.adoc">jobs</a> using one of <code>runJob</code> methods.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">runJob[T, U](
  rdd: RDD[T],
  func: (TaskContext, Iterator[T]) =&gt; U,
  partitions: Seq[Int],
  resultHandler: (Int, U) =&gt; Unit): Unit
runJob[T, U](
  rdd: RDD[T],
  func: (TaskContext, Iterator[T]) =&gt; U,
  partitions: Seq[Int]): Array[U]
runJob[T, U](
  rdd: RDD[T],
  func: Iterator[T] =&gt; U,
  partitions: Seq[Int]): Array[U]
runJob[T, U](rdd: RDD[T], func: (TaskContext, Iterator[T]) =&gt; U): Array[U]
runJob[T, U](rdd: RDD[T], func: Iterator[T] =&gt; U): Array[U]
runJob[T, U](
  rdd: RDD[T],
  processPartition: (TaskContext, Iterator[T]) =&gt; U,
  resultHandler: (Int, U) =&gt; Unit)
runJob[T, U: ClassTag](
  rdd: RDD[T],
  processPartition: Iterator[T] =&gt; U,
  resultHandler: (Int, U) =&gt; Unit)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runJob</code> executes a function on one or many partitions of a RDD (in a <code>SparkContext</code> space) to produce a collection of values per partition.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runJob</code> can only work when a <code>SparkContext</code> is <em>not</em> <a href="#stop">stopped</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Internally, <code>runJob</code> first makes sure that the <code>SparkContext</code> is not <a href="#stop">stopped</a>. If it is, you should see the following <code>IllegalStateException</code> exception in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>java.lang.IllegalStateException: SparkContext has been shutdown
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1893)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1914)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1934)
  ... 48 elided</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runJob</code> then <a href="#getCallSite">calculates the call site</a> and <a href="#clean">cleans a <code>func</code> closure</a>.</p>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: Starting job: [callSite]</code></pre>
</div>
</div>
<div class="paragraph">
<p>With <a href="spark-rdd-lineage.adoc#spark_logLineage">spark.logLineage</a> enabled (which is not by default), you should see the following INFO message with <a href="spark-rdd-lineage.adoc#toDebugString">toDebugString</a> (executed on <code>rdd</code>):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: RDD's recursive dependencies:
[toDebugString]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runJob</code> requests  <a href="spark-scheduler-DAGScheduler.adoc#runJob"><code>DAGScheduler</code> to run a job</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<code>runJob</code> just prepares input parameters for <a href="spark-scheduler-DAGScheduler.adoc#runJob"><code>DAGScheduler</code> to run a job</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After <code>DAGScheduler</code> is done and the job has finished, <code>runJob</code> <a href="spark-sparkcontext-ConsoleProgressBar.adoc#finishAll">stops <code>ConsoleProgressBar</code></a> and <a href="spark-rdd-checkpointing.adoc#doCheckpoint">performs RDD checkpointing of <code>rdd</code></a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
For some actions, e.g. <code>first()</code> and <code>lookup()</code>, there is no need to compute all the partitions of the RDD in a job. And Spark knows it.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">// RDD to work with
val lines = sc.parallelize(Seq("hello world", "nice to see you"))

import org.apache.spark.TaskContext
scala&gt; sc.runJob(lines, (t: TaskContext, i: Iterator[String]) =&gt; 1) <i class="conum" data-value="1"></i><b>(1)</b>
res0: Array[Int] = Array(1, 1)  <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Run a job using <code>runJob</code> on <code>lines</code> RDD with a function that returns 1 for every partition (of <code>lines</code> RDD).</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>What can you say about the number of partitions of the <code>lines</code> RDD? Is your result <code>res0</code> different than mine? Why?</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Read <a href="spark-TaskContext.adoc">TaskContext</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Running a job is essentially executing a <code>func</code> function on all or a subset of partitions in an <code>rdd</code> RDD and returning the result as an array (with elements being the results per partition).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-runjob.png" alt="spark runjob">
</div>
<div class="title">Figure 6. Executing action</div>
</div>
</div>
<div class="sect2">
<h3 id="_stopping_sparkcontextstop_method"><a class="anchor" href="#_stopping_sparkcontextstop_method"></a><a id="stop"></a><a id="stopping"></a> Stopping <code>SparkContext</code>&#8201;&#8212;&#8201;<code>stop</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">stop(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>stop</code> stops the <code>SparkContext</code>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>stop</code> enables <code>stopped</code> internal flag. If already stopped, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: SparkContext already stopped.</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>stop</code> then does the following:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Removes <code>_shutdownHookRef</code> from <code>ShutdownHookManager</code></p>
</li>
<li>
<p><a href="#postApplicationEnd">Posts a <code>SparkListenerApplicationEnd</code></a> (to <a href="#listenerBus">LiveListenerBus Event Bus</a>)</p>
</li>
<li>
<p><a href="spark-webui-SparkUI.adoc#stop">Stops web UI</a></p>
</li>
<li>
<p><a href="spark-metrics-MetricsSystem.adoc#report">Requests <code>MetricSystem</code> to report metrics</a> (from all registered sinks)</p>
</li>
<li>
<p><a href="spark-service-contextcleaner.adoc#stop">Stops <code>ContextCleaner</code></a></p>
</li>
<li>
<p><a href="spark-ExecutorAllocationManager.adoc#stop">Requests <code>ExecutorAllocationManager</code> to stop</a></p>
</li>
<li>
<p>If <code>LiveListenerBus</code> was started, <a href="spark-scheduler-LiveListenerBus.adoc#stop">requests <code>LiveListenerBus</code> to stop</a></p>
</li>
<li>
<p>Requests <a href="spark-SparkListener-EventLoggingListener.adoc#stop"><code>EventLoggingListener</code> to stop</a></p>
</li>
<li>
<p>Requests <a href="spark-scheduler-DAGScheduler.adoc#stop"><code>DAGScheduler</code> to stop</a></p>
</li>
<li>
<p>Requests <a href="spark-rpc.adoc#stop">RpcEnv to stop <code>HeartbeatReceiver</code> endpoint</a></p>
</li>
<li>
<p>Requests <a href="spark-sparkcontext-ConsoleProgressBar.adoc#stop"><code>ConsoleProgressBar</code> to stop</a></p>
</li>
<li>
<p>Clears the reference to <code>TaskScheduler</code>, i.e. <code>_taskScheduler</code> is <code>null</code></p>
</li>
<li>
<p>Requests <a href="spark-SparkEnv.adoc#stop"><code>SparkEnv</code> to stop</a> and clears <code>SparkEnv</code></p>
</li>
<li>
<p>Clears <a href="yarn/spark-yarn-client.adoc#SPARK_YARN_MODE"><code>SPARK_YARN_MODE</code> flag</a></p>
</li>
<li>
<p><a href="#clearActiveContext">Clears an active <code>SparkContext</code></a></p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Ultimately, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO SparkContext: Successfully stopped SparkContext</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_registering_sparklisteneraddsparklistener_method"><a class="anchor" href="#_registering_sparklisteneraddsparklistener_method"></a><a id="addSparkListener"></a> Registering SparkListener&#8201;&#8212;&#8201;<code>addSparkListener</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">addSparkListener(listener: SparkListenerInterface): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can register a custom <a href="spark-scheduler-SparkListener.adoc#SparkListenerInterface">SparkListenerInterface</a> using <code>addSparkListener</code> method</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You can also register custom listeners using <a href="spark-scheduler-LiveListenerBus.adoc#spark_extraListeners">spark.extraListeners</a> setting.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_custom_schedulerbackend_taskscheduler_and_dagscheduler"><a class="anchor" href="#_custom_schedulerbackend_taskscheduler_and_dagscheduler"></a><a id="custom-schedulers"></a> Custom SchedulerBackend, TaskScheduler and DAGScheduler</h3>
<div class="paragraph">
<p>By default, SparkContext uses (<code>private[spark]</code> class) <code>org.apache.spark.scheduler.DAGScheduler</code>, but you can develop your own custom DAGScheduler implementation, and use (<code>private[spark]</code>) <code>SparkContext.dagScheduler_=(ds: DAGScheduler)</code> method to assign yours.</p>
</div>
<div class="paragraph">
<p>It is also applicable to <code>SchedulerBackend</code> and <code>TaskScheduler</code> using <code>schedulerBackend_=(sb: SchedulerBackend)</code> and <code>taskScheduler_=(ts: TaskScheduler)</code> methods, respectively.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Make it an advanced exercise.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_events"><a class="anchor" href="#_events"></a><a id="events"></a> Events</h3>
<div class="paragraph">
<p>When a Spark context starts, it triggers <a href="spark-scheduler-SparkListener.adoc#SparkListenerEnvironmentUpdate">SparkListenerEnvironmentUpdate</a> and <a href="spark-scheduler-SparkListener.adoc#SparkListenerApplicationStart">SparkListenerApplicationStart</a> messages.</p>
</div>
<div class="paragraph">
<p>Refer to the section <a href="#creating-instance">SparkContext&#8217;s initialization</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_setting_default_logging_levelsetloglevel_method"><a class="anchor" href="#_setting_default_logging_levelsetloglevel_method"></a><a id="setLogLevel"></a><a id="setting-default-log-level"></a> Setting Default Logging Level&#8201;&#8212;&#8201;<code>setLogLevel</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">setLogLevel(logLevel: String)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>setLogLevel</code> allows you to set the root logging level in a Spark application, e.g. <a href="spark-shell.adoc">Spark shell</a>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>setLogLevel</code> calls <a href="http://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/Level.html#toLevel(java.lang.String)">org.apache.log4j.Level.toLevel(logLevel)</a> that it then uses to set using <a href="http://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/LogManager.html#getRootLogger()">org.apache.log4j.LogManager.getRootLogger().setLevel(level)</a>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can directly set the logging level using <a href="http://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/LogManager.html#getLogger()">org.apache.log4j.LogManager.getLogger()</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">LogManager.getLogger("org").setLevel(Level.OFF)</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_closure_cleaningclean_method"><a class="anchor" href="#_closure_cleaningclean_method"></a><a id="clean"></a><a id="closure-cleaning"></a> Closure Cleaning&#8201;&#8212;&#8201;<code>clean</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">clean(f: F, checkSerializable: Boolean = true): F</code></pre>
</div>
</div>
<div class="paragraph">
<p>Every time an action is called, Spark cleans up the closure, i.e. the body of the action, before it is serialized and sent over the wire to executors.</p>
</div>
<div class="paragraph">
<p>SparkContext comes with <code>clean(f: F, checkSerializable: Boolean = true)</code> method that does this. It in turn calls <code>ClosureCleaner.clean</code> method.</p>
</div>
<div class="paragraph">
<p>Not only does <code>ClosureCleaner.clean</code> method clean the closure, but also does it transitively, i.e. referenced closures are cleaned transitively.</p>
</div>
<div class="paragraph">
<p>A closure is considered serializable as long as it does not explicitly reference unserializable objects. It does so by traversing the hierarchy of enclosing closures and null out any references that are not actually used by the starting closure.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Enable <code>DEBUG</code> logging level for <code>org.apache.spark.util.ClosureCleaner</code> logger to see what happens inside the class.</p>
</div>
<div class="paragraph">
<p>Add the following line to <code>conf/log4j.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>log4j.logger.org.apache.spark.util.ClosureCleaner=DEBUG</code></pre>
</div>
</div>
<div class="paragraph">
<p>Refer to <a href="spark-logging.adoc">Logging</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>With <code>DEBUG</code> logging level you should see the following messages in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>+++ Cleaning closure [func] ([func.getClass.getName]) +++
 + declared fields: [declaredFields.size]
     [field]
 ...
+++ closure [func] ([func.getClass.getName]) is now cleaned +++</code></pre>
</div>
</div>
<div class="paragraph">
<p>Serialization is verified using a new instance of <code>Serializer</code> (as <a href="spark-SparkEnv.adoc#closureSerializer">closure Serializer</a>). Refer to <a href="spark-serialization.adoc">Serialization</a>.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME an example, please.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_hadoop_configuration"><a class="anchor" href="#_hadoop_configuration"></a><a id="hadoopConfiguration"></a> Hadoop Configuration</h3>
<div class="paragraph">
<p>While a <a href="#creating-instance"><code>SparkContext</code> is being created</a>, so is a Hadoop configuration (as an instance of <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/conf/Configuration.html">org.apache.hadoop.conf.Configuration</a> that is available as <code>_hadoopConfiguration</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-SparkHadoopUtil.adoc#newConfiguration">SparkHadoopUtil.get.newConfiguration</a> is used.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If a SparkConf is provided it is used to build the configuration as described. Otherwise, the default <code>Configuration</code> object is returned.</p>
</div>
<div class="paragraph">
<p>If <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> are both available, the following settings are set for the Hadoop configuration:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>fs.s3.awsAccessKeyId</code>, <code>fs.s3n.awsAccessKeyId</code>, <code>fs.s3a.access.key</code> are set to the value of <code>AWS_ACCESS_KEY_ID</code></p>
</li>
<li>
<p><code>fs.s3.awsSecretAccessKey</code>, <code>fs.s3n.awsSecretAccessKey</code>, and <code>fs.s3a.secret.key</code> are set to the value of <code>AWS_SECRET_ACCESS_KEY</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Every <code>spark.hadoop.</code> setting becomes a setting of the configuration with the prefix <code>spark.hadoop.</code> removed for the key.</p>
</div>
<div class="paragraph">
<p>The value of <code>spark.buffer.size</code> (default: <code>65536</code>) is used as the value of <code>io.file.buffer.size</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_listenerbuslivelistenerbus_event_bus"><a class="anchor" href="#_listenerbuslivelistenerbus_event_bus"></a><a id="listenerBus"></a> <code>listenerBus</code>&#8201;&#8212;&#8201;<code>LiveListenerBus</code> Event Bus</h3>
<div class="paragraph">
<p><code>listenerBus</code> is a <a href="spark-scheduler-LiveListenerBus.adoc">LiveListenerBus</a> object that acts as a mechanism to announce events to other services on the <a href="spark-driver.adoc">driver</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It is created and started when <a href="spark-SparkContext-creating-instance-internals.adoc">SparkContext starts</a> and, since it is a single-JVM event bus, is exclusively used on the driver.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>listenerBus</code> is a <code>private[spark]</code> value in <code>SparkContext</code>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_time_when_sparkcontext_was_createdstarttime_property"><a class="anchor" href="#_time_when_sparkcontext_was_createdstarttime_property"></a><a id="startTime"></a> Time when <code>SparkContext</code> was Created&#8201;&#8212;&#8201;<code>startTime</code> Property</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">startTime: Long</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>startTime</code> is the time in milliseconds when <a href="#creating-instance">SparkContext was created</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">scala&gt; sc.startTime
res0: Long = 1464425605653</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_spark_usersparkuser_property"><a class="anchor" href="#_spark_usersparkuser_property"></a><a id="sparkUser"></a> Spark User&#8201;&#8212;&#8201;<code>sparkUser</code> Property</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">sparkUser: String</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>sparkUser</code> is the user who started the <code>SparkContext</code> instance.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It is computed when <a href="spark-SparkContext-creating-instance-internals.adoc#sparkUser">SparkContext is created</a> using <a href="spark-SparkContext-creating-instance-internals.adoc#">Utils.getCurrentUserName</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_submitting_shuffledependency_for_executionsubmitmapstage_internal_method"><a class="anchor" href="#_submitting_shuffledependency_for_executionsubmitmapstage_internal_method"></a><a id="submitMapStage"></a> Submitting <code>ShuffleDependency</code> for Execution&#8201;&#8212;&#8201;<code>submitMapStage</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">submitMapStage[K, V, C](
  dependency: ShuffleDependency[K, V, C]): SimpleFutureAction[MapOutputStatistics]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>submitMapStage</code> <a href="spark-scheduler-DAGScheduler.adoc#submitMapStage">submits the input <code>ShuffleDependency</code> to <code>DAGScheduler</code> for execution</a> and returns a <code>SimpleFutureAction</code>.</p>
</div>
<div class="paragraph">
<p>Internally, <code>submitMapStage</code> <a href="#getCallSite">calculates the call site</a> first and submits it with <code>localProperties</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Interestingly, <code>submitMapStage</code> is used exclusively when Spark SQL&#8217;s <a href="spark-sql-SparkPlan-ShuffleExchange.adoc">ShuffleExchange</a> physical operator is executed.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>submitMapStage</code> <em>seems</em> related to <a href="spark-scheduler-DAGScheduler.adoc#adaptive-query-planning">Adaptive Query Planning / Adaptive Scheduling</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_calculating_call_sitegetcallsite_method"><a class="anchor" href="#_calculating_call_sitegetcallsite_method"></a><a id="getCallSite"></a> Calculating Call Site&#8201;&#8212;&#8201;<code>getCallSite</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cancelling_job_groupcanceljobgroup_method"><a class="anchor" href="#_cancelling_job_groupcanceljobgroup_method"></a><a id="cancelJobGroup"></a> Cancelling Job Group&#8201;&#8212;&#8201;<code>cancelJobGroup</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cancelJobGroup(groupId: String)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cancelJobGroup</code> requests <code>DAGScheduler</code> <a href="spark-scheduler-DAGScheduler.adoc#cancelJobGroup">to cancel a group of active Spark jobs</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelJobGroup</code> is used exclusively when <code>SparkExecuteStatementOperation</code> does <code>cancel</code>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cancelling_all_running_and_scheduled_jobscancelalljobs_method"><a class="anchor" href="#_cancelling_all_running_and_scheduled_jobscancelalljobs_method"></a><a id="cancelAllJobs"></a> Cancelling All Running and Scheduled Jobs&#8201;&#8212;&#8201;<code>cancelAllJobs</code> Method</h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>cancelAllJobs</code> is used when <a href="spark-shell.adoc">spark-shell</a> is terminated (e.g. using Ctrl+C, so it can in turn terminate all active Spark jobs) or <code>SparkSQLCLIDriver</code> is terminated.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_setting_local_properties_to_group_spark_jobssetjobgroup_method"><a class="anchor" href="#_setting_local_properties_to_group_spark_jobssetjobgroup_method"></a><a id="setJobGroup"></a> Setting Local Properties to Group Spark Jobs&#8201;&#8212;&#8201;<code>setJobGroup</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">setJobGroup(
  groupId: String,
  description: String,
  interruptOnCancel: Boolean = false): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>setJobGroup</code> <a href="spark-sparkcontext-local-properties.adoc#setLocalProperty">sets local properties</a>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>spark.jobGroup.id</code> as <code>groupId</code></p>
</li>
<li>
<p><code>spark.job.description</code> as <code>description</code></p>
</li>
<li>
<p><code>spark.job.interruptOnCancel</code> as <code>interruptOnCancel</code></p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>setJobGroup</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Spark Thrift Server&#8217;s <code>SparkExecuteStatementOperation</code> runs a query</p>
</li>
<li>
<p>Structured Streaming&#8217;s <code>StreamExecution</code> runs batches</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_cleaner_method"><a class="anchor" href="#_cleaner_method"></a><a id="cleaner"></a> <code>cleaner</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">cleaner: Option[ContextCleaner]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>cleaner</code> is a <code>private[spark]</code> method to get the optional application-wide <a href="spark-service-contextcleaner.adoc">ContextCleaner</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-service-contextcleaner.adoc#creating-instance"><code>ContextCleaner</code> is created</a> when <a href="spark-SparkContext-creating-instance-internals.adoc#_cleaner"><code>SparkContext</code> is created with <code>spark.cleaner.referenceTracking</code> Spark property enabled</a> (which it is by default).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_finding_preferred_locations_placement_preferences_for_rdd_partitiongetpreferredlocs_method"><a class="anchor" href="#_finding_preferred_locations_placement_preferences_for_rdd_partitiongetpreferredlocs_method"></a><a id="getPreferredLocs"></a> Finding Preferred Locations (Placement Preferences) for RDD Partition&#8201;&#8212;&#8201;<code>getPreferredLocs</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getPreferredLocs(rdd: RDD[_], partition: Int): Seq[TaskLocation]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getPreferredLocs</code> simply <a href="spark-scheduler-DAGScheduler.adoc#getPreferredLocs">requests <code>DAGScheduler</code> for the preferred locations for <code>partition</code></a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Preferred locations of a partition of a RDD are also called <strong>placement preferences</strong> or <strong>locality preferences</strong>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getPreferredLocs</code> is used in <code>CoalescedRDDPartition</code>, <code>DefaultPartitionCoalescer</code> and <code>PartitionerAwareUnionRDD</code>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_registering_rdd_in_persistentrdds_internal_registrypersistrdd_internal_method"><a class="anchor" href="#_registering_rdd_in_persistentrdds_internal_registrypersistrdd_internal_method"></a><a id="persistRDD"></a> Registering RDD in persistentRdds Internal Registry&#8201;&#8212;&#8201;<code>persistRDD</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">persistRDD(rdd: RDD[_]): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>persistRDD</code> registers <code>rdd</code> in <a href="#persistentRdds">persistentRdds</a> internal registry.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>persistRDD</code> is used exclusively when <code>RDD</code> is <a href="spark-rdd.adoc#persist-internal">persisted or locally checkpointed</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_getting_storage_status_of_cached_rdds_as_rddinfosgetrddstorageinfo_methods"><a class="anchor" href="#_getting_storage_status_of_cached_rdds_as_rddinfosgetrddstorageinfo_methods"></a><a id="getRDDStorageInfo"></a> Getting Storage Status of Cached RDDs (as RDDInfos)&#8201;&#8212;&#8201;<code>getRDDStorageInfo</code> Methods</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getRDDStorageInfo: Array[RDDInfo] <i class="conum" data-value="1"></i><b>(1)</b>
getRDDStorageInfo(filter: RDD[_] =&gt; Boolean): Array[RDDInfo]  <i class="conum" data-value="2"></i><b>(2)</b></code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Part of Spark&#8217;s Developer API that uses &lt;2&gt; filtering no RDDs</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>getRDDStorageInfo</code> takes all the RDDs (from <a href="#persistentRdds">persistentRdds</a> registry) that match <code>filter</code> and creates a collection of <a href="spark-core-RDDInfo.adoc">RDDInfo</a> instances.</p>
</div>
<div class="paragraph">
<p><code>getRDDStorageInfo</code> then <a href="spark-webui-StorageListener.adoc#StorageUtils.updateRddInfo">updates the RDDInfos</a> with the <a href="#getExecutorStorageStatus">current status of all BlockManagers</a> (in a Spark application).</p>
</div>
<div class="paragraph">
<p>In the end, <code>getRDDStorageInfo</code> gives only the RDD that are cached (i.e. the sum of memory and disk sizes as well as the number of partitions cached are greater than <code>0</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>getRDDStorageInfo</code> is used when <code>RDD</code> <a href="spark-rdd-lineage.adoc#toDebugString">is requested for RDD lineage graph</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_settings"><a class="anchor" href="#_settings"></a><a id="settings"></a> Settings</h3>
<div class="sect3">
<h4 id="_spark_driver_allowmultiplecontexts"><a class="anchor" href="#_spark_driver_allowmultiplecontexts"></a><a id="spark.driver.allowMultipleContexts"></a> spark.driver.allowMultipleContexts</h4>
<div class="paragraph">
<p>Quoting the scaladoc of  <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.SparkContext">org.apache.spark.SparkContext</a>:</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>Only one SparkContext may be active per JVM. You must <code>stop()</code> the active SparkContext before creating a new one.</p>
</div>
</blockquote>
</div>
<div class="paragraph">
<p>You can however control the behaviour using <code>spark.driver.allowMultipleContexts</code> flag.</p>
</div>
<div class="paragraph">
<p>It is disabled, i.e. <code>false</code>, by default.</p>
</div>
<div class="paragraph">
<p>If enabled (i.e. <code>true</code>), Spark prints the following WARN message to the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>WARN Multiple running SparkContexts detected in the same JVM!</code></pre>
</div>
</div>
<div class="paragraph">
<p>If disabled (default), it will throw an <code>SparkException</code> exception:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
[ctx.creationSite.longForm]</code></pre>
</div>
</div>
<div class="paragraph">
<p>When creating an instance of <code>SparkContext</code>, Spark marks the current thread as having it being created (very early in the instantiation process).</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
It&#8217;s not guaranteed that Spark will work properly with two or more SparkContexts. Consider the feature a work in progress.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_accessing_appstatusstorestatusstore_method"><a class="anchor" href="#_accessing_appstatusstorestatusstore_method"></a><a id="statusStore"></a> Accessing AppStatusStore&#8201;&#8212;&#8201;<code>statusStore</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">statusStore: AppStatusStore</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>statusStore</code> gives the current <a href="spark-SparkContext-creating-instance-internals.adoc#_statusStore">AppStatusStore</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><code>statusStore</code> is used when:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ConsoleProgressBar</code> is requested to <a href="spark-sparkcontext-ConsoleProgressBar.adoc#refresh">refresh</a></p>
</li>
<li>
<p>Spark SQL&#8217;s <code>SharedState</code> is requested for a <code>SQLAppStatusStore</code> (as <code>statusStore</code>)</p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_requesting_url_of_web_uiuiweburl_method"><a class="anchor" href="#_requesting_url_of_web_uiuiweburl_method"></a><a id="uiWebUrl"></a> Requesting URL of web UI&#8201;&#8212;&#8201;<code>uiWebUrl</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">uiWebUrl: Option[String]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>uiWebUrl</code> requests the <a href="spark-SparkContext-creating-instance-internals.adoc#_ui">SparkUI</a> for <a href="spark-webui-WebUI.adoc#webUrl">webUrl</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_maxnumconcurrenttasks_method"><a class="anchor" href="#_maxnumconcurrenttasks_method"></a><a id="maxNumConcurrentTasks"></a> <code>maxNumConcurrentTasks</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">maxNumConcurrentTasks(): Int</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>maxNumConcurrentTasks</code> simply requests the <a href="#schedulerBackend">SchedulerBackend</a> for the <a href="spark-SchedulerBackend.html#maxNumConcurrentTasks" class="page">maximum number of tasks that can be launched concurrently</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>maxNumConcurrentTasks</code> is used exclusively when <code>DAGScheduler</code> is requested to <a href="spark-scheduler-DAGScheduler.html#checkBarrierStageWithNumSlots" class="page">checkBarrierStageWithNumSlots</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_creating_schedulerbackend_and_taskschedulercreatetaskscheduler_internal_factory_method"><a class="anchor" href="#_creating_schedulerbackend_and_taskschedulercreatetaskscheduler_internal_factory_method"></a><a id="createTaskScheduler"></a> Creating SchedulerBackend and TaskScheduler&#8201;&#8212;&#8201;<code>createTaskScheduler</code> Internal Factory Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">createTaskScheduler(
  sc: SparkContext,
  master: String,
  deployMode: String): (SchedulerBackend, TaskScheduler)</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>createTaskScheduler</code> creates the <a href="spark-SchedulerBackend.html" class="page">SchedulerBackend</a> and the <a href="spark-scheduler-TaskScheduler.html" class="page">TaskScheduler</a> for the given master URL and deployment mode.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/diagrams/sparkcontext-createtaskscheduler.png" alt="sparkcontext createtaskscheduler">
</div>
<div class="title">Figure 7. SparkContext creates Task Scheduler and Scheduler Backend</div>
</div>
<div class="paragraph">
<p>Internally, <code>createTaskScheduler</code> branches off per the given master URL (<a href="spark-deployment-environments.adoc#master-urls">master URL</a>) to select the requested implementations.</p>
</div>
<div class="paragraph">
<p><code>createTaskScheduler</code> understands the following master URLs:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>local</code> - local mode with 1 thread only</p>
</li>
<li>
<p><code>local[n]</code> or <code>local[*]</code> - local mode with <code>n</code> threads</p>
</li>
<li>
<p><code>local[n, m]</code> or <code>local[*, m]</code>&#8201;&#8212;&#8201;local mode with <code>n</code> threads and <code>m</code> number of failures</p>
</li>
<li>
<p><code>spark://hostname:port</code> for Spark Standalone</p>
</li>
<li>
<p><code>local-cluster[n, m, z]</code>&#8201;&#8212;&#8201;local cluster with <code>n</code> workers, <code>m</code> cores per worker, and <code>z</code> memory per worker</p>
</li>
<li>
<p>any other URL is passed to <a href="#getClusterManager"><code>getClusterManager</code> to load an external cluster manager</a>.</p>
</li>
</ul>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_environment_variables"><a class="anchor" href="#_environment_variables"></a><a id="environment-variables"></a> Environment Variables</h3>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Environment Variables</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Environment Variable</th>
<th class="tableblock halign-left valign-top">Default Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="SPARK_EXECUTOR_MEMORY"></a> <code>SPARK_EXECUTOR_MEMORY</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>1024</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Amount of memory to allocate for a Spark executor in  MB.</p>
<p class="tableblock">See <a href="spark-Executor.adoc#memory">Executor Memory</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="SPARK_USER"></a> <code>SPARK_USER</code></p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The user who is running <code>SparkContext</code>. Available later as <a href="#sparkUser">sparkUser</a>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_posting_sparklistenerenvironmentupdate_event_to_livelistenerbuspostenvironmentupdate_internal_method"><a class="anchor" href="#_posting_sparklistenerenvironmentupdate_event_to_livelistenerbuspostenvironmentupdate_internal_method"></a><a id="postEnvironmentUpdate"></a> Posting SparkListenerEnvironmentUpdate Event to LiveListenerBus&#8201;&#8212;&#8201;<code>postEnvironmentUpdate</code> Internal Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">postEnvironmentUpdate(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>postEnvironmentUpdate</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>postEnvironmentUpdate</code> is used when <code>SparkContext</code> is <a href="spark-SparkContext-creating-instance-internals.html#postEnvironmentUpdate" class="page">created</a>, and requested to <a href="#addFile">addFile</a> and <a href="#addJar">addJar</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_addjar_method"><a class="anchor" href="#_addjar_method"></a><a id="addJar-internals"></a> <code>addJar</code> Method</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">addJar(path: String): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>addJar</code>&#8230;&#8203;FIXME</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>addJar</code> is used when&#8230;&#8203;FIXME
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</article>
</main>
</div>
<footer class="footer">
  <p>This page was built using the Antora default UI.</p>
  <p>The source code for this UI is licensed under the terms of the MPL-2.0 license.</p>
</footer>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
