<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hadoop Hbase Hive Spark Kylin 配置 Kerberos :: The Cuddly Computing Machine</title>
    <link rel="canonical" href="http://alexwangx.github.io/cuddly-blog/1.2/hadoop/hadoop_krb_install.html">
    <meta name="generator" content="Antora 2.3.1">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86782445-1"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','UA-86782445-1')</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="http://alexwangx.github.io">The Cuddly Computing Machine</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/alexwangx">GitHub</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="cuddly-blog" data-version="1.2">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Cuddly Blog</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Flink</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../flink/training/index.html">Flink Training Home</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Streaming 介绍</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/intro/intro-1.html">使用Apache Flink 进行流处理</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/intro/intro-2.html">流可以传输什么?</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/intro/intro-3.html">一个完整的例子</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">环境配置</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/labs/devEnvSetup.html">设置您的开发环境</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/labs/taxiData.html">使用出租车数据流</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/labs/howto-exercises.html">如何做实验室</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/training/lab1/rideCleansing.html">Lab 1 - 过滤流</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">数据转换</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab1/stateless.html">无状态转换</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab1/keyed-streams.html">Keyed 流</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab1/stateful.html">有状态的转换</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab1/connected-streams.html">连接流</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/training/lab2/rideEnrichment-flatmap.html">Lab 2 - Stateful Enrichment</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">时间和分析</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab3/event-time-watermarks.html">Event Time and Watermarks</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab3/windows.html">Windows</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Lab 3 - Windowing</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab3/hourlyTips.html">Lab 3 - 窗口化分析</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab3/hourlyTips-discussion.html">Lab 3 - 讨论</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">事件驱动的应用</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab4/processfunction.html">ProcessFunction</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab4/side-outputs.html">Side Outputs</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Lab 4 - 到期状态</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab4/rideEnrichment-processfunction.html">Lab 4 - 练习</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/lab4/expiring-state-discussion.html">Lab 4 - 讨论</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">容错能力</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/fault/state-backends.html">状态后端</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/fault/snapshots.html">检查点和保存点</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/training/app-dev.html">应用开发</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">其他练习</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/extra-labs/longRides.html">长途警报</a>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">广播状态</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../flink/training/extra-labs/nearestTaxi.html">寻找最近的出租车</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../flink/training/extra-labs/ongoingRides.html">报告正在进行的出租车</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../flink/training/extra-labs/taxiQuery.html">规则引擎</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../flink/training/extra-labs/eventTimeJoin.html">丰富的 Joins</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/training/resources.html">资源链接</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../flink/introduction/index.html">Flink 简介</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/architecture.html">Flink 架构介绍</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/failover.html">Flink 容错机制</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/scheduling.html">Flink 调度机制</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/statemachine.html">Flink 状态机</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/memorymanager.html">Flink 内存管理</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/dataflow.html">Flink Dataflow</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/batchdata.html">Flink 批处理</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../flink/introduction/streamdata.html">Flink 流处理</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../flink/internals/index.html">Flink 学习笔记</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Spark</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Spark ops</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark/ops/spark-exitcode.html">Spark 任务退出码</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark/ops/spark-issues.html">Spark 常见错误</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="https://alexwangx.github.io/apache-spark-internals/2.4.5/">Spark 2.4.4 架构原理</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Hadoop</span>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="hadoop_krb_install.html">Hadoop 配置 Kerberos</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Hadoop ops</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="hdp-ops/hadoop_commands.html">Hadoop Commands</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="hdp-ops/hadoop_practices.html">Hadoop Practices</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="hdp-ops/hadoop_jmx.html">Hadoop JMX</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="hdp-ops/hadoop_delroot.html">Hadoop 意外删除挽救</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="hdp-ops/delrmstore_onzk.html">删除ZK上的rmstore目录</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Hbase</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Hbase ops</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../hbase/hbase-ops/hbase_notes.html">Hbase 基本命令</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../hbase/hbase-ops/hbase_issues.html">Hbase Issues</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Druid</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../druid/druid-install.html">Druid 安装</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../druid/ops/druid-restApi.html">Druid RestApi</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Druid 架构</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../druid/druid-internals/tutorial-load-data.html">Druid 导入数据</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../druid/druid-internals/tutorial-load-data1.html">Druid Json 配置介绍</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/druid-internals.html">Druid 0.1.5 架构</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/broker.html">Druid Broker</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/coordinator.html">Druid Coordinator</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/historical.html">Druid Historical</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/middleManager.html">Druid MiddleManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/overlord.html">Druid Overlord</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/router.html">Druid Router</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../druid/druid-internals/segment.html">Druid Segments</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Kafka</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../kafka/kafka_practices.html">Kafka Practices</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../kafka/kafka_issues.html">Kafka Issues</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Other</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../mac.html">Mac OS</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../linux.html">Linux</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../mysql_install.html">Mysql 安装</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../readlist.html">北京中小学孩子读书清单</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../demo/demo.html">Adoc Demo</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Cuddly Blog</span>
    <span class="version">1.2</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Cuddly Blog</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.2</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main>
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Cuddly Blog</a></li>
    <li>Hadoop</li>
    <li><a href="hadoop_krb_install.html">Hadoop 配置 Kerberos</a></li>
  </ul>
</nav>
</div>
<article class="doc">
<h1 class="page">Hadoop Hbase Hive Spark Kylin 配置 Kerberos</h1>
<div id="preamble">
<div class="sectionbody">
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="ulist">
<ul>
<li>
<p>转载: 请附上原文出处链接.</p>
</li>
<li>
<p><a href="https://github.com/alexwangx/alexwangx.github.io/issues" target="_blank" rel="noopener">点击留言</a></p>
</li>
</ul>
</div>
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
文档内容请自行测试之后上生产.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>kdc 数据存储到 ldap 中, hadoop可自行配置 ldap 用户权限管理, 软件编译自行解决.</p>
<div class="ulist">
<ul>
<li>
<p>hadoop 重新编译, container-executor <a href="https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/SecureContainer.html">参考官网</a></p>
</li>
<li>
<p>jsvc <a href="https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-common/SecureMode.html">参考官网</a></p>
</li>
<li>
<p>HBase 开启 Kerberos 需要 zookeeper 也要开启 Kerberos.</p>
</li>
</ul>
</div>
</li>
<li>
<p>多 KDC 不在此文档实现, 具体可参考下列博客</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://secfree.github.io/blog/2015/06/23/kerberos-kdc-xinetd.html">Kerberos 多 KDC 中使用 xinetd</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Principal 介绍</p>
<div class="ulist">
<ul>
<li>
<p>在 Kerberos 安全机制里, 一个 principal 就是 realm 里的一个对象, 一个 principal 总是和一个密钥（secret key）成对出现的.</p>
</li>
<li>
<p>这个 principal 的对应物可以是 service, 可以是 host, 也可以是 user, 对于 Kerberos 来说,都没有区别.</p>
</li>
<li>
<p>Kdc(Key distribute center) 知道所有 principal 的 secret key, 但每个 principal 对应的对象只知道自己的那个 secret key. 这也是"共享密钥"的由来.</p>
</li>
<li>
<p>对于 hadoop, principals 的格式为 username/fully.qualified.domain.name@YOUR-REALM.COM</p>
</li>
</ul>
</div>
</li>
<li>
<p>Keytab</p>
<div class="ulist">
<ul>
<li>
<p>keytab 是包含 principals 和加密 principal key 的文件. keytab 文件对于每个 host 是唯一的, 因为 key 中包含 hostname.</p>
</li>
<li>
<p>keytab 文件用于不需要人工交互和保存纯文本密码, 实现到 kerberos 上验证一个主机上的 principal.</p>
</li>
<li>
<p>因为服务器上可以访问 keytab 文件即可以以 principal 的身份通过 kerberos 的认证. 所以, keytab 文件应该被妥善保存, 应该只有少数的用户可以访问.</p>
</li>
</ul>
</div>
</li>
<li>
<p>关于AES-256加密 根据 JDK 版本自行下载</p>
<div class="ulist">
<ul>
<li>
<p>对于使用 centos5.6 及以上的系统, 默认使用 AES-256 来加密. 这就需要集群中的所有节点上安装 JCE.</p>
</li>
<li>
<p><a href="https://www.oracle.com/technetwork/java/javase/downloads/jce-6-download-429243.html?spm=5176.blog25636.yqblogcon1.4.omPS6X">Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files for JDK/JRE 6</a></p>
</li>
<li>
<p><a href="https://www.oracle.com/technetwork/java/embedded/embedded-se/downloads/jce-7-download-432124.html?spm=5176.blog25636.yqblogcon1.5.omPS6X">Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files for JDK/JRE 7</a></p>
</li>
<li>
<p><a href="https://www.oracle.com/technetwork/java/javase/downloads/jce8-download-2133166.html">Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy Files 8 Download</a></p>
</li>
<li>
<p>下载的文件是一个 zip 包, 解开后将里面的两个文件拷贝到目录: JAVA_HOME/jre/lib/security</p>
</li>
</ul>
</div>
</li>
<li>
<p>Ranger 配置</p>
<div class="ulist">
<ul>
<li>
<p>Ranger 安装需要注意 hbase 组件的版本.</p>
</li>
<li>
<p>具体配置参考官网 <a href="https://cwiki.apache.org/confluence/display/RANGER/Ranger+installation+in+Kerberized++Environment#RangerinstallationinKerberizedEnvironment-InstallationStepsforRanger-Admin">Ranger installation in Kerberized Environment</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>Debug</p>
<div class="ulist">
<ul>
<li>
<p>Hadoop 集群可通过 <code>export HADOOP_OPTS=" -Dsun.security.krb5.debug=true "</code> Debug</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Kerberos 常用命令:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>list_principals</p>
</li>
<li>
<p>getprinc hbase/hadoop3@HADOOP.COM</p>
</li>
<li>
<p>getprinc krbtgt/HADOOP.COM</p>
</li>
<li>
<p>modprinc -maxlife 90days hbase/hadoop3@HADOOP.COM</p>
</li>
<li>
<p>modprinc -maxlife 90days krbtgt/HADOOP.COM</p>
</li>
</ol>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_代码编译"><a class="anchor" href="#_代码编译"></a>代码编译</h2>
<div class="sectionbody">
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
NM的一个Bug <a href="https://issues.apache.org/jira/browse/MAPREDUCE-5763">version&#8656;2.7.x</a> 下载相关patch, 打好补丁之后再编译代码.
编译完替换 <code>hadoop-mapreduce-client-shuffle-2.6.4.jar</code>  另外: <a href="https://issues.apache.org/jira/browse/YARN-3203">警告提示语句,语法错误</a>,这个无关紧要,可以不打patch.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>下面编译错误信息是个bug: <a href="https://issues.apache.org/jira/browse/MAPREDUCE-4769">Patch地址</a></p>
</div>
<div class="listingblock">
<div class="content">
<pre>Linking CXX executable examples/pipes-sort
/usr/local/lib/gcc/x86_64-unknown-linux-gnu/4.8.1/../../../../x86_64-unknown-linux-gnu/bin/ld: libhadooppipes.a(HadoopPipes.cc.o): undefined reference to symbol 'BIO_ctrl'
/lib64/libcrypto.so.6: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
make\[2]: \*** [examples/pipes-sort] Error 1
make\[1]: \*** [CMakeFiles/pipes-sort.dir/all] Error 2
make: \*** [all] Error 2</pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Centos 64</p>
<div class="ulist">
<ul>
<li>
<p><code>yum -y install gcc-c++.x86_64 make.x86_64 openssl.x86_64 openssl-devel.x86_64 openssh.x86_64 libtool.x86_64 autoconf.noarch automake.noarch cmake.x86_64 xz.x86_64 xz-devel.x86_64  zlib.x86_64 zlib-devel.x86_64</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>编译</p>
<div class="ulist">
<ul>
<li>
<p><code>mvn package -X -Pdist,native -DskipTests -Dtar -Dmaven.javadoc.skip=true -Dcontainer-executor.conf.dir=/etc/yarn-container</code></p>
<div class="ulist">
<ul>
<li>
<p><code>-Dcontainer-executor.conf.dir=/etc/yarn-container</code> 是为了满足kerberos的一些限制,详情参考kerberos安装说明. 编译native是为了匹配当前机器的GLIBC的版本.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_安装ldap"><a class="anchor" href="#_安装ldap"></a>安装ldap</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://yhz61010.iteye.com/blog/2352672">安装参考</a> 如果已经安装,跳过此步骤.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">#!/usr/bin/env bash

### 在需要安装 ldap 的机器上面执行如下命令进行安装.

export LDAP_PASSWORD=vYGwAbBX%3D@66UX
export LDAP_ADMIN_USER=Manager
export LDAP_HOST=hadoop1.xx.hadoop.com
export LDAP_BASE=dc=hadoop,dc=com
export LDAP_DC=hadoop


################ 安装 ldap 安装包 ################
yum install -y openldap openldap-clients openldap-servers migrationtools
cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG
chown ldap. /var/lib/ldap/DB_CONFIG
systemctl start slapd
systemctl enable slapd

################ 修改配置文件 ################
if [[ "${LDAP_HOST}" != ""   &amp;&amp; "${LDAP_BASE}" != "" ]]; then
    sed -i "/^URI/d" /etc/openldap/ldap.conf
    sed -i "/^BASE/d" /etc/openldap/ldap.conf

    echo -e "URI ldap://${LDAP_HOST}/" &gt;&gt; /etc/openldap/ldap.conf
    echo -e "BASE ${LDAP_BASE}" &gt;&gt; /etc/openldap/ldap.conf
    echo -e "TLS_REQCERT never" &gt;&gt; /etc/openldap/ldap.conf

    cat /etc/openldap/ldap.conf
fi

################ 配置 ldap 日志 ################
echo -e "
# Send slapd(8c) logs to /var/log/slapd.log
if \$programname == 'slapd' then /var/log/slapd.log
&amp; ~
" &gt;&gt; /etc/rsyslog.conf

touch /var/log/slapd.log

service rsyslog restart

service slapd restart

netstat -tlnp | grep slapd

tailf /var/log/slapd.log

################ 设置 OpenLDAP 的管理员密码  ################
slappasswd
New password:vYGwAbBX%3D@66UX
Re-enter new password:vYGwAbBX%3D@66UX
{SSHA}D/9SFStcv+rjHMtrJUkcBP7MU1L3Trye

#其中 {SSHA}xxxxxxxxxxxxxxxxxxxxxxxx 就是加密处理后的明文密码, 之后会用到这个密码.

## 创建文件
touch chrootpw.ldif
echo "dn: olcDatabase={0}config,cn=config" &gt;&gt; chrootpw.ldif
echo "changetype: modify" &gt;&gt; chrootpw.ldif
echo "add: olcRootPW" &gt;&gt; chrootpw.ldif
echo "olcRootPW: {SSHA}D/9SFStcv+rjHMtrJUkcBP7MU1L3Trye" &gt;&gt; chrootpw.ldif


## 导入文件
ldapadd -Y EXTERNAL -H ldapi:/// -f chrootpw.ldif
SASL/EXTERNAL authentication started
SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth
SASL SSF: 0
modifying entry "olcDatabase={0}config,cn=config"

################ 导入基本 Schema（可以有选择的导入）  ################

cd /etc/openldap/schema/
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f collective.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f corba.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f core.ldif   ##  报错 忽略
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f cosine.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f duaconf.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f dyngroup.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f inetorgperson.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f java.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f misc.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f nis.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f openldap.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f pmi.ldif
ldapadd -Y EXTERNAL -H ldapi:/// -D "cn=config" -f ppolicy.ldif

################ 设置自己的 Domain Name   ################
#首先要生成经处理后的目录管理者明文密码

slappasswd
New password:vYGwAbBX%3D@66UX
Re-enter new password:vYGwAbBX%3D@66UX
{SSHA}zENgMVBMt/S8E+BKwdZZiqzWyATMNL17


# 要使用你自己的域名替换掉文件中所有的 "dc=***,dc=***", 并且使用刚刚生成的密码, 替换文中的 "olcRootPW" 部分
cat &gt; chdomain.ldif &lt;&lt; EOF
# replace to your own domain name for "dc=***,dc=***" section
# specify the password generated above for "olcRootPW" section
dn: olcDatabase={1}monitor,cn=config
changetype: modify
replace: olcAccess
olcAccess: {0}to * by dn.base="gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth"
  read by dn.base="cn=Manager,${LDAP_BASE}" read by * none

dn: olcDatabase={2}hdb,cn=config
changetype: modify
replace: olcSuffix
olcSuffix: ${LDAP_BASE}

dn: olcDatabase={2}hdb,cn=config
changetype: modify
replace: olcRootDN
olcRootDN: cn=Manager,${LDAP_BASE}

dn: olcDatabase={2}hdb,cn=config
changetype: modify
add: olcRootPW
olcRootPW: {SSHA}zENgMVBMt/S8E+BKwdZZiqzWyATMNL17

dn: olcDatabase={2}hdb,cn=config
changetype: modify
add: olcAccess
olcAccess: {0}to attrs=userPassword,shadowLastChange by
  dn="cn=Manager,${LDAP_BASE}" write by anonymous auth by self write by * none
olcAccess: {1}to dn.base="" by * read
olcAccess: {2}to * by dn="cn=Manager,${LDAP_BASE}" write by * read
EOF

cat chdomain.ldif

# 导入该文件
ldapmodify -Y EXTERNAL -H ldapi:/// -f chdomain.ldif
SASL/EXTERNAL authentication started
SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth
SASL SSF: 0
modifying entry "olcDatabase={1}monitor,cn=config"

modifying entry "olcDatabase={2}hdb,cn=config"

modifying entry "olcDatabase={2}hdb,cn=config"

modifying entry "olcDatabase={2}hdb,cn=config"

modifying entry "olcDatabase={2}hdb,cn=config"


#要使用你自己的域名替换掉文件中所有的 "dc=***,dc=***"
cat &gt; basedomain.ldif &lt;&lt; EOF
# replace to your own domain name for "dc=***,dc=***" section
dn: ${LDAP_BASE}
objectClass: top
objectClass: dcObject
objectclass: organization
o: Server World
dc: ${LDAP_DC}

dn: cn=Manager,${LDAP_BASE}
objectClass: organizationalRole
cn: Manager
description: Directory Manager

dn: ou=People,${LDAP_BASE}
objectClass: organizationalUnit
ou: People

dn: ou=Group,${LDAP_BASE}
objectClass: organizationalUnit
ou: Group
EOF

cat basedomain.ldif



# 导入该文件
ldapadd -x -D cn=Manager,${LDAP_BASE} -W -f basedomain.ldif
Enter LDAP Password:


################ 到此 ldap 已经安装完毕, 安装 phpldapadmin 用于管理 ldap 的 web 界面  ################

yum install -y phpldapadmin


vim /etc/phpldapadmin/config.php
#修改内容, 解除 397 行的注释, 注释到 398 行. 修改后的结果如下:
$servers-&gt;setValue('login','attr','dn');
// $servers-&gt;setValue('login','attr','uid');

##########

vim /etc/httpd/conf.d/phpldapadmin.conf
#
#  Web-based tool for managing LDAP servers
#

Alias /phpldapadmin /usr/share/phpldapadmin/htdocs
Alias /ldapadmin /usr/share/phpldapadmin/htdocs

&lt;Directory /usr/share/phpldapadmin/htdocs&gt;
  &lt;IfModule mod_authz_core.c&gt;
    # Apache 2.4
    #Require local
    Require all granted
  &lt;/IfModule&gt;
  &lt;IfModule !mod_authz_core.c&gt;
    # Apache 2.2
    Order Deny,Allow
    Deny from all
    Allow from 127.0.0.1
    Allow from ::1
  &lt;/IfModule&gt;
&lt;/Directory&gt;


systemctl restart httpd

curl  http://localhost/phpldapadmin/</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_安装_kerberos"><a class="anchor" href="#_安装_kerberos"></a>安装 Kerberos</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://github.com/abajwa-hw/security-workshops/blob/master/Setup-OpenLDAP-KDC-integration.md">安装参考</a> 如果已经安装,跳过此步骤.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export LDAP_PASSWORD=vYGwAbBX%3D@66UX
export LDAP_ADMIN_USER=Manager

export KDC_REALM=HADOOP.COM
export KDC_HOST=hadoop7
export KDC_DOMAIN=hadoop.com

#export KDC_ADMIN=admin/admin
export KDC_PASSWORD=25rvBmu^6DEK4wNE
export KDC_ADMINPASSWORD=25rvBmu^6DEK4wNE

export TEMP_DIR=/root/ldap_kerberos

export LDAP_ADMIN_USER=Manager
export KDC_DOMAIN_DN=dc=hadoop,dc=com

export LDAP_DOMAIN_DN=cn=Manager,dc=hadoop,dc=com
export LDAP_KERBEROS_CONTAINER_DN=cn=kerberos,dc=hadoop,dc=com


################ 安装软件   ################

#on each client node
yum install -y krb5-workstation

#on admin node
yum install -y krb5-pkinit-openssl krb5-libs krb5-server-ldap krb5-server


################ Configure OpenLDAP to talk to KDC   ################

ls -l /usr/share/doc/krb5-server-ldap-1.15.1/kerberos.schema
cp -r /usr/share/doc/krb5-server-ldap-1.15.1/kerberos.schema /etc/openldap/schema/

mkdir $TEMP_DIR
cd $TEMP_DIR
mkdir  $TEMP_DIR/ldif_output
export SCHEMA_CONV=$TEMP_DIR/schema_convert.conf

echo "include /etc/openldap/schema/core.schema" &gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/collective.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/corba.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/cosine.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/duaconf.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/dyngroup.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/inetorgperson.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/java.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/misc.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/nis.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/openldap.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/ppolicy.schema" &gt;&gt; $SCHEMA_CONV
echo "include /etc/openldap/schema/kerberos.schema" &gt;&gt; $SCHEMA_CONV

slapcat -f schema_convert.conf -F $TEMP_DIR/ldif_output -n0 -s "cn={12}kerberos,cn=schema,cn=config" &gt; cn=kerberos.ldif

cp cn\=kerberos.ldif cn\=kerberos.ldif.orig

#remove {12} from $TEMP_DIR/cn\=kerberos.ldif
sed -i "s/{12}kerberos/kerberos/g" cn\=kerberos.ldif


#remove bottom lines
head -n -8 cn\=kerberos.ldif &gt; cn\=kerberos.ldif.tmp
/bin/rm -f cn\=kerberos.ldif
mv cn\=kerberos.ldif.tmp cn\=kerberos.ldif

### 导入
ldapadd -c -Y EXTERNAL -H ldapi:/// -f cn\=kerberos.ldif


#vi /etc/openldap/slapd.d/cn\=config/olcDatabase\=\{2\}bdb.ldif
#add olcDbIndex: krbPrincipalName eq,pres,sub
#sed -i "s/olcDbLinearIndex: FALSE/olcDbIndex: krbPrincipalName eq,pres,sub\nolcDbLinearIndex: FALSE/g" /etc/openldap/slapd.d/cn\=config/olcDatabase\=\{2\}bdb.ldif


mv /var/kerberos/krb5kdc/kdc.conf /var/kerberos/krb5kdc/kdc.conf.orig
cat &gt; /var/kerberos/krb5kdc/kdc.conf &lt;&lt; EOF
[kdcdefaults]
 kdc_ports = 88
 kdc_tcp_ports = 88
 v4_mode = nopreauth

[realms]
 ${KDC_REALM} = {
 acl_file = /var/kerberos/krb5kdc/kadm5.acl
 dict_file = /usr/share/dict/words
 admin_keytab = /var/kerberos/krb5kdc/kadm5.keytab
 #max_life = 10h 0m 0s
 #max_renewable_life = 7d 0h 0m 0s
 max_life = 90d
 max_renewable_life = 360d
 master_key_type = des3-hmac-sha1
#supported_enctypes = arcfour-hmac:normal des3-hmac-sha1:normal des-cbc-crc:normal des:normal des:v4 des:norealm des:onlyrealm des:afs3
 supported_enctypes = aes256-cts:normal aes128-cts:normal des3-hmac-sha1:normal arcfour-hmac:normal camellia256-cts:normal camellia128-cts:normal des-hmac-sha1:normal des-cbc-md5:normal des-cbc-crc:normal
 default_principal_flags = +renewable
}


[dbdefaults]
ldap_kerberos_container_dn = ${LDAP_KERBEROS_CONTAINER_DN}

[dbmodules]
openldap_ldapconf = {
  db_library = kldap
  ldap_kdc_dn = ${LDAP_DOMAIN_DN}
  ldap_kadmind_dn = ${LDAP_DOMAIN_DN}
  ldap_service_password_file = /etc/krb5.d/stash.keyfile
  #    ldap_servers = ldapi://localhost:389/
  ldap_servers = ldapi:///
  ldap_conns_per_server = 5
}
EOF

cat /var/kerberos/krb5kdc/kdc.conf

#wget https://github.com/abajwa-hw/kdc-stack/raw/master/package/templates/kdc.conf -P /var/kerberos/krb5kdc/
#sed -i "s/EXAMPLE.COM/$KDC_REALM/g" /var/kerberos/krb5kdc/kdc.conf

#update ACL file
sed -i "s/EXAMPLE.COM/$KDC_REALM/g" /var/kerberos/krb5kdc/kadm5.acl
cat /var/kerberos/krb5kdc/kadm5.acl

mv /etc/krb5.conf /etc/krb5.conf.orig
#wget https://github.com/abajwa-hw/kdc-stack/raw/master/package/templates/krb5.conf -P /etc
#sed -i "s/EXAMPLE.COM/$KDC_REALM/g" /etc/krb5.conf
#sed -i "s/kerberos.example.com/$KDC_HOST/g" /etc/krb5.conf
#sed -i "s/example.com/$KDC_DOMAIN/g" /etc/krb5.conf
#sed -i "s/dc=EXAMPLE,dc=COM/$KDC_DOMAIN_DN/g" /etc/krb5.conf
#sed -i "s/Manager/$LDAP_ADMIN_USER/g" /etc/krb5.conf

cat &gt; /etc/krb5.conf &lt;&lt; EOF
[logging]
 default = FILE:/var/log/krb5libs.log
 kdc = FILE:/var/log/krb5kdc.log
 admin_server = FILE:/var/log/kadmind.log

[libdefaults]
default_realm = ${KDC_REALM}
dns_lookup_realm = false
dns_lookup_kdc = false
ticket_lifetime = 24h
renew_lifetime = 7d
forwardable = true
allow_weak_crypto = true
#default_tkt_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1
#default_tgs_enctypes = des-cbc-md5 des-cbc-crc des3-cbc-sha1

[realms]
${KDC_REALM} = {
kdc = ${KDC_HOST}
admin_server = ${KDC_HOST}
database_module = openldap_ldapconf
}

[domain_realm]
.${KDC_DOMAIN} = ${KDC_REALM}
${KDC_DOMAIN} = ${KDC_REALM}

[appdefaults]
pam = {
debug = false
ticket_lifetime = 36000
renew_lifetime = 36000
forwardable = true
krb4_convert = false
}

[dbmodules]
openldap_ldapconf = {
  db_library = kldap
  ldap_kerberos_container_dn = ${LDAP_KERBEROS_CONTAINER_DN}
  ldap_kdc_dn = ${LDAP_DOMAIN_DN}
  # this object needs to have read rights on
  # the realm container, principal container and realm sub-trees
  ldap_kadmind_dn = ${LDAP_DOMAIN_DN}
  # this object needs to have read and write rights on
  # the realm container, principal container and realm sub-trees
  ldap_service_password_file = /etc/krb5.d/stash.keyfile
  ldap_servers = ldapi:///
  ldap_conns_per_server = 5
}
EOF

cat /etc/krb5.conf


#create KDC entries in LDAP
kdb5_ldap_util -D "${LDAP_DOMAIN_DN}" create -subtrees "${LDAP_KERBEROS_CONTAINER_DN}" -r ${KDC_REALM} -s -H ldapi:///

ldapsearch -LLLY EXTERNAL -H ldapi:/// -b ${LDAP_KERBEROS_CONTAINER_DN} dn

mkdir /etc/krb5.d

kdb5_ldap_util -D "${LDAP_DOMAIN_DN}" stashsrvpw -f /etc/krb5.d/stash.keyfile "${LDAP_DOMAIN_DN}"

cat /etc/krb5.d/stash.keyfile


###################### Setup servie logs for KDC services ######################
touch /var/log/krb5kdc.log /var/log/kadmind.log

echo "# Send kadmind(8) logs to /var/log/kadmind.log" &gt;&gt; /etc/rsyslog.conf
echo "if \$programname == 'kadmind' then /var/log/kadmind.log" &gt;&gt; /etc/rsyslog.conf
echo "&amp; ~" &gt;&gt; /etc/rsyslog.conf

echo "# Send krb5kdc(8) logs to /var/log/krb5kdc.log" &gt;&gt; /etc/rsyslog.conf
echo "if \$programname == 'krb5kdc' then /var/log/krb5kdc.log" &gt;&gt; /etc/rsyslog.conf
echo "&amp; ~" &gt;&gt; /etc/rsyslog.conf

service rsyslog restart

tail -F /var/log/krb5kdc.log /var/log/kadmind.log

#Start KDC services
chkconfig krb5kdc on
chkconfig kadmin on

systemctl restart krb5kdc
systemctl restart kadmin

systemctl status krb5kdc
systemctl status kadmin

# 创建远程管理员账号
kadmin.local -q "addprinc root/admin@${KDC_REALM}"
passwd:${KDC_PASSWORD}

kadmin.local -p root/admin -q "list_principals"

# 查询ldap 上面的 princ
ldapsearch -LLLY EXTERNAL -H ldapi:/// -b ${LDAP_KERBEROS_CONTAINER_DN} dn

#on each node
scp -r /etc/krb5.conf  hadoop1~n:/etc/krb5.conf

#on hadoop1 test
kadmin</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_前期准备"><a class="anchor" href="#_前期准备"></a>前期准备</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_hadoop_服务keytab_创建"><a class="anchor" href="#_hadoop_服务keytab_创建"></a>Hadoop 服务Keytab 创建</h3>
<div class="ulist">
<ul>
<li>
<p>addprinc on kdc node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">for node in `cat /etc/hosts|grep hadoop|awk '{print $2}'` ;do
    echo ${node}
    kadmin.local -q "addprinc -randkey your_hdfs_super_account/${node}"
    kadmin.local -q "addprinc -randkey spnego/${node}"
    kadmin.local -q "addprinc -randkey rangeradmin/${node}"
    kadmin.local -q "addprinc -randkey rangerlookup/${node}"
    kadmin.local -q "addprinc -randkey HTTP/${node}"
    kadmin.local -q "addprinc -randkey nn/${node}"
    kadmin.local -q "addprinc -randkey jn/${node}"
    kadmin.local -q "addprinc -randkey sn/${node}"
    kadmin.local -q "addprinc -randkey dn/${node}"
    kadmin.local -q "addprinc -randkey rm/${node}"
    kadmin.local -q "addprinc -randkey nm/${node}"
    kadmin.local -q "addprinc -randkey jhs/${node}"
    kadmin.local -q "addprinc -randkey tls/${node}"
    kadmin.local -q "addprinc -randkey hbase/${node}"
    kadmin.local -q "addprinc -randkey hive/${node}"
    kadmin.local -q "addprinc -randkey zookeeper/${node}"
    kadmin.local -q "addprinc -randkey spark/${node}"
done

kadmin.local -q "list_principals"</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create hadoop service keytab on hadoop node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE
mkdir -p /etc/keytabs
cd /etc/keytabs

cat &gt; /etc/keytabs/tmp &lt;&lt; EOF
nn.service.keytab nn
jn.service.keytab jn
dn.service.keytab dn
jhs.service.keytab    jhs
rm.service.keytab rm
nm.service.keytab nm
tls.service.keytab    tls
spnego.service.keytab HTTP
EOF

## on each hadoop node
cat /etc/keytabs/tmp | awk '{ print $1,$2}' | while read key_name user
do
    #key_name=spnego.service.keytab
    #user=HTTP
    cd /etc/keytabs
    \rm -rfv /etc/keytabs/${key_name}
    echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
    chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
    klist -ket ${key_name}
    #kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
    #klist
    #kdestroy
    sleep 2
done</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create rangeradmin service keytab on ranger node</p>
<div class="ulist">
<ul>
<li>
<p><a href="https://cwiki.apache.org/confluence/display/RANGER/Ranger+installation+in+Kerberized++Environment#RangerinstallationinKerberizedEnvironment-InstallationStepsforRanger-Admin">Ranger Kerberos</a></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># rangeradmin

export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE
mkdir -p /etc/keytabs
cd /etc/keytabs

key_name=rangeradmin.service.keytab
user=rangeradmin

key_name=rangerlookup.service.keytab
user=rangerlookup

cd /etc/keytabs
\rm -rfv /etc/keytabs/${key_name}
echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
klist -ket ${key_name}
#kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
#klist
#kdestroy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create hive keytab on hive server node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE

mkdir -p /etc/keytabs
cd /etc/keytabs

key_name=hive.service.keytab
user=hive

cd /etc/keytabs
\rm -rfv /etc/keytabs/${key_name}
echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
klist -ket ${key_name}
#kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
#klist
#kdestroy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create hbase keytab on hbase server node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE

mkdir -p /etc/keytabs
cd /etc/keytabs

key_name=hbase.service.keytab
user=hbase

cd /etc/keytabs
\rm -rfv /etc/keytabs/${key_name}
echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
klist -ket ${key_name}
#kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
#klist
#kdestroy
ls -l</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create zookeeper keytab on zk server node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE

mkdir -p /etc/keytabs
cd /etc/keytabs

key_name=zookeeper.service.keytab
user=zookeeper

cd /etc/keytabs
\rm -rfv /etc/keytabs/${key_name}
echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
klist -ket ${key_name}
#kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
#klist
#kdestroy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>create spark keytab on spark server node</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
export KDC_PASSWORD=25rvBmu^6DEK4wNE

mkdir -p /etc/keytabs
cd /etc/keytabs

key_name=spark.service.keytab
user=spark

cd /etc/keytabs
\rm -rfv /etc/keytabs/${key_name}
echo "${KDC_PASSWORD}" |kadmin -p root/admin -q "xst  -k /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}"
chown your_service_startup_account:your_service_startup_group /etc/keytabs/${key_name} ;chmod 400 /etc/keytabs/${key_name}
klist -ket ${key_name}
#kinit -k -t /etc/keytabs/${key_name}  ${user}/`hostname`@${KDC_REALM}
#klist
#kdestroy</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>配置 hadoop container-executor</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># on each node
mkdir -p /etc/yarn-container

cat &gt; /etc/yarn-container/container-executor.cfg &lt;&lt; EOF
yarn.nodemanager.linux-container-executor.group=your_hdfs_super_group
banned.users=root
min.user.id=500
allowed.system.users=nobody,impala,hive,hdfs,yarn,your_hdfs_super_account
EOF

cp -r /your_path/container-executor /etc/yarn-container/
ls -l /etc/yarn-container/

chown root:your_hdfs_super_group /etc/yarn-container/*
chmod 6050 /etc/yarn-container/container-executor
chmod 400 /etc/yarn-container/container-executor.cfg
ls -l /etc/yarn-container
/etc/yarn-container/container-executor --checksetup


for i in `cat /etc/hosts|grep -E "hadoop"|grep -Ev "hadoop1"|awk '{print $2}'`;do
echo $i
scp -r /etc/yarn-container $i:/etc/
ssh $i "chown root:your_hdfs_super_group /etc/yarn-container/*
chmod 6050 /etc/yarn-container/container-executor
chmod 400 /etc/yarn-container/container-executor.cfg
ls -l /etc/yarn-container
"
done</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_配置hadoophbasehivespark等组件的kerberos"><a class="anchor" href="#_配置hadoophbasehivespark等组件的kerberos"></a>配置Hadoop,Hbase,Hive,Spark等组件的Kerberos</h2>
<div class="sectionbody">
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/SecureMode.html#Configuration">官方配置</a></p>
</li>
<li>
<p><a href="https://community.cloudera.com/t5/Support-Questions/Zookeeper-kerberos-authentication/m-p/147267">zk 开启 Kerberos 后,NN 的配置</a></p>
</li>
<li>
<p><a href="http://bdlabs.edureka.co/static/help/topics/cdh_sg_hbase_authentication.html#concept_srw_ybw_4t_unique_4">Hbase 配置</a></p>
</li>
</ol>
</div>
<div class="sect2">
<h3 id="_hadoop_配置"><a class="anchor" href="#_hadoop_配置"></a>Hadoop 配置</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>core-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- security switch begin--&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.rpc.protection&lt;/name&gt;
        &lt;value&gt;authentication&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hadoop.security.authorization&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hadoop.security.authentication&lt;/name&gt;
        &lt;value&gt;kerberos&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hadoop.security.auth_to_local&lt;/name&gt;
        &lt;value&gt;RULE:[2:$1@$0](nn@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](jn@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](dn@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](nm@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](rm@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](jhs@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](tls@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](hbase@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](rangeradmin@HADOOP.COM)s/.*/work/
            RULE:[2:$1@$0](spark@HADOOP.COM)s/.*/work/
            DEFAULT&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- security switch end--&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>hdfs-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- General HDFS security config --&gt;
     &lt;property&gt;
          &lt;name&gt;dfs.block.access.token.enable&lt;/name&gt;
          &lt;value&gt;true&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.namenode.keytab.file&lt;/name&gt;
          &lt;value&gt;/etc/keytabs/nn.service.keytab&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.namenode.kerberos.principal&lt;/name&gt;
          &lt;value&gt;nn/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.namenode.kerberos.internal.spnego.principal&lt;/name&gt;
          &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.secondary.namenode.keytab.file&lt;/name&gt;
          &lt;value&gt;/etc/keytabs/nn.service.keytab&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.secondary.namenode.kerberos.principal&lt;/name&gt;
          &lt;value&gt;nn/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.secondary.namenode.kerberos.internal.spnego.principal&lt;/name&gt;
          &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;
          &lt;value&gt;700&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.keytab.file&lt;/name&gt;
          &lt;value&gt;/etc/keytabs/dn.service.keytab&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.kerberos.principal&lt;/name&gt;
          &lt;value&gt;dn/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.journalnode.keytab.file&lt;/name&gt;
          &lt;value&gt;/etc/keytabs/jn.service.keytab&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.journalnode.kerberos.principal&lt;/name&gt;
          &lt;value&gt;jn/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.journalnode.kerberos.internal.spnego.principal&lt;/name&gt;
          &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
          &lt;value&gt;false&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.web.authentication.kerberos.principal&lt;/name&gt;
          &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.web.authentication.kerberos.keytab&lt;/name&gt;
          &lt;value&gt;/etc/keytabs/spnego.service.keytab&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.encrypt.data.transfer&lt;/name&gt;
          &lt;value&gt;false&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.address&lt;/name&gt;
          &lt;value&gt;0.0.0.0:1004&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.https.address&lt;/name&gt;
          &lt;value&gt;0.0.0.0:50470&lt;/value&gt;
      &lt;/property&gt;

      &lt;property&gt;
          &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;
          &lt;value&gt;0.0.0.0:1006&lt;/value&gt;
      &lt;/property&gt;
      &lt;!-- General HDFS security config --&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>mapred-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- security switch begin--&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/jhs.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.principal&lt;/name&gt;
        &lt;value&gt;jhs/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- security switch end--&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>yarn-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- ResourceManager security configs --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/rm.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.principal&lt;/name&gt;
        &lt;value&gt;rm/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.http-authentication.type&lt;/name&gt;
        &lt;value&gt;kerberos&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.http-authentication.simple.anonymous.allowed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.client.best-effort&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.http-authentication.kerberos.principal&lt;/name&gt;
        &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.http-authentication.kerberos.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/spnego.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.principal&lt;/name&gt;
        &lt;value&gt;tls/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.timeline-service.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/tls.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/nm.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.principal&lt;/name&gt;
        &lt;value&gt;nm/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.container-executor.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.linux-container-executor.path&lt;/name&gt;
        &lt;value&gt;/etc/yarn-container/container-executor&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.linux-container-executor.group&lt;/name&gt;
        &lt;value&gt;your_hdfs_super_group&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- ResourceManager security configs --&gt;</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_hbase_配置"><a class="anchor" href="#_hbase_配置"></a>Hbase 配置</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>hbase-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- add for kerberos--&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.regionserver.kerberos.principal&lt;/name&gt;
        &lt;value&gt;hbase/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.regionserver.keytab.file&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/hbase.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.master.kerberos.principal&lt;/name&gt;
        &lt;value&gt;hbase/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.master.keytab.file&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/hbase.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.security.authentication.spnego.kerberos.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/spnego.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.security.authentication.spnego.kerberos.principal&lt;/name&gt;
        &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.security.authorization&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.security.authentication&lt;/name&gt;
        &lt;value&gt;kerberos&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rpc.protection&lt;/name&gt;
        &lt;value&gt;authentication&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rpc.timeout&lt;/name&gt;
        &lt;value&gt;90000&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;
        &lt;value&gt;/your_path/dn_socket&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.thrift.keytab.file&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/hbase.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.thrift.kerberos.principal&lt;/name&gt;
        &lt;value&gt;hbase/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rest.keytab.file&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/hbase.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rest.kerberos.principal&lt;/name&gt;
        &lt;value&gt;hbase/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rest.authentication.type&lt;/name&gt;
        &lt;value&gt;kerberos&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rest.authentication.kerberos.principal&lt;/name&gt;
        &lt;value&gt;HTTP/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hbase.rest.authentication.kerberos.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/spnego.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;!--end adding for kerberos --&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>hbase-env.sh</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Set environment variables here.

# The java implementation to use. Java 1.6 required.
export JAVA_HOME=/usr/java/default

# HBase Configuration directory
export HBASE_CONF_DIR=${HBASE_CONF_DIR:-/opt/cloud/hbase/conf}

# Extra Java CLASSPATH elements. Optional.
export HBASE_CLASSPATH=${HBASE_CLASSPATH}


# The maximum amount of heap to use, in MB. Default is 1000.
# export HBASE_HEAPSIZE=1000

# Extra Java runtime options.
# Below are what we set by default. May only work with SUN JVM.
# For more on why as well as other possible settings,
# see http://wiki.apache.org/hadoop/PerformanceTuning
export SERVER_GC_OPTS="-verbose:gc -XX:-PrintGCCause -XX:+PrintAdaptiveSizePolicy -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/opt/cloud/hbase/logs/gc.log-`date +'%Y%m%d%H%M'`"
# Uncomment below to enable java garbage collection logging.
# export HBASE_OPTS="$HBASE_OPTS -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:$HBASE_HOME/logs/gc-hbase.log"

# Uncomment and adjust to enable JMX exporting
# See jmxremote.password and jmxremote.access in $JRE_HOME/lib/management to configure remote password access.
# More details at: http://java.sun.com/javase/6/docs/technotes/guides/management/agent.html
#
# export HBASE_JMX_BASE="-Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false"
# If you want to configure BucketCache, specify '-XX: MaxDirectMemorySize=' with proper direct memory size
# export HBASE_THRIFT_OPTS="$HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10103"
# export HBASE_ZOOKEEPER_OPTS="$HBASE_JMX_BASE -Dcom.sun.management.jmxremote.port=10104"

# File naming hosts on which HRegionServers will run. $HBASE_HOME/conf/regionservers by default.
#export HBASE_REGIONSERVERS=${HBASE_CONF_DIR}/regionservers

# Extra ssh options. Empty by default.
# export HBASE_SSH_OPTS="-o ConnectTimeout=1 -o SendEnv=HBASE_CONF_DIR"

# Where log files are stored. $HBASE_HOME/logs by default.
#export HBASE_LOG_DIR=/var/log/hbase

# A string representing this instance of hbase. $USER by default.
# export HBASE_IDENT_STRING=$USER

# The scheduling priority for daemon processes. See 'man nice'.
# export HBASE_NICENESS=10

# The directory where pid files are stored. /tmp by default.
export HBASE_PID_DIR=/opt/cloud/hbase/hbase-pids

# Seconds to sleep between slave commands. Unset by default. This
# can be useful in large clusters, where, e.g., slave rsyncs can
# otherwise arrive faster than the master can service them.
# export HBASE_SLAVE_SLEEP=0.1

# Tell HBase whether it should manage it's own instance of Zookeeper or not.
export HBASE_MANAGES_ZK=false



# Set common JVM configuration
export HBASE_OPTS="$HBASE_OPTS -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:-ResizePLAB -XX:ErrorFile=/opt/cloud/hbase/logs/hs_err_pid%p.log -Djava.io.tmpdir=/opt/cloud/hbase/logs/iotmp"
export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS -Xmx4096m -XX:ParallelGCThreads=12 $JDK_DEPENDED_OPTS "
export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS -Xms4096m -Xmx4096m -XX:ParallelGCThreads=12 $JDK_DEPENDED_OPTS"
export PHOENIX_QUERYSERVER_OPTS="$PHOENIX_QUERYSERVER_OPTS -XX:ParallelGCThreads=12 $JDK_DEPENDED_OPTS"

# Add Kerberos authentication-related configuration

#export HBASE_OPTS="$HBASE_OPTS -Djava.security.auth.login.config=/opt/cloud/hbase/conf/hbase_client_jaas.conf -Dzookeeper.sasl.client=true -Dzookeeper.sasl.client.username=zookeeper -Dzookeeper.sasl.clientconfig=Client"
export HBASE_OPTS="$HBASE_OPTS -Djava.security.auth.login.config=/opt/cloud/hbase/conf/hbase_client_jaas.conf"
export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS -Djava.security.auth.login.config=/opt/cloud/hbase/conf/hbase_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false"
export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS -Djava.security.auth.login.config=/opt/cloud/hbase/conf/hbase_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false"
export PHOENIX_QUERYSERVER_OPTS="$PHOENIX_QUERYSERVER_OPTS -Djava.security.auth.login.config=/opt/cloud/hbase/conf/hbase_jaas.conf"


# HBase off-heap MaxDirectMemorySize
export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS "
export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS "</code></pre>
</div>
</div>
</li>
<li>
<p>hbase_client_jaas.conf</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=false
  useTicketCache=true;
};</code></pre>
</div>
</div>
</li>
<li>
<p>hbase_jaas.conf</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  storeKey=true
  useTicketCache=false
  keyTab="/etc/keytabs/hbase.service.keytab"
  principal="hbase/hadoop1.xx.hadoop.com@HADOOP.COM";
};
com.sun.security.jgss.krb5.initiate {
  com.sun.security.auth.module.Krb5LoginModule required
  renewTGT=false
  doNotPrompt=true
  useKeyTab=true
  storeKey=true
  useTicketCache=false
  keyTab="/etc/keytabs/hbase.service.keytab"
  principal="hbase/hadoop1.xx.hadoop.com@HADOOP.COM";
};</code></pre>
</div>
</div>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">for i in `cat /etc/hosts|grep -E "hadoop"|grep -Ev "hadoop1"|awk '{print $2}'`;do
echo $i
scp -r /opt/cloud/hbase/bin/hbase $i:/opt/cloud/hbase/bin/hbase
scp -r /opt/cloud/hbase/conf/hbase-env.sh $i:/opt/cloud/hbase/conf/hbase-env.sh
scp -r /opt/cloud/hbase/conf/hbase-site.xml $i:/opt/cloud/hbase/conf/hbase-site.xml
scp -r /opt/cloud/hbase/conf/hbase_client_jaas.conf $i:/opt/cloud/hbase/conf/
scp -r /opt/cloud/hbase/conf/hbase_jaas.conf $i:/opt/cloud/hbase/conf/
done


sed -i "s/hadoop1.xx.hadoop.com/`hostname`/g" /opt/cloud/hbase/conf/hbase_jaas.conf
cat /opt/cloud/hbase/conf/hbase_jaas.conf</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_hive_配置"><a class="anchor" href="#_hive_配置"></a>Hive 配置</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>hive-site.xml</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">    &lt;!-- add for kerberos--&gt;
    &lt;property&gt;
        &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hive.server2.authentication&lt;/name&gt;
        &lt;value&gt;KERBEROS&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hive.server2.authentication.kerberos.principal&lt;/name&gt;
        &lt;value&gt;work/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;hive.server2.authentication.kerberos.keytab&lt;/name&gt;
        &lt;value&gt;/etc/keytabs/work.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
      &lt;name&gt;hive.metastore.sasl.enabled&lt;/name&gt;
      &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
      &lt;name&gt;hive.metastore.kerberos.keytab.file&lt;/name&gt;
      &lt;value&gt;/etc/keytabs/work.service.keytab&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
      &lt;name&gt;hive.metastore.kerberos.principal&lt;/name&gt;
      &lt;value&gt;work/_HOST@HADOOP.COM&lt;/value&gt;
    &lt;/property&gt;
   ​&lt;!--end adding for kerberos --&gt;</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_spark_配置"><a class="anchor" href="#_spark_配置"></a>Spark 配置</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>spark-defaults.conf</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
cat &gt;&gt; spark-defaults.conf &lt;&lt; EOF
spark.history.kerberos.enabled true
spark.history.kerberos.principal spark/`hostname`@${KDC_REALM}
spark.history.kerberos.keytab /etc/keytabs/spark.service.keytab
EOF</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_zookeeper_配置"><a class="anchor" href="#_zookeeper_配置"></a>Zookeeper 配置</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>zoo.cfg</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">dataLogDir=/mnt/disk01/zk_data/log
dataDir=/mnt/disk01/zk_data/data
# The number of milliseconds of each tick
tickTime=3000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
autopurge.snapRetainCount=30
# Purge task interval in hours
# Set to "0" to disable auto purge feature
autopurge.purgeInterval=24
server.1=hadoop1:2888:3888
server.2=hadoop2:2888:3888
server.3=hadoop3:2888:3888

authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
jaasLoginRenew=3600000
kerberos.removeHostFromPrincipal=true
kerberos.removeRealmFromPrincipal=true</code></pre>
</div>
</div>
</li>
<li>
<p>zookeeper_client_jaas.conf</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=false
  useTicketCache=true;
};</code></pre>
</div>
</div>
</li>
<li>
<p>zookeeper_jaas.conf</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Server {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  storeKey=true
  useTicketCache=false
  keyTab="/etc/keytabs/zookeeper.service.keytab"
  principal="zookeeper/hadoop1.xx.hadoop.com@HADOOP.COM";
};</code></pre>
</div>
</div>
</li>
<li>
<p>java.env</p>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">#!/usr/bin/env bash
export JVMFLAGS="-Xms4096m -Xmx4096m $JVMFLAGS"


#zk base path
export JAVA_HOME=/usr/java/default
export JAVA=$JAVA_HOME/bin/java

export ZKPARENT_HOME=/opt/cloud

export ZOOKEEPER_HOME=${ZKPARENT_HOME}/zookeeper
export ZOO_LOG_DIR=${ZOOKEEPER_HOME}/log
export ZOOKEEPER_CONF=${ZOOKEEPER_HOME}/conf
export CLASSPATH=$CLASSPATH:$ZOOKEEPER_CONF:$ZOOKEEPER_HOME/*:$ZOOKEEPER_HOME/lib/*
export ZOOCFGDIR=${ZOOCFGDIR:-$ZOOKEEPER_CONF}


#SERVER_JVMFLAGS="-Dsun.net.spi.nameservice.provider.1=dns,sun"
#export JVMFLAGS="$JVMFLAGS $SERVER_JVMFLAGS"

export JVMFLAGS="$JVMFLAGS -Djava.security.auth.login.config=$ZOOKEEPER_CONF/zookeeper_jaas.conf"
#export JVMFLAGS="$JVMFLAGS -Djava.security.auth.login.config=$ZOOKEEPER_CONF/zookeeper_client_jaas.conf -Dzookeeper.sasl.client.username=zookeeper"</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_kylin_2_6_4_配置"><a class="anchor" href="#_kylin_2_6_4_配置"></a>Kylin 2.6.4 配置</h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">export KDC_REALM=HADOOP.COM
cat &gt; /opt/cloud/kylin/bin/init_kt.sh &lt;&lt; EOF
#!/bin/bash
kinit -k -t /etc/keytabs/kylin.service.keytab your_service_startup_account/`hostname`@${KDC_REALM}
EOF

crontab 配置
su - kylin
# kylin kinit
0 1 * * *  sh /opt/cloud/kylin/bin/init_kt.sh  &gt; /opt/cloud/kylin/logs/init_kt.log 2&gt;&amp;1</code></pre>
</div>
</div>
</div>
</div>
</div>
</article>
</main>
</div>
<footer class="footer">
  <p>This page was built using the Antora default UI.</p>
  <p>The source code for this UI is licensed under the terms of the MPL-2.0 license.</p>
</footer>
<script src="../../../_/js/site.js"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
